{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19fe915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "from gpytorch_models_old import DivergenceFreeSEKernel\n",
    "from NN_models import dfNN\n",
    "\n",
    "class dfNGP(gpytorch.models.ExactGP):\n",
    "    # dfGP model with constant mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        # Inherit from ExactGP with 3 inputs + self = 4 inputs\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = dfNN()\n",
    "        self.covar_module = DivergenceFreeSEKernel()\n",
    "        \n",
    "        # initialize hyperparameters by sampling from a uniform distribution over predefined ranges\n",
    "        self.likelihood.noise = torch.zeros(1, device = device) + 0.005\n",
    "        self.covar_module.outputscale = torch.ones(1, device = device) * 0.001\n",
    "        self.covar_module.lengthscale = torch.ones(2, device = device)\n",
    "\n",
    "        self.likelihood.noise_covar.register_constraint(\n",
    "            \"raw_noise\", gpytorch.constraints.GreaterThan(1e-4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Make 2D for dfNN\n",
    "        x_for_dfNN = x.reshape(2, -1).T\n",
    "        mean_x_from_dfNN = self.mean_module(x_for_dfNN)\n",
    "        # HACK: Reshape to interleaved format. This is counterintuitive but necessary\n",
    "        mean_x = mean_x_from_dfNN.reshape(-1)\n",
    "\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85ee702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLPMean(gpytorch.means.Mean):\n",
    "    def __init__(self, dim):\n",
    "        super(MLPMean, self).__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 32), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        m = self.mlp(x)\n",
    "        print(\"MLPMean output shape:\", m.shape)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb0b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dfRBFKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(dfRBFKernel, self).__init__(**kwargs)\n",
    "\n",
    "        # Register the outputscale / variance (sigma_f) as a learnable parameter\n",
    "        self.register_parameter(name = \"raw_outputscale\", \n",
    "                                parameter = torch.nn.Parameter(torch.tensor(1.0)))\n",
    "        \n",
    "        self.register_parameter(name = \"raw_lengthscale\",\n",
    "                                parameter = torch.nn.Parameter(torch.tensor([1.0, 1.0])))\n",
    "\n",
    "        # Register transform for positivity (softplus)\n",
    "        self.register_constraint(\"raw_outputscale\", gpytorch.constraints.Positive())\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", gpytorch.constraints.Positive())\n",
    "\n",
    "    @property\n",
    "    def outputscale(self):\n",
    "        return self.raw_outputscale_constraint.transform(self.raw_outputscale)\n",
    "    \n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @outputscale.setter\n",
    "    def outputscale(self, value):\n",
    "        self.initialize(raw_outputscale = self.raw_outputscale_constraint.inverse_transform(value))\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self.initialize(raw_lengthscale = self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, diag = False, **params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x1: torch.Size([2N, 1]) flattened, second explicit dim is automatic\n",
    "            x2: torch.Size([2M, 1])\n",
    "        Returns:\n",
    "            K: torch.Size([2N, 2M])\n",
    "        \"\"\"\n",
    "        # Transform long/flat format into 2D\n",
    "        mid_x1 = x1.shape[0] // 2\n",
    "        mid_x2 = x2.shape[0] // 2 \n",
    "\n",
    "        # torch.Size([N, 2])\n",
    "        x1 = torch.cat((x1[:mid_x1], x1[mid_x1:]), dim = 1).to(x1.device)\n",
    "        # torch.Size([M, 2])\n",
    "        x2 = torch.cat((x2[:mid_x2], x2[mid_x2:]), dim = 1).to(x2.device)\n",
    "\n",
    "        l = self.lengthscale.squeeze().to(x1.device)  # Shape (2,)\n",
    "\n",
    "        lx1, lx2 = l[0].to(x1.device), l[1].to(x1.device)\n",
    "\n",
    "        sigma_f = self.outputscale\n",
    "\n",
    "        # Broadcast pairwise differences: shape [N, M, 2]\n",
    "        diff = (x1[:, None, :] - x2[None, :, :]).to(x1.device)\n",
    "\n",
    "        ### 2x2 block components ###\n",
    "        upper_left = (1 - diff[:, :, 1].square() / lx2.square()) / lx2.square()\n",
    "        lower_right = (1 - diff[:, :, 0].square() / lx1.square()) / lx1.square()\n",
    "        upper_right = (diff[:, :, 0] * diff[:, :, 1]) / (lx1.square() * lx2.square())\n",
    "        lower_left = upper_right\n",
    "\n",
    "        # Block matrix assembly\n",
    "        top = torch.cat((upper_left, upper_right), dim = 1)\n",
    "        bottom = torch.cat((lower_left, lower_right), dim = 1)\n",
    "        blocks = torch.cat((top, bottom), dim = 0)\n",
    "\n",
    "        # RBF/SE envelope (elementwise)\n",
    "        exp_term = torch.exp(-0.5 * (diff.square() / l.square()).sum(dim = -1))\n",
    "        # .tile(2, 2) forms (N, M) -> (2N, 2M) for the 2D vector field\n",
    "        K = sigma_f.square() * blocks * exp_term.tile(2, 2)\n",
    "\n",
    "        # Add this for Quantile Coverage Error (QCE) calculation\n",
    "        if diag:\n",
    "        # Return only the diagonal as a 1D tensor\n",
    "            return K.diag()\n",
    "\n",
    "        return K\n",
    "\n",
    "class dfNGP(gpytorch.models.ExactGP):\n",
    "    # dfGP model with constant mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        # Inherit from ExactGP with 3 inputs + self = 4 inputs\n",
    "        # train_x is in flat block shape: [x1_1, x1_2, ..., x1_n, x2_1, x2_2, ..., x2_n]\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = MLPMean(dim = 2)\n",
    "        self.base_module = DivergenceFreeSEKernel()\n",
    "        \n",
    "        # initialize hyperparameters by sampling from a uniform distribution over predefined ranges\n",
    "        self.likelihood.noise = torch.zeros(1, device = device) + 0.0001\n",
    "        self.covar_module.outputscale = torch.ones(1, device = device) * 0.001\n",
    "        self.covar_module.lengthscale = torch.ones(2, device = device)\n",
    "\n",
    "        self.likelihood.noise_covar.register_constraint(\n",
    "            \"raw_noise\", gpytorch.constraints.GreaterThan(1e-4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Make 2D for dfNN\n",
    "        x_for_dfNN = x.reshape(2, -1).T\n",
    "        mean_x = self.mean_module(x_for_dfNN).T.reshape(-1)\n",
    "        # print(\"x:\", x_for_dfNN.shape)\n",
    "        # print(\"mean_x shape:\", mean_x.shape)\n",
    "\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import (simulate_detailed_curve,)\n",
    "simulations = {\"curve\": simulate_detailed_curve}\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised_0to1.pt\", weights_only = False).float()\n",
    "from utils import make_grid\n",
    "N_SIDE = 20\n",
    "_, x_test = make_grid(N_SIDE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "y_train = simulate_detailed_curve(x_train.cpu()).to(device)\n",
    "y_test = simulate_detailed_curve(x_test.cpu()).to(device)\n",
    "x_test = x_test.to(device)\n",
    "x_train = x_train.to(device)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "model = dfNGP(\n",
    "            x_train.T.reshape(-1),\n",
    "            y_train.T.reshape(-1), \n",
    "            likelihood,\n",
    "            ).to(device)\n",
    "model.train()\n",
    "likelihood.train()\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "optimizer = torch.optim.AdamW([\n",
    "            {\"params\": model.mean_module.parameters(), \"weight_decay\": 0.0001, \"lr\": (0.1)},\n",
    "            # {\"params\": list(model.covar_module.parameters()) + list(model.likelihood.parameters()), \"weight_decay\": # WEIGHT_DECAY, \"lr\": MODEL_LEARNING_RATE},\n",
    "            ])\n",
    "\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    train_pred_dist = model(x_train.T.reshape(-1).to(device))\n",
    "    print(\"HERE\")\n",
    "    # Train on noisy or true targets?\n",
    "    loss = - mll(train_pred_dist, y_train.T.reshape(-1).to(device))  # negative marginal log likelihood\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    print(\"HERE 2\")\n",
    "    train_pred_dist = model(x_train.T.reshape(-1).to(device))\n",
    "    print(\"HERE 3\")\n",
    "    test_pred_dist = model(x_test.T.reshape(-1).to(device))\n",
    "    print(\"HERE 4\")\n",
    "\n",
    "    train_RMSE = torch.sqrt(gpytorch.metrics.mean_squared_error(train_pred_dist, y_train.T.reshape(-1).to(device)))\n",
    "    test_RMSE = torch.sqrt(gpytorch.metrics.mean_squared_error(test_pred_dist, y_test.T.reshape(-1).to(device)))\n",
    "    test_mean_module_RMSE = (model.mean_module(x_test.to(device)).detach() - y_test.to(device)).norm(dim = 1).mean()\n",
    "\n",
    "    print(f\"Epoch {i + 1}, Training Loss (NLML): {loss:.4f}, (RMSE): {train_RMSE:.4f}, Test RMSE: {test_RMSE:.4f}, Test Mean Module RMSE: {test_mean_module_RMSE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column: 80 values from 1 to 8\n",
    "col1 = torch.linspace(1, 8, steps = 80)\n",
    "\n",
    "# Second column: 80 values from 10 to 80\n",
    "col2 = torch.linspace(10, 80, steps = 80)\n",
    "\n",
    "# Stack into a tensor of shape [80, 2]\n",
    "x_tensor = torch.stack([col1, col2], dim = 1)\n",
    "\n",
    "# shuffle formats\n",
    "x_flat_block = x_tensor.T.reshape(-1)\n",
    "x_two_column = x_flat_block.reshape(2, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d160527",
   "metadata": {},
   "source": [
    "# Build in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7201f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "\n",
    "class MLPMean_2D(gpytorch.means.Mean):\n",
    "    def __init__(self, dim):\n",
    "        super(MLPMean_2D, self).__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            torch.nn.Linear(dim, 32), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        m = self.mlp(x)\n",
    "        return m\n",
    "\n",
    "class dfNN(gpytorch.means.Mean):\n",
    "    # NOTE: This needs to be initialised of class gpytorch.means.Mean\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        # NOTE: we use the same default dimensionalities as the dfNN NN model\n",
    "        super(dfNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1  # Scalar potential (corresponds to H in HNNs)\n",
    "        \n",
    "        # HACK: SiLu() worked much better than ReLU() for this gradient-based model\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        H = self.net(x)\n",
    "\n",
    "        partials = torch.autograd.grad(\n",
    "                outputs = H.sum(), # we can sum here because every H row only depend on every x row\n",
    "                inputs = x,\n",
    "                create_graph = True\n",
    "            )[0]\n",
    "\n",
    "        # Symplectic gradient\n",
    "        # flip columns (last dim) for x2, x1 order. Multiply x2 by -1\n",
    "        mean_symp = partials.flip(-1) * torch.tensor([1, -1], dtype = torch.float32, device = x.device)\n",
    "\n",
    "        # return symp, H # NOTE: return H as well if we want to see what is going on\n",
    "        return mean_symp\n",
    "\n",
    "class dfNGP(gpytorch.models.ExactGP):\n",
    "    # dfGP model with constant mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(dfNGP, self).__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = dfNN(input_dim = 2) # default hidden_dim = 32\n",
    "        self.base_kernel = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        # print(\"mean_x shape:\", mean_x.shape)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # print(\"covar_x shape:\", covar_x.shape)\n",
    "        \n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478f0e0",
   "metadata": {},
   "source": [
    "# Add dfRBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dee07776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from gpytorch.lazy import KroneckerProductLazyTensor, lazify\n",
    "from gpytorch.kernels import Kernel\n",
    "\n",
    "class MultitaskKernelWrapper(Kernel):\n",
    "    r\"\"\"\n",
    "    Kernel supporting Kronecker style multitask Gaussian processes (where every data point is evaluated at every\n",
    "    task) using :class:`gpytorch.kernels.IndexKernel` as a basic multitask kernel.\n",
    "\n",
    "    Given a base covariance module to be used for the data, :math:`K_{XX}`, this kernel computes a task kernel of\n",
    "    specified size :math:`K_{TT}` and returns :math:`K = K_{TT} \\otimes K_{XX}`. as an\n",
    "    :obj:`gpytorch.lazy.KroneckerProductLazyTensor`.\n",
    "\n",
    "    :param ~gpytorch.kernels.Kernel data_covar_module: Kernel to use as the data kernel.\n",
    "    :param int num_tasks: Number of tasks\n",
    "    :param int rank: (default 1) Rank of index kernel to use for task covariance matrix.\n",
    "    :param ~gpytorch.priors.Prior task_covar_prior: (default None) Prior to use for task kernel.\n",
    "        See :class:`gpytorch.kernels.IndexKernel` for details.\n",
    "    :param dict kwargs: Additional arguments to pass to the kernel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_covar_module: Kernel,\n",
    "        num_tasks: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\"\"\"\n",
    "        super(MultitaskKernelWrapper, self).__init__(**kwargs)\n",
    "        self.data_covar_module = data_covar_module\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "    def forward(self, x1, x2, diag = False, **params):\n",
    "        # covar_x = lazify(self.data_covar_module.forward(x1, x2, **params))\n",
    "        covar_x = self.data_covar_module(x1, x2, **params)\n",
    "        print(\"covar_x shape inside:\", covar_x.shape)\n",
    "        return covar_x.diag() if diag else covar_x\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Given `n` data points `x1` and `m` datapoints `x2`, this multitask\n",
    "        kernel returns an `(n*num_tasks) x (m*num_tasks)` covariance matrix.\n",
    "        \"\"\"\n",
    "        return self.num_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16d8cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class dfRBFKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, num_tasks = 2, **kwargs):\n",
    "        super().__init__(num_tasks = num_tasks, **kwargs)\n",
    "        self.num_tasks = num_tasks\n",
    "        \n",
    "        self.register_parameter(name = \"raw_lengthscale\",\n",
    "                                parameter = torch.nn.Parameter(torch.tensor([1.0, 1.0])))\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", gpytorch.constraints.Positive())\n",
    "\n",
    "    @property\n",
    "    def outputscale(self):\n",
    "        return self.raw_outputscale_constraint.transform(self.raw_outputscale)\n",
    "    \n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @outputscale.setter\n",
    "    def outputscale(self, value):\n",
    "        self.initialize(raw_outputscale = self.raw_outputscale_constraint.inverse_transform(value))\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self.initialize(raw_lengthscale = self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, row_tensor, column_tensor, diag = False, **params):\n",
    "\n",
    "        # Extract the chosen device\n",
    "        device = row_tensor.device\n",
    "\n",
    "        # Remove second explicit dim to get Shape: (2,)\n",
    "        l = self.lengthscale.squeeze().to(device)\n",
    "        # Extract both lengthscales\n",
    "        l1, l2 = l[0], l[1]\n",
    "\n",
    "        # STEP 1: Pairwise differences of shape [N, M, 2]\n",
    "        # Expand row_tensor [N, 2] -> [N, 1, 2] and column_tensor [M, 2] -> [1, M, 2]\n",
    "        diff = (row_tensor[:, None, :] - column_tensor[None, :, :]).to(device)\n",
    "        # Extract the components (columns) for convenience, matching paper notation\n",
    "        r1 = diff[:, :, 0]\n",
    "        r2 = diff[:, :, 1]\n",
    "\n",
    "        # STEP 2: Block matrix\n",
    "        # Compute the 4 (2x2) block components\n",
    "        upper_left = l2.square() - r2.square()\n",
    "        lower_right = l1.square() - r1.square()\n",
    "        upper_right = r1 * r2\n",
    "        lower_left = upper_right # symmetric\n",
    "\n",
    "        # Assemble the 2x2 block matrix\n",
    "        top = torch.cat((upper_left, upper_right), dim = 1) # Shape: [N, 2M]\n",
    "        bottom = torch.cat((lower_left, lower_right), dim = 1) # Shape: [N, 2M]\n",
    "        blocks = torch.cat((top, bottom), dim = 0) # Shape: [2N, 2M]\n",
    "\n",
    "        # STEP 3: RBF/SE envelope (elementwise)\n",
    "        exponent_term = torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2))  # Shape: [N, M]\n",
    "        \n",
    "        # .tile(2, 2) forms (N, M) -> (2N, 2M) for the 2D vector field\n",
    "        K = (1 / (l1**2 * l2**2)) * blocks * exponent_term.tile(2, 2)\n",
    "\n",
    "        # Add this for Quantile Coverage Error (QCE) calculation\n",
    "        if diag:\n",
    "            # Return only the diagonal as a 1D tensor\n",
    "            return K.diag()\n",
    "\n",
    "        return K\n",
    "\"\"\"\n",
    "\n",
    "class dfRBFKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # register trainable parameter and set initial (raw) lengthscale\n",
    "        # the raw (unconstrained) parameter will later we transformed to enforce the constraint\n",
    "        self.register_parameter(name = \"raw_lengthscale\",\n",
    "                                parameter = torch.nn.Parameter(torch.tensor([0.0, 0.0])))\n",
    "        \n",
    "         # register a constraint to ensure the lengthscale, self.lengthscale, is positive\n",
    "        self.register_constraint(\"raw_lengthscale\", gpytorch.constraints.Positive())\n",
    "        # NOTE: We wrap the output scalar around this base_kernel outside of this class\n",
    "    \n",
    "    # --- Properties for read-access (transforming raw parameters and call kernel.lengthscale) ---\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "    \n",
    "    # --- Setters to allow assigning transformed values rather than raw ---\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self.initialize(raw_lengthscale = self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, row_tensor, column_tensor, diag = False, **params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            row_tensor: torch.Size([N, 2]) first input will correspond to rows in returned K\n",
    "            column_tensor: torch.Size([M, 2]) second input will correspond to columns in returned K\n",
    "            diag: bool, if True, return only the diagonal of the covariance matrix. Needed for Quantile Coverage Error (QCE) calculation.\n",
    "        Returns:\n",
    "            K: torch.Size([2N, 2M]) block format covariance matrix\n",
    "        \"\"\"\n",
    "        # Extract the chosen device\n",
    "        device = row_tensor.device\n",
    "        # l = self.lengthscale.squeeze().to(device)\n",
    "        # Extract both lengthscales\n",
    "        l1, l2 = self.lengthscale[0].to(device), self.lengthscale[1].to(device)\n",
    "\n",
    "        # STEP 1: Pairwise differences of shape [N, M, 2]\n",
    "        # Expand row_tensor [N, 2] -> [N, 1, 2] and column_tensor [M, 2] -> [1, M, 2]\n",
    "        diff = (row_tensor[:, None, :] - column_tensor[None, :, :]).to(device)\n",
    "        # Extract the components (columns) for convenience, matching paper notation\n",
    "        r1 = diff[:, :, 0]\n",
    "        r2 = diff[:, :, 1]\n",
    "\n",
    "        # STEP 2: Block matrix\n",
    "        # Compute the 4 (2x2) block components\n",
    "        upper_left = l2.square() - r2.square()\n",
    "        lower_right = l1.square() - r1.square()\n",
    "        upper_right = r1 * r2\n",
    "        lower_left = upper_right # symmetric\n",
    "\n",
    "        # Assemble the 2x2 block matrix\n",
    "        top = torch.cat((upper_left, upper_right), dim = 1) # Shape: [N, 2M]\n",
    "        bottom = torch.cat((lower_left, lower_right), dim = 1) # Shape: [N, 2M]\n",
    "        blocks = torch.cat((top, bottom), dim = 0) # Shape: [2N, 2M]\n",
    "\n",
    "        # STEP 3: RBF/SE envelope (elementwise)\n",
    "        exponent_term = torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2))  # Shape: [N, M]\n",
    "        \n",
    "        # .tile(2, 2) forms (N, M) -> (2N, 2M) for the 2D vector field\n",
    "        K = (1 / (l1**2 * l2**2)) * blocks * exponent_term.tile(2, 2)\n",
    "\n",
    "        # Add this for Quantile Coverage Error (QCE) calculation\n",
    "        if diag:\n",
    "            # Return only the diagonal as a 1D tensor\n",
    "            return K.diag()\n",
    "\n",
    "        return K\n",
    "\n",
    "class dfNN(gpytorch.means.Mean):\n",
    "    # NOTE: This needs to be initialised of class gpytorch.means.Mean\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        # NOTE: we use the same default dimensionalities as the dfNN NN model\n",
    "        super(dfNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1  # Scalar potential (corresponds to H in HNNs)\n",
    "        \n",
    "        # HACK: SiLu() worked much better than ReLU() for this gradient-based model\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        H = self.net(x)\n",
    "\n",
    "        partials = torch.autograd.grad(\n",
    "                outputs = H.sum(), # we can sum here because every H row only depend on every x row\n",
    "                inputs = x,\n",
    "                create_graph = True\n",
    "            )[0]\n",
    "\n",
    "        # Symplectic gradient\n",
    "        # flip columns (last dim) for x2, x1 order. Multiply x2 by -1\n",
    "        mean_symp = partials.flip(-1) * torch.tensor([1, -1], dtype = torch.float32, device = x.device)\n",
    "\n",
    "        # return symp, H \n",
    "        # # NOTE: return H as well if we want to see what is going on\n",
    "        return mean_symp\n",
    "\n",
    "class dfNGP(gpytorch.models.ExactGP):\n",
    "    # dfGP model with constant mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(dfNGP, self).__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        # Custom mean module\n",
    "        self.mean_module = dfNN(input_dim = 2) # default hidden_dim = 32\n",
    "        # Custom kernel module\n",
    "        self.base_kernel = MultitaskKernelWrapper(\n",
    "            dfRBFKernel(), \n",
    "            num_tasks = 2,\n",
    "            )\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_kernel)\n",
    "\n",
    "        self.covar_module.outputscale = torch.ones(1, device = device) * 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        # print(\"mean_x shape:\", mean_x.shape)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # print(\"covar_x shape:\", covar_x.shape)\n",
    "        \n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84705b2f",
   "metadata": {},
   "source": [
    "# dfGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee4fa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import L_RANGE, SIGMA_F_RANGE, SIGMA_N_RANGE\n",
    "\n",
    "class dfGP(gpytorch.models.ExactGP):\n",
    "    # dfGP model with zero mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ZeroMean(), num_tasks = 2\n",
    "            )\n",
    "\n",
    "        self.base_kernel = MultitaskKernelWrapper(\n",
    "            dfRBFKernel(), \n",
    "            num_tasks = 2,\n",
    "            )\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_kernel)\n",
    "        \n",
    "        # initialize hyperparameters by sampling from a uniform distribution over predefined ranges\n",
    "        self.base_kernel.data_covar_module.lengthscale = torch.empty(2, device = device).uniform_( * L_RANGE)\n",
    "        self.covar_module.outputscale = torch.empty(1, device = device).uniform_( * SIGMA_F_RANGE)\n",
    "        self.likelihood.task_noises = torch.empty(2, device = device).uniform_( * SIGMA_N_RANGE)\n",
    "\n",
    "        # add constraint to likelihood 1e-4 is the default\n",
    "        # self.likelihood.raw_task_noises_constraint = gpytorch.constraints.GreaterThan(1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        print(covar_x.shape)\n",
    "        # NOTE: Assure it is multitask\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20243146",
   "metadata": {},
   "source": [
    "# dfGPcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "410ed9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dfGPcm(gpytorch.models.ExactGP):\n",
    "    # dfGP model with zero mean\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(),\n",
    "            num_tasks = 2\n",
    "            )\n",
    "\n",
    "        self.base_kernel = MultitaskKernelWrapper(\n",
    "            dfRBFKernel(), \n",
    "            num_tasks = 2,\n",
    "            )\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_kernel)\n",
    "\n",
    "        \n",
    "        # initialize hyperparameters by sampling from a uniform distribution over predefined ranges\n",
    "        self.base_kernel.data_covar_module.lengthscale = torch.empty(2, device = device).uniform_( * L_RANGE)\n",
    "        self.covar_module.outputscale = torch.empty(1, device = device).uniform_( * SIGMA_F_RANGE)\n",
    "        self.likelihood.task_noises = torch.empty(2, device = device).uniform_( * SIGMA_N_RANGE)\n",
    "\n",
    "        # add constraint to likelihood 1e-4 is the default\n",
    "        # self.likelihood.raw_task_noises_constraint = gpytorch.constraints.GreaterThan(1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # NOTE: Assure it is multitask\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "12647f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from simulate import (simulate_detailed_curve,)\n",
    "simulations = {\"curve\": simulate_detailed_curve}\n",
    "\n",
    "from utils import make_grid\n",
    "N_SIDE = 20\n",
    "_, x_test = make_grid(N_SIDE)\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised_0to1.pt\", weights_only = False).float()\n",
    "\n",
    "y_train = simulate_detailed_curve(x_train.cpu()).to(device)\n",
    "y_test = simulate_detailed_curve(x_test.cpu()).to(device)\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "x_train = x_train.to(device)\n",
    "\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks = 2).to(device)\n",
    "\n",
    "model = dfGPcm(\n",
    "            x_train,\n",
    "            y_train, \n",
    "            likelihood,\n",
    "            ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "adf2d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstantMean()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mean_module.base_means[0].initialize(constant = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2efa2909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mean_module.base_means[0].constant.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce6fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskMean(\n",
       "  (base_means): ModuleList(\n",
       "    (0-1): 2 x ConstantMean()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mean_module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c6d5ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_task_noises torch.Size([2])\n",
      "raw_noise torch.Size([1])\n",
      "likelihood.raw_task_noises torch.Size([2])\n",
      "likelihood.raw_noise torch.Size([1])\n",
      "base_kernel.data_covar_module.raw_lengthscale torch.Size([2])\n",
      "covar_module.raw_outputscale torch.Size([])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([1192, 1192])\n",
      "covar_x shape inside: torch.Size([800, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([392, 392])\n",
      "covar_x shape inside: torch.Size([392, 392])\n",
      "torch.Size([784, 784])\n",
      "covar_x shape inside: torch.Size([392, 392])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     64\u001b[0m likelihood\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 66\u001b[0m train_pred_dist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m test_pred_dist \u001b[38;5;241m=\u001b[39m model(x_test\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     69\u001b[0m train_RMSE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39msquare(train_pred_dist\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;241m-\u001b[39m y_train)))\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:333\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[1;32m    330\u001b[0m     (\n\u001b[1;32m    331\u001b[0m         predictive_mean,\n\u001b[1;32m    332\u001b[0m         predictive_covar,\n\u001b[0;32m--> 333\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    336\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/gpytorch/models/exact_prediction_strategies.py:321\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    317\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[1;32m    318\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[1;32m    323\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/gpytorch/models/exact_prediction_strategies.py:346\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    344\u001b[0m nan_policy \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mobservation_nan_policy\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 346\u001b[0m     res \u001b[38;5;241m=\u001b[39m (\u001b[43mtest_train_covar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# Restrict train dimension to observed values\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     observed \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mobservation_nan_policy\u001b[38;5;241m.\u001b[39m_get_observed(mean_cache, torch\u001b[38;5;241m.\u001b[39mSize((mean_cache\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],)))\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2905\u001b[0m, in \u001b[0;36mLinearOperator.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__matmul__\u001b[39m(\n\u001b[1;32m   2900\u001b[0m     \u001b[38;5;28mself\u001b[39m: Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch M N\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   2901\u001b[0m     other: Union[\n\u001b[1;32m   2902\u001b[0m         Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch2 N D\u001b[39m\u001b[38;5;124m\"\u001b[39m], Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m], Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*batch2 N D\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2903\u001b[0m     ],\n\u001b[1;32m   2904\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... M D\u001b[39m\u001b[38;5;124m\"\u001b[39m], Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... M\u001b[39m\u001b[38;5;124m\"\u001b[39m], Float[LinearOperator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... M D\u001b[39m\u001b[38;5;124m\"\u001b[39m]]:\n\u001b[0;32m-> 2905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:1839\u001b[0m, in \u001b[0;36mLinearOperator.matmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlinear_operator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatmul_linear_operator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatmulLinearOperator\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatmulLinearOperator(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m-> 1839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatmul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/linear_operator/functions/_matmul.py:20\u001b[0m, in \u001b[0;36mMatmul.forward\u001b[0;34m(ctx, representation_tree, rhs, *matrix_args)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     is_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m linear_op \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmatrix_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m res \u001b[38;5;241m=\u001b[39m linear_op\u001b[38;5;241m.\u001b[39m_matmul(rhs)\n\u001b[1;32m     23\u001b[0m to_save \u001b[38;5;241m=\u001b[39m [orig_rhs] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(matrix_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/linear_operator/operators/linear_operator_representation_tree.py:30\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__call__\u001b[0;34m(self, *flattened_representation)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         sub_representation \u001b[38;5;241m=\u001b[39m flattened_representation[index]\n\u001b[0;32m---> 30\u001b[0m         unflattened_representation\u001b[38;5;241m.\u001b[39mappend(\u001b[43msubtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msub_representation\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_kwarg_names):\n\u001b[1;32m     33\u001b[0m     args \u001b[38;5;241m=\u001b[39m unflattened_representation[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_kwarg_names)]\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/linear_operator/operators/linear_operator_representation_tree.py:42\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__call__\u001b[0;34m(self, *flattened_representation)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cls(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdifferentiable_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nondifferentiable_kwargs)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munflattened_representation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nondifferentiable_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:32\u001b[0m, in \u001b[0;36mdeprecated_lazy_tensor.<locals>.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeprecated_lazy_tensor\u001b[39m(_LinearOperatorClass: \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtype\u001b[39m:\n\u001b[1;32m     30\u001b[0m     __orig_init__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_LinearOperatorClass, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     33\u001b[0m         new_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from simulate import (simulate_detailed_curve,)\n",
    "simulations = {\"curve\": simulate_detailed_curve}\n",
    "\n",
    "from utils import make_grid\n",
    "N_SIDE = 20\n",
    "_, x_test = make_grid(N_SIDE)\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised_0to1.pt\", weights_only = False).float()\n",
    "\n",
    "y_train = simulate_detailed_curve(x_train.cpu()).to(device)\n",
    "y_test = simulate_detailed_curve(x_test.cpu()).to(device)\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "x_train = x_train.to(device)\n",
    "\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks = 2).to(device)\n",
    "\n",
    "model = dfGP(\n",
    "            x_train,\n",
    "            y_train, \n",
    "            likelihood,\n",
    "            ).to(device)\n",
    "\n",
    "for name, param in likelihood.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "# likelihood.raw_task_noises\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "# We can actually set it as such\n",
    "# model.covar_module.outputscale = 0.001\n",
    "# print(model.covar_module.raw_outputscale)\n",
    "# print(model.covar_module.outputscale)\n",
    "\n",
    "# Set to not require grad\n",
    "# model.covar_module.raw_outputscale.requires_grad_(False)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "            # {\"params\": model.mean_module.parameters(), \"weight_decay\": 0.0001, \"lr\": 0.05},\n",
    "            {\"params\": list(model.covar_module.parameters()) + list(model.likelihood.parameters()), \"weight_decay\": 0.001, \"lr\": 0.005},\n",
    "            ])\n",
    "\n",
    "for i in range(300):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_pred_dist = model(x_train.to(device))\n",
    "    # Train on noisy or true targets?\n",
    "    loss = - mll(train_pred_dist, y_train.to(device))  # negative marginal log likelihood\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    train_pred_dist = model(x_train.to(device))\n",
    "    test_pred_dist = model(x_test.to(device))\n",
    "\n",
    "    train_RMSE = torch.sqrt(torch.mean(torch.square(train_pred_dist.mean - y_train)))\n",
    "    test_RMSE = torch.sqrt(torch.mean(torch.square(test_pred_dist.mean - y_test)))\n",
    "    test_mean_module_RMSE = torch.sqrt(torch.mean(torch.square(model.mean_module(x_test.to(device)).detach() - y_test.to(device))))\n",
    "\n",
    "    # print(f\"Epoch {i + 1} Training Loss (NLML): {loss:.4f} Train RMSE: {train_RMSE:.4f} Test RMSE: {test_RMSE:.4f}, Test Mean Module RMSE: {test_mean_module_RMSE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "180c10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.raw_task_noises torch.Size([2]) Parameter containing:\n",
      "tensor([-2.8781, -2.7647], device='cuda:0', requires_grad=True)\n",
      "likelihood.raw_noise torch.Size([1]) Parameter containing:\n",
      "tensor([-0.0020], device='cuda:0', requires_grad=True)\n",
      "base_kernel.data_covar_module.raw_lengthscale torch.Size([2]) Parameter containing:\n",
      "tensor([ 0.0362, -1.0428], device='cuda:0', requires_grad=True)\n",
      "covar_module.raw_outputscale torch.Size([]) Parameter containing:\n",
      "tensor(0.5773, device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3f239ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0548, 0.0612], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.7114, 0.3019], device='cuda:0', grad_fn=<SoftplusBackward0>)\n",
      "tensor(1.0229, device='cuda:0', grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(likelihood.task_noises)\n",
    "# likelihood.noise not used\n",
    "print(model.base_kernel.data_covar_module.lengthscale)\n",
    "print(model.covar_module.outputscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b79e69",
   "metadata": {},
   "source": [
    "# Check x_train covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dfRBFKernel(gpytorch.kernels.Kernel):\n",
    "    # NOTE: This is always for num_task = 2 i.e. 2D vector field\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # register trainable parameter and set initial (raw) lengthscale\n",
    "        # the raw (unconstrained) parameter will later we transformed to enforce the constraint\n",
    "        self.register_parameter(name = \"raw_lengthscale\",\n",
    "                                parameter = torch.nn.Parameter(torch.tensor([0.0, 0.0])))\n",
    "        \n",
    "         # register a constraint to ensure the lengthscale, self.lengthscale, is positive\n",
    "        self.register_constraint(\"raw_lengthscale\", gpytorch.constraints.Positive())\n",
    "        # NOTE: We wrap the output scalar around this base_kernel outside of this class\n",
    "    \n",
    "    # --- Properties for read-access (transforming raw parameters and call kernel.lengthscale) ---\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "    \n",
    "    # --- Setters to allow assigning transformed values rather than raw ---\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self.initialize(raw_lengthscale = self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, row_tensor, column_tensor, diag = False, **params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            row_tensor: torch.Size([N, 2]) first input will correspond to rows in returned K\n",
    "            column_tensor: torch.Size([M, 2]) second input will correspond to columns in returned K\n",
    "            diag: bool, if True, return only the diagonal of the covariance matrix. Needed for Quantile Coverage Error (QCE) calculation.\n",
    "        Returns:\n",
    "            K: torch.Size([2N, 2M]) block format covariance matrix\n",
    "        \"\"\"\n",
    "        # Extract the chosen device\n",
    "        device = row_tensor.device\n",
    "\n",
    "        # Extract both lengthscales\n",
    "        l1, l2 = self.lengthscale[0].to(device), self.lengthscale[1].to(device)\n",
    "\n",
    "        # STEP 1: Pairwise differences of shape [N, M, 2]\n",
    "        # Expand row_tensor [N, 2] -> [N, 1, 2] and column_tensor [M, 2] -> [1, M, 2]\n",
    "        diff = (row_tensor[:, None, :] - column_tensor[None, :, :]).to(device)\n",
    "        # Extract the components (columns) for convenience, matching paper notation\n",
    "        r1 = diff[:, :, 0]\n",
    "        r2 = diff[:, :, 1]\n",
    "\n",
    "        # STEP 2: Block matrix\n",
    "        # Compute the 4 (2x2) block components\n",
    "        upper_left = l2.square() - r2.square()\n",
    "        lower_right = l1.square() - r1.square()\n",
    "        upper_right = r1 * r2\n",
    "        lower_left = upper_right # symmetric\n",
    "\n",
    "        # Assemble the 2x2 block matrix\n",
    "        top = torch.cat((upper_left, upper_right), dim = 1) # Shape: [N, 2M]\n",
    "        bottom = torch.cat((lower_left, lower_right), dim = 1) # Shape: [N, 2M]\n",
    "        blocks = torch.cat((top, bottom), dim = 0) # Shape: [2N, 2M]\n",
    "\n",
    "        # STEP 3: RBF/SE envelope (elementwise)\n",
    "        # diagonal is 1\n",
    "        exponent_term = torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2))  # Shape: [N, M]\n",
    "        \n",
    "        # .tile(2, 2) forms (N, M) -> (2N, 2M) for the 2D vector field\n",
    "        K = (1 / (l1**2 * l2**2)) * blocks * exponent_term.tile(2, 2)\n",
    "\n",
    "        # Add this for Quantile Coverage Error (QCE) calculation\n",
    "        if diag:\n",
    "            # Return only the diagonal as a 1D tensor\n",
    "            return K.diag()\n",
    "\n",
    "        # NOTE: This is the base kernel and not scaled yet\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67c8e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_tensor = x_train \n",
    "column_tensor = x_train\n",
    "\n",
    "diff = (row_tensor[:, None, :] - column_tensor[None, :, :]).to(device)\n",
    "# Extract the components (columns) for convenience, matching paper notation\n",
    "r1 = diff[:, :, 0]\n",
    "r2 = diff[:, :, 1]\n",
    "\n",
    "l1, l2 = model.covar_module.base_kernel.data_covar_module.lengthscale[0].to(device), model.covar_module.base_kernel.data_covar_module.lengthscale[1].to(device)\n",
    "\n",
    "exponent_term = torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2))\n",
    "\n",
    "# diagonal of r2.square() is always 0\n",
    "upper_left = l2.square() - r2.square()\n",
    "lower_right = l1.square() - r1.square()\n",
    "upper_right = r1 * r2\n",
    "lower_left = upper_right # symmetric\n",
    "\n",
    "# Assemble the 2x2 block matrix\n",
    "top = torch.cat((upper_left, upper_right), dim = 1) # Shape: [N, 2M]\n",
    "bottom = torch.cat((lower_left, lower_right), dim = 1) # Shape: [N, 2M]\n",
    "blocks = torch.cat((top, bottom), dim = 0) # Shape: [2N, 2M]\n",
    "\n",
    "# STEP 3: RBF/SE envelope (elementwise)\n",
    "# diagonal is 1\n",
    "exponent_term = torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2))  # Shape: [N, M]\n",
    "\n",
    "K = (1 / (l1**2 * l2**2)) * blocks * exponent_term.tile(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61e33acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(K == K.T).any().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95e21b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0549, device='cuda:0', grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9134ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.0359,      0.0267,      0.0203,      0.0159,      0.0130,\n",
       "             0.0111,      0.0099,      0.0093,      0.0091,      0.0093,\n",
       "             0.0100,      0.0113,      0.0050,      0.0012,     -0.0010,\n",
       "            -0.0021,     -0.0025,     -0.0026,     -0.0024,     -0.0022,\n",
       "            -0.0020,     -0.0018,     -0.0016,     -0.0013,     -0.0008,\n",
       "            -0.0000,      0.0011,      0.0028,      0.0051,      0.0089,\n",
       "             0.0025,     -0.0013,     -0.0032,     -0.0040,     -0.0040,\n",
       "            -0.0037,     -0.0034,     -0.0030,     -0.0028,     -0.0028,\n",
       "            -0.0028,     -0.0028,     -0.0028,     -0.0026,     -0.0022,\n",
       "            -0.0016,     -0.0006,      0.0010,      0.0032,      0.0065,\n",
       "             0.0089,      0.0019,     -0.0021,     -0.0039,     -0.0043,\n",
       "            -0.0040,     -0.0032,     -0.0025,     -0.0018,     -0.0014,\n",
       "            -0.0013,     -0.0014,     -0.0016,     -0.0018,     -0.0021,\n",
       "            -0.0024,     -0.0026,     -0.0027,     -0.0027,     -0.0027,\n",
       "            -0.0024,     -0.0019,     -0.0009,      0.0009,      0.0038,\n",
       "             0.0085,      0.0157,      0.0260,      0.0405,      0.0601,\n",
       "             0.0859,      0.0051,      0.0017,     -0.0004,     -0.0017,\n",
       "            -0.0024,     -0.0026,     -0.0026,     -0.0023,     -0.0018,\n",
       "            -0.0012,     -0.0006,      0.0002,      0.0009,      0.0017,\n",
       "             0.0024,      0.0031,      0.0037,      0.0043,      0.0048,\n",
       "             0.0054,      0.0062,      0.0073,      0.0091,      0.0119,\n",
       "             0.0163,      0.0227,      0.0320,      0.0450,      0.0624,\n",
       "             0.0094,      0.0063,      0.0042,      0.0030,      0.0025,\n",
       "             0.0027,      0.0035,      0.0048,      0.0066,      0.0090,\n",
       "             0.0120,      0.0157,      0.0200,      0.0252,      0.0314,\n",
       "             0.0386,      0.0473,      0.0206,      0.0098,      0.0031,\n",
       "            -0.0002,     -0.0013,     -0.0007,      0.0008,      0.0028,\n",
       "             0.0050,      0.0071,      0.0091,      0.0109,      0.0125,\n",
       "             0.0138,      0.0149,      0.0158,      0.0164,      0.0168,\n",
       "             0.0167,      0.0164,      0.0157,      0.0148,      0.0138,\n",
       "             0.0131,      0.0132,      0.0146,      0.0183,      0.0252,\n",
       "             0.0364,      0.0530,      0.0218,      0.0138,      0.0080,\n",
       "             0.0039,      0.0010,     -0.0008,     -0.0020,     -0.0026,\n",
       "            -0.0028,     -0.0028,     -0.0027,     -0.0024,     -0.0020,\n",
       "            -0.0016,     -0.0010,     -0.0003,      0.0008,      0.0023,\n",
       "             0.0045,      0.0077,      0.0123,      0.0188,      0.0277,\n",
       "             0.0398,      0.0097,      0.0084,      0.0075,      0.0071,\n",
       "             0.0070,      0.0072,      0.0077,      0.0087,      0.0104,\n",
       "             0.0128,      0.0165,      0.0218,      0.0293,      0.0398,\n",
       "             0.0540,      0.0204,      0.0190,      0.0180,      0.0174,\n",
       "             0.0173,      0.0175,      0.0183,      0.0196,      0.0215,\n",
       "             0.0243,      0.0280,      0.0059,      0.0049,      0.0040,\n",
       "             0.0034,      0.0028,      0.0024,      0.0020,      0.0018,\n",
       "             0.0017,      0.0017,      0.0019,      0.0024,      0.0033,\n",
       "             0.0047,      0.0067,      0.0097,      0.0139,      0.0195,\n",
       "             0.0054,      0.0044,      0.0036,      0.0029,      0.0023,\n",
       "             0.0018,      0.0014,      0.0010,      0.0007,      0.0004,\n",
       "             0.0002,      0.0000,     -0.0000,      0.0002,      0.0006,\n",
       "             0.0014,      0.0029,      0.0051,      0.0084,      0.0132,\n",
       "             0.0199,      0.0058,      0.0049,      0.0041,      0.0035,\n",
       "             0.0030,      0.0026,      0.0022,      0.0019,      0.0016,\n",
       "             0.0013,      0.0012,      0.0010,      0.0009,      0.0008,\n",
       "             0.0007,      0.0006,      0.0006,      0.0006,      0.0007,\n",
       "             0.0010,      0.0014,      0.0022,      0.0034,      0.0052,\n",
       "             0.0080,      0.0119,      0.0172,      0.0244,      0.0338,\n",
       "             0.0459,      0.0610,      0.0195,      0.0107,      0.0052,\n",
       "             0.0022,      0.0010,      0.0008,      0.0013,      0.0021,\n",
       "             0.0029,      0.0038,      0.0047,      0.0055,      0.0065,\n",
       "             0.0075,      0.0086,      0.0097,      0.0108,      0.0117,\n",
       "             0.0125,      0.0130,      0.0132,      0.0134,      0.0138,\n",
       "             0.0148,      0.0171,      0.0216,      0.0292,      0.0410,\n",
       "             0.0583,      0.0225,      0.0148,      0.0101,      0.0075,\n",
       "             0.0065,      0.0064,      0.0068,      0.0075,      0.0083,\n",
       "             0.0092,      0.0101,      0.0112,      0.0124,      0.0138,\n",
       "             0.0154,      0.0172,      0.0192,      0.0097,      0.0086,\n",
       "             0.0077,      0.0071,      0.0067,      0.0063,      0.0060,\n",
       "             0.0058,      0.0056,      0.0054,      0.0053,      0.0053,\n",
       "             0.0054,      0.0055,      0.0058,      0.0061,      0.0066,\n",
       "             0.0072,      0.0080,      0.0090,      0.0102,      0.0116,\n",
       "             0.0133,      0.0154,      0.0180,      0.0211,      0.0250,\n",
       "             0.0297,      0.0356,      0.0427,      0.0109,      0.0076,\n",
       "             0.0056,      0.0045,      0.0041,      0.0040,      0.0041,\n",
       "             0.0044,      0.0048,      0.0052,      0.0056,      0.0059,\n",
       "             0.0062,      0.0065,      0.0068,      0.0074,      0.0085,\n",
       "             0.0104,      0.0137,      0.0191,      0.0273,      0.0395,\n",
       "             0.0566,      0.0797,      0.0062,      0.0065,      0.0069,\n",
       "             0.0073,      0.0078,      0.0084,      0.0091,      0.0103,\n",
       "             0.0123,      0.0155,      0.0207,      0.0287,      0.0405,\n",
       "             0.0575,      0.0807], device='cuda:0',\n",
       "       grad_fn=<DiagonalBackward0>)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_dist.covariance_matrix.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c4a5e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_task_noises torch.Size([2]) Parameter containing:\n",
      "tensor([-3.0022, -2.8665], device='cuda:0', requires_grad=True)\n",
      "raw_noise torch.Size([1]) Parameter containing:\n",
      "tensor([-0.0035], device='cuda:0', requires_grad=True)\n",
      "likelihood.raw_task_noises torch.Size([2]) Parameter containing:\n",
      "tensor([-3.0022, -2.8665], device='cuda:0', requires_grad=True)\n",
      "likelihood.raw_noise torch.Size([1]) Parameter containing:\n",
      "tensor([-0.0035], device='cuda:0', requires_grad=True)\n",
      "base_kernel.data_covar_module.raw_lengthscale torch.Size([2]) Parameter containing:\n",
      "tensor([-0.1848,  0.1207], device='cuda:0', requires_grad=True)\n",
      "covar_module.raw_outputscale torch.Size([]) Parameter containing:\n",
      "tensor(0.9780, device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in likelihood.named_parameters():\n",
    "    print(name, param.shape, param)\n",
    "\n",
    "# likelihood.raw_task_noises\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "99eeccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2972, device='cuda:0', grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, device='cuda:0', grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood.eval()\n",
    "likelihood.raw_task_noises\n",
    "likelihood.task_noises\n",
    "\n",
    "model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "248bd0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from visualise import visualise_v_quiver\n",
    "\n",
    "mean_model_out = model.mean_module(x_test.to(device)).detach()\n",
    "\n",
    "visualise_v_quiver(\n",
    "    test_pred_dist.mean,\n",
    "    x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1acedb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood(test_pred_dist).mean - test_pred_dist.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4a60cba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7644, 0.7659],\n",
       "        [0.7662, 0.7651],\n",
       "        [0.7627, 0.7591],\n",
       "        [0.7542, 0.7480],\n",
       "        [0.7406, 0.7320],\n",
       "        [0.7222, 0.7113],\n",
       "        [0.6994, 0.6864],\n",
       "        [0.6724, 0.6576],\n",
       "        [0.6419, 0.6254],\n",
       "        [0.6083, 0.5905],\n",
       "        [0.7789, 0.7809],\n",
       "        [0.7816, 0.7809],\n",
       "        [0.7789, 0.7755],\n",
       "        [0.7708, 0.7647],\n",
       "        [0.7574, 0.7488],\n",
       "        [0.7390, 0.7280],\n",
       "        [0.7158, 0.7026],\n",
       "        [0.6884, 0.6732],\n",
       "        [0.6571, 0.6402],\n",
       "        [0.6226, 0.6043],\n",
       "        [0.7907, 0.7932],\n",
       "        [0.7942, 0.7939],\n",
       "        [0.7922, 0.7890],\n",
       "        [0.7845, 0.7786],\n",
       "        [0.7714, 0.7628],\n",
       "        [0.7529, 0.7418],\n",
       "        [0.7295, 0.7161],\n",
       "        [0.7016, 0.6861],\n",
       "        [0.6697, 0.6524],\n",
       "        [0.6343, 0.6155],\n",
       "        [0.7998, 0.8026],\n",
       "        [0.8041, 0.8041],\n",
       "        [0.8026, 0.7997],\n",
       "        [0.7954, 0.7896],\n",
       "        [0.7824, 0.7739],\n",
       "        [0.7640, 0.7529],\n",
       "        [0.7404, 0.7268],\n",
       "        [0.7121, 0.6963],\n",
       "        [0.6796, 0.6619],\n",
       "        [0.6434, 0.6242],\n",
       "        [0.8060, 0.8092],\n",
       "        [0.8110, 0.8114],\n",
       "        [0.8102, 0.8075],\n",
       "        [0.8034, 0.7977],\n",
       "        [0.7907, 0.7822],\n",
       "        [0.7723, 0.7611],\n",
       "        [0.7485, 0.7348],\n",
       "        [0.7199, 0.7039],\n",
       "        [0.6869, 0.6689],\n",
       "        [0.6501, 0.6305],\n",
       "        [0.8093, 0.8130],\n",
       "        [0.8151, 0.8158],\n",
       "        [0.8148, 0.8124],\n",
       "        [0.8085, 0.8030],\n",
       "        [0.7960, 0.7876],\n",
       "        [0.7777, 0.7665],\n",
       "        [0.7539, 0.7400],\n",
       "        [0.7250, 0.7088],\n",
       "        [0.6915, 0.6733],\n",
       "        [0.6542, 0.6343],\n",
       "        [0.8099, 0.8139],\n",
       "        [0.8163, 0.8173],\n",
       "        [0.8166, 0.8144],\n",
       "        [0.8107, 0.8053],\n",
       "        [0.7985, 0.7901],\n",
       "        [0.7803, 0.7691],\n",
       "        [0.7565, 0.7426],\n",
       "        [0.7274, 0.7111],\n",
       "        [0.6937, 0.6753],\n",
       "        [0.6559, 0.6358],\n",
       "        [0.8076, 0.8119],\n",
       "        [0.8147, 0.8159],\n",
       "        [0.8155, 0.8136],\n",
       "        [0.8100, 0.8049],\n",
       "        [0.7982, 0.7899],\n",
       "        [0.7802, 0.7690],\n",
       "        [0.7564, 0.7425],\n",
       "        [0.7273, 0.7109],\n",
       "        [0.6934, 0.6748],\n",
       "        [0.6553, 0.6350],\n",
       "        [0.8025, 0.8071],\n",
       "        [0.8102, 0.8117],\n",
       "        [0.8116, 0.8099],\n",
       "        [0.8066, 0.8016],\n",
       "        [0.7951, 0.7870],\n",
       "        [0.7774, 0.7663],\n",
       "        [0.7537, 0.7398],\n",
       "        [0.7247, 0.7082],\n",
       "        [0.6907, 0.6721],\n",
       "        [0.6525, 0.6321],\n",
       "        [0.7946, 0.7996],\n",
       "        [0.8030, 0.8048],\n",
       "        [0.8049, 0.8035],\n",
       "        [0.8004, 0.7957],\n",
       "        [0.7893, 0.7814],\n",
       "        [0.7719, 0.7610],\n",
       "        [0.7486, 0.7348],\n",
       "        [0.7196, 0.7033],\n",
       "        [0.6858, 0.6672],\n",
       "        [0.6476, 0.6271],\n",
       "        [0.7841, 0.7893],\n",
       "        [0.7930, 0.7951],\n",
       "        [0.7956, 0.7944],\n",
       "        [0.7915, 0.7870],\n",
       "        [0.7809, 0.7732],\n",
       "        [0.7640, 0.7532],\n",
       "        [0.7409, 0.7273],\n",
       "        [0.7123, 0.6961],\n",
       "        [0.6787, 0.6602],\n",
       "        [0.6407, 0.6203],\n",
       "        [0.7709, 0.7764],\n",
       "        [0.7804, 0.7828],\n",
       "        [0.7835, 0.7826],\n",
       "        [0.7801, 0.7759],\n",
       "        [0.7700, 0.7626],\n",
       "        [0.7536, 0.7430],\n",
       "        [0.7310, 0.7176],\n",
       "        [0.7028, 0.6868],\n",
       "        [0.6695, 0.6512],\n",
       "        [0.6318, 0.6116],\n",
       "        [0.7551, 0.7609],\n",
       "        [0.7652, 0.7679],\n",
       "        [0.7690, 0.7684],\n",
       "        [0.7661, 0.7622],\n",
       "        [0.7567, 0.7496],\n",
       "        [0.7409, 0.7306],\n",
       "        [0.7189, 0.7057],\n",
       "        [0.6912, 0.6754],\n",
       "        [0.6585, 0.6404],\n",
       "        [0.6213, 0.6013],\n",
       "        [0.7368, 0.7430],\n",
       "        [0.7476, 0.7506],\n",
       "        [0.7520, 0.7517],\n",
       "        [0.7498, 0.7463],\n",
       "        [0.7411, 0.7343],\n",
       "        [0.7259, 0.7161],\n",
       "        [0.7047, 0.6919],\n",
       "        [0.6777, 0.6623],\n",
       "        [0.6456, 0.6279],\n",
       "        [0.6091, 0.5894],\n",
       "        [0.7162, 0.7227],\n",
       "        [0.7276, 0.7309],\n",
       "        [0.7326, 0.7327],\n",
       "        [0.7312, 0.7281],\n",
       "        [0.7233, 0.7169],\n",
       "        [0.7090, 0.6995],\n",
       "        [0.6885, 0.6761],\n",
       "        [0.6624, 0.6474],\n",
       "        [0.6312, 0.6138],\n",
       "        [0.5955, 0.5762],\n",
       "        [0.6933, 0.7001],\n",
       "        [0.7053, 0.7090],\n",
       "        [0.7111, 0.7116],\n",
       "        [0.7105, 0.7077],\n",
       "        [0.7034, 0.6975],\n",
       "        [0.6900, 0.6810],\n",
       "        [0.6705, 0.6587],\n",
       "        [0.6454, 0.6309],\n",
       "        [0.6152, 0.5983],\n",
       "        [0.5805, 0.5617],\n",
       "        [0.6683, 0.6754],\n",
       "        [0.6809, 0.6850],\n",
       "        [0.6875, 0.6884],\n",
       "        [0.6877, 0.6855],\n",
       "        [0.6816, 0.6762],\n",
       "        [0.6693, 0.6608],\n",
       "        [0.6509, 0.6396],\n",
       "        [0.6269, 0.6129],\n",
       "        [0.5978, 0.5815],\n",
       "        [0.5643, 0.5461],\n",
       "        [0.6413, 0.6486],\n",
       "        [0.6546, 0.6590],\n",
       "        [0.6619, 0.6633],\n",
       "        [0.6631, 0.6614],\n",
       "        [0.6581, 0.6532],\n",
       "        [0.6468, 0.6390],\n",
       "        [0.6297, 0.6190],\n",
       "        [0.6070, 0.5937],\n",
       "        [0.5792, 0.5636],\n",
       "        [0.5470, 0.5295],\n",
       "        [0.6124, 0.6201],\n",
       "        [0.6263, 0.6312],\n",
       "        [0.6346, 0.6364],\n",
       "        [0.6368, 0.6356],\n",
       "        [0.6328, 0.6286],\n",
       "        [0.6229, 0.6157],\n",
       "        [0.6071, 0.5971],\n",
       "        [0.5858, 0.5732],\n",
       "        [0.5595, 0.5446],\n",
       "        [0.5288, 0.5120],\n",
       "        [0.5817, 0.5898],\n",
       "        [0.5964, 0.6017],\n",
       "        [0.6055, 0.6079],\n",
       "        [0.6088, 0.6082],\n",
       "        [0.6061, 0.6026],\n",
       "        [0.5975, 0.5911],\n",
       "        [0.5832, 0.5740],\n",
       "        [0.5635, 0.5517],\n",
       "        [0.5388, 0.5248],\n",
       "        [0.5098, 0.4938],\n",
       "        [0.8126, 0.8084],\n",
       "        [0.8002, 0.7881],\n",
       "        [0.7722, 0.7525],\n",
       "        [0.7292, 0.7024],\n",
       "        [0.6724, 0.6394],\n",
       "        [0.6035, 0.5652],\n",
       "        [0.5245, 0.4819],\n",
       "        [0.4377, 0.3921],\n",
       "        [0.3454, 0.2981],\n",
       "        [0.2503, 0.2025],\n",
       "        [0.8102, 0.8073],\n",
       "        [0.8004, 0.7897],\n",
       "        [0.7750, 0.7566],\n",
       "        [0.7346, 0.7091],\n",
       "        [0.6804, 0.6486],\n",
       "        [0.6139, 0.5767],\n",
       "        [0.5371, 0.4955],\n",
       "        [0.4522, 0.4075],\n",
       "        [0.3617, 0.3151],\n",
       "        [0.2681, 0.2209],\n",
       "        [0.8073, 0.8058],\n",
       "        [0.8003, 0.7909],\n",
       "        [0.7776, 0.7606],\n",
       "        [0.7399, 0.7158],\n",
       "        [0.6883, 0.6578],\n",
       "        [0.6244, 0.5883],\n",
       "        [0.5499, 0.5094],\n",
       "        [0.4671, 0.4234],\n",
       "        [0.3784, 0.3326],\n",
       "        [0.2863, 0.2397],\n",
       "        [0.8040, 0.8038],\n",
       "        [0.7997, 0.7917],\n",
       "        [0.7799, 0.7643],\n",
       "        [0.7451, 0.7223],\n",
       "        [0.6962, 0.6670],\n",
       "        [0.6349, 0.6001],\n",
       "        [0.5628, 0.5235],\n",
       "        [0.4822, 0.4395],\n",
       "        [0.3955, 0.3505],\n",
       "        [0.3050, 0.2591],\n",
       "        [0.8002, 0.8015],\n",
       "        [0.7988, 0.7923],\n",
       "        [0.7820, 0.7678],\n",
       "        [0.7500, 0.7287],\n",
       "        [0.7041, 0.6762],\n",
       "        [0.6454, 0.6119],\n",
       "        [0.5759, 0.5377],\n",
       "        [0.4976, 0.4559],\n",
       "        [0.4128, 0.3688],\n",
       "        [0.3240, 0.2788],\n",
       "        [0.7960, 0.7987],\n",
       "        [0.7976, 0.7926],\n",
       "        [0.7837, 0.7711],\n",
       "        [0.7548, 0.7350],\n",
       "        [0.7118, 0.6854],\n",
       "        [0.6560, 0.6238],\n",
       "        [0.5891, 0.5521],\n",
       "        [0.5132, 0.4725],\n",
       "        [0.4305, 0.3873],\n",
       "        [0.3434, 0.2990],\n",
       "        [0.7914, 0.7957],\n",
       "        [0.7961, 0.7926],\n",
       "        [0.7853, 0.7742],\n",
       "        [0.7595, 0.7412],\n",
       "        [0.7195, 0.6945],\n",
       "        [0.6665, 0.6357],\n",
       "        [0.6023, 0.5666],\n",
       "        [0.5289, 0.4893],\n",
       "        [0.4483, 0.4061],\n",
       "        [0.3630, 0.3194],\n",
       "        [0.7865, 0.7923],\n",
       "        [0.7942, 0.7923],\n",
       "        [0.7866, 0.7771],\n",
       "        [0.7639, 0.7472],\n",
       "        [0.7270, 0.7036],\n",
       "        [0.6770, 0.6477],\n",
       "        [0.6156, 0.5812],\n",
       "        [0.5447, 0.5063],\n",
       "        [0.4663, 0.4251],\n",
       "        [0.3829, 0.3400],\n",
       "        [0.7812, 0.7885],\n",
       "        [0.7921, 0.7917],\n",
       "        [0.7876, 0.7797],\n",
       "        [0.7682, 0.7530],\n",
       "        [0.7344, 0.7125],\n",
       "        [0.6875, 0.6595],\n",
       "        [0.6289, 0.5958],\n",
       "        [0.5605, 0.5233],\n",
       "        [0.4844, 0.4442],\n",
       "        [0.4029, 0.3608],\n",
       "        [0.7757, 0.7845],\n",
       "        [0.7896, 0.7909],\n",
       "        [0.7884, 0.7822],\n",
       "        [0.7722, 0.7587],\n",
       "        [0.7416, 0.7213],\n",
       "        [0.6978, 0.6713],\n",
       "        [0.6420, 0.6103],\n",
       "        [0.5763, 0.5402],\n",
       "        [0.5025, 0.4633],\n",
       "        [0.4229, 0.3816],\n",
       "        [0.7698, 0.7802],\n",
       "        [0.7869, 0.7898],\n",
       "        [0.7889, 0.7843],\n",
       "        [0.7760, 0.7641],\n",
       "        [0.7487, 0.7299],\n",
       "        [0.7079, 0.6829],\n",
       "        [0.6551, 0.6247],\n",
       "        [0.5920, 0.5571],\n",
       "        [0.5205, 0.4823],\n",
       "        [0.4429, 0.4025],\n",
       "        [0.7636, 0.7756],\n",
       "        [0.7838, 0.7884],\n",
       "        [0.7891, 0.7862],\n",
       "        [0.7795, 0.7692],\n",
       "        [0.7554, 0.7383],\n",
       "        [0.7178, 0.6943],\n",
       "        [0.6679, 0.6389],\n",
       "        [0.6075, 0.5739],\n",
       "        [0.5384, 0.5013],\n",
       "        [0.4628, 0.4232],\n",
       "        [0.7571, 0.7706],\n",
       "        [0.7805, 0.7867],\n",
       "        [0.7891, 0.7878],\n",
       "        [0.7828, 0.7741],\n",
       "        [0.7619, 0.7463],\n",
       "        [0.7275, 0.7055],\n",
       "        [0.6805, 0.6529],\n",
       "        [0.6228, 0.5904],\n",
       "        [0.5561, 0.5200],\n",
       "        [0.4825, 0.4438],\n",
       "        [0.7503, 0.7654],\n",
       "        [0.7768, 0.7846],\n",
       "        [0.7887, 0.7890],\n",
       "        [0.7857, 0.7787],\n",
       "        [0.7681, 0.7541],\n",
       "        [0.7368, 0.7163],\n",
       "        [0.6928, 0.6666],\n",
       "        [0.6378, 0.6067],\n",
       "        [0.5735, 0.5385],\n",
       "        [0.5019, 0.4641],\n",
       "        [0.7433, 0.7599],\n",
       "        [0.7729, 0.7823],\n",
       "        [0.7879, 0.7899],\n",
       "        [0.7882, 0.7828],\n",
       "        [0.7739, 0.7615],\n",
       "        [0.7457, 0.7267],\n",
       "        [0.7047, 0.6799],\n",
       "        [0.6524, 0.6225],\n",
       "        [0.5905, 0.5565],\n",
       "        [0.5210, 0.4840],\n",
       "        [0.7359, 0.7540],\n",
       "        [0.7686, 0.7795],\n",
       "        [0.7868, 0.7904],\n",
       "        [0.7903, 0.7866],\n",
       "        [0.7792, 0.7684],\n",
       "        [0.7542, 0.7367],\n",
       "        [0.7162, 0.6927],\n",
       "        [0.6665, 0.6379],\n",
       "        [0.6070, 0.5742],\n",
       "        [0.5396, 0.5035],\n",
       "        [0.7283, 0.7479],\n",
       "        [0.7640, 0.7765],\n",
       "        [0.7853, 0.7905],\n",
       "        [0.7920, 0.7899],\n",
       "        [0.7841, 0.7749],\n",
       "        [0.7622, 0.7462],\n",
       "        [0.7271, 0.7050],\n",
       "        [0.6802, 0.6528],\n",
       "        [0.6230, 0.5912],\n",
       "        [0.5576, 0.5224],\n",
       "        [0.7204, 0.7414],\n",
       "        [0.7590, 0.7730],\n",
       "        [0.7834, 0.7902],\n",
       "        [0.7932, 0.7927],\n",
       "        [0.7885, 0.7808],\n",
       "        [0.7696, 0.7551],\n",
       "        [0.7374, 0.7167],\n",
       "        [0.6932, 0.6670],\n",
       "        [0.6384, 0.6077],\n",
       "        [0.5751, 0.5407],\n",
       "        [0.7122, 0.7346],\n",
       "        [0.7536, 0.7691],\n",
       "        [0.7810, 0.7893],\n",
       "        [0.7939, 0.7949],\n",
       "        [0.7923, 0.7861],\n",
       "        [0.7764, 0.7633],\n",
       "        [0.7471, 0.7277],\n",
       "        [0.7055, 0.6805],\n",
       "        [0.6531, 0.6235],\n",
       "        [0.5918, 0.5583],\n",
       "        [0.7037, 0.7274],\n",
       "        [0.7478, 0.7648],\n",
       "        [0.7782, 0.7879],\n",
       "        [0.7941, 0.7966],\n",
       "        [0.7954, 0.7907],\n",
       "        [0.7825, 0.7709],\n",
       "        [0.7560, 0.7380],\n",
       "        [0.7170, 0.6933],\n",
       "        [0.6670, 0.6384],\n",
       "        [0.6077, 0.5751]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_dist.mean - mean_model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "143159ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.7644,      1.9055],\n",
       "        [     0.5802,      0.0026],\n",
       "        [     0.8037,      1.8130],\n",
       "        [     0.7528,      0.1417],\n",
       "        [     0.7647,      2.0711],\n",
       "        [     0.8023,      0.6639],\n",
       "        [     0.7512,      2.4637],\n",
       "        [     0.8062,      0.9762],\n",
       "        [     0.8091,      2.4176],\n",
       "        [     0.6901,      0.9267],\n",
       "        [     0.8289,      2.1596],\n",
       "        [     0.4711,      0.8379],\n",
       "        [     0.7856,      1.9160],\n",
       "        [     0.2825,      0.8057],\n",
       "        [     0.6993,      1.7157],\n",
       "        [     0.1883,      0.8185],\n",
       "        [     0.5814,      1.5591],\n",
       "        [     0.1468,      0.8689],\n",
       "        [     0.4246,      1.4624],\n",
       "        [     0.0880,      0.9589],\n",
       "        [     0.3032,      1.8953],\n",
       "        [     0.1624,      1.3340],\n",
       "        [     0.2863,      1.5895],\n",
       "        [     0.2196,      1.2484],\n",
       "        [     0.2588,      1.6623],\n",
       "        [     0.2735,      1.4566],\n",
       "        [     0.3149,      1.8483],\n",
       "        [     0.4094,      1.4189],\n",
       "        [     0.4488,      1.6914],\n",
       "        [     0.5428,      1.0560],\n",
       "        [     0.5674,      1.4018],\n",
       "        [     0.6184,      0.6615],\n",
       "        [     0.6531,      1.1736],\n",
       "        [     0.6304,      0.3444],\n",
       "        [     0.7031,      1.0336],\n",
       "        [     0.5669,      0.1206],\n",
       "        [     0.7037,      0.9790],\n",
       "        [     0.4109,     -0.0008],\n",
       "        [     0.6436,      1.0107],\n",
       "        [     0.1627,     -0.0215],\n",
       "        [     0.6600,      1.7464],\n",
       "        [     0.1101,     -0.1110],\n",
       "        [     0.5821,      1.6754],\n",
       "        [     0.1563,      0.0545],\n",
       "        [     0.5399,      1.9556],\n",
       "        [     0.2192,      0.5060],\n",
       "        [     0.6333,      2.2830],\n",
       "        [     0.3077,      0.7642],\n",
       "        [     0.8068,      2.2832],\n",
       "        [     0.3159,      0.7705],\n",
       "        [     0.9406,      2.1322],\n",
       "        [     0.2551,      0.7580],\n",
       "        [     0.9969,      1.9988],\n",
       "        [     0.2056,      0.8086],\n",
       "        [     0.9696,      1.9148],\n",
       "        [     0.1876,      0.9194],\n",
       "        [     0.8562,      1.8804],\n",
       "        [     0.1610,      1.0759],\n",
       "        [     0.6654,      1.8911],\n",
       "        [     0.0955,      1.2485],\n",
       "        [     0.3825,      2.2643],\n",
       "        [    -0.0209,      1.5285],\n",
       "        [     0.2134,      1.9463],\n",
       "        [    -0.0485,      1.4188],\n",
       "        [     0.1217,      1.9233],\n",
       "        [     0.0218,      1.4811],\n",
       "        [     0.1943,      1.9434],\n",
       "        [     0.2087,      1.3392],\n",
       "        [     0.3631,      1.7359],\n",
       "        [     0.3978,      0.9741],\n",
       "        [     0.5302,      1.4563],\n",
       "        [     0.5278,      0.6045],\n",
       "        [     0.6656,      1.2584],\n",
       "        [     0.5768,      0.3338],\n",
       "        [     0.7498,      1.1748],\n",
       "        [     0.5232,      0.1818],\n",
       "        [     0.7644,      1.1965],\n",
       "        [     0.3602,      0.1395],\n",
       "        [     0.7147,      1.2945],\n",
       "        [     0.1185,      0.1674],\n",
       "        [     0.7561,      1.6425],\n",
       "        [     0.0114,     -0.0552],\n",
       "        [     0.6593,      1.4601],\n",
       "        [     0.0276,      0.0047],\n",
       "        [     0.6478,      1.5845],\n",
       "        [     0.1120,      0.2712],\n",
       "        [     0.7905,      1.7757],\n",
       "        [     0.2337,      0.4399],\n",
       "        [     0.9895,      1.8034],\n",
       "        [     0.2866,      0.4757],\n",
       "        [     1.1295,      1.7672],\n",
       "        [     0.2781,      0.5330],\n",
       "        [     1.1791,      1.7869],\n",
       "        [     0.2673,      0.6835],\n",
       "        [     1.1363,      1.8865],\n",
       "        [     0.2658,      0.9209],\n",
       "        [     1.0063,      2.0427],\n",
       "        [     0.2505,      1.2010],\n",
       "        [     0.8157,      2.2047],\n",
       "        [     0.2167,      1.4528],\n",
       "        [     0.4610,      2.6557],\n",
       "        [     0.0089,      1.7568],\n",
       "        [     0.2492,      2.3392],\n",
       "        [    -0.0330,      1.5863],\n",
       "        [     0.1481,      2.1872],\n",
       "        [     0.0457,      1.4875],\n",
       "        [     0.2206,      2.0526],\n",
       "        [     0.2301,      1.2605],\n",
       "        [     0.3822,      1.8026],\n",
       "        [     0.4032,      0.9019],\n",
       "        [     0.5357,      1.5332],\n",
       "        [     0.5031,      0.5621],\n",
       "        [     0.6522,      1.3647],\n",
       "        [     0.5161,      0.3391],\n",
       "        [     0.7216,      1.3346],\n",
       "        [     0.4362,      0.2526],\n",
       "        [     0.7387,      1.4188],\n",
       "        [     0.2755,      0.2657],\n",
       "        [     0.7205,      1.5528],\n",
       "        [     0.0742,      0.3083],\n",
       "        [     0.7234,      1.7988],\n",
       "        [    -0.1225,      0.1664],\n",
       "        [     0.6559,      1.4055],\n",
       "        [    -0.0868,      0.0626],\n",
       "        [     0.6810,      1.2232],\n",
       "        [     0.0208,      0.0933],\n",
       "        [     0.8416,      1.1591],\n",
       "        [     0.1658,      0.1322],\n",
       "        [     1.0402,      1.1121],\n",
       "        [     0.2535,      0.1590],\n",
       "        [     1.1639,      1.1203],\n",
       "        [     0.2735,      0.2550],\n",
       "        [     1.1827,      1.2515],\n",
       "        [     0.2722,      0.4737],\n",
       "        [     1.1111,      1.5164],\n",
       "        [     0.2738,      0.8024],\n",
       "        [     0.9752,      1.8621],\n",
       "        [     0.2787,      1.1700],\n",
       "        [     0.8123,      2.1933],\n",
       "        [     0.2889,      1.4825],\n",
       "        [     0.3350,      2.8394],\n",
       "        [    -0.0623,      1.8903],\n",
       "        [     0.1317,      2.5863],\n",
       "        [    -0.0969,      1.6751],\n",
       "        [     0.0390,      2.3698],\n",
       "        [    -0.0250,      1.4592],\n",
       "        [     0.1062,      2.1457],\n",
       "        [     0.1424,      1.1824],\n",
       "        [     0.2690,      1.8896],\n",
       "        [     0.3042,      0.8582],\n",
       "        [     0.4271,      1.6577],\n",
       "        [     0.3830,      0.5703],\n",
       "        [     0.5342,      1.5277],\n",
       "        [     0.3619,      0.3937],\n",
       "        [     0.5877,      1.5337],\n",
       "        [     0.2567,      0.3444],\n",
       "        [     0.6036,      1.6425],\n",
       "        [     0.1014,      0.3711],\n",
       "        [     0.6077,      1.7750],\n",
       "        [    -0.0643,      0.3997],\n",
       "        [     0.5068,      2.2457],\n",
       "        [    -0.4240,      0.4625],\n",
       "        [     0.4566,      1.7514],\n",
       "        [    -0.3747,      0.2554],\n",
       "        [     0.4891,      1.3047],\n",
       "        [    -0.2643,      0.0906],\n",
       "        [     0.6347,      0.9311],\n",
       "        [    -0.1027,     -0.0224],\n",
       "        [     0.8318,      0.6696],\n",
       "        [     0.0454,     -0.0511],\n",
       "        [     0.9760,      0.5680],\n",
       "        [     0.1362,      0.0418],\n",
       "        [     1.0096,      0.6592],\n",
       "        [     0.1772,      0.2739],\n",
       "        [     0.9407,      0.9380],\n",
       "        [     0.1968,      0.6185],\n",
       "        [     0.8131,      1.3402],\n",
       "        [     0.2183,      0.9968],\n",
       "        [     0.6747,      1.7617],\n",
       "        [     0.2513,      1.3234],\n",
       "        [     0.1128,      2.6486],\n",
       "        [    -0.2268,      1.8688],\n",
       "        [    -0.1176,      2.5009],\n",
       "        [    -0.3018,      1.6281],\n",
       "        [    -0.2430,      2.3184],\n",
       "        [    -0.2891,      1.3462],\n",
       "        [    -0.2218,      2.0963],\n",
       "        [    -0.1781,      1.0415],\n",
       "        [    -0.0738,      1.8820],\n",
       "        [    -0.0240,      0.7666],\n",
       "        [     0.1213,      1.7343],\n",
       "        [     0.0848,      0.5672],\n",
       "        [     0.2788,      1.6890],\n",
       "        [     0.0903,      0.4667],\n",
       "        [     0.3625,      1.7486],\n",
       "        [    -0.0025,      0.4533],\n",
       "        [     0.3910,      1.8691],\n",
       "        [    -0.1461,      0.4731],\n",
       "        [     0.4016,      1.9821],\n",
       "        [    -0.2940,      0.4732],\n",
       "        [     0.4148,      2.7432],\n",
       "        [    -0.6604,      0.7280],\n",
       "        [     0.2850,      2.2821],\n",
       "        [    -0.6916,      0.4828],\n",
       "        [     0.2209,      1.7735],\n",
       "        [    -0.6689,      0.2168],\n",
       "        [     0.2560,      1.2534],\n",
       "        [    -0.5703,     -0.0105],\n",
       "        [     0.3815,      0.8189],\n",
       "        [    -0.4034,     -0.1102],\n",
       "        [     0.5404,      0.5665],\n",
       "        [    -0.2139,     -0.0332],\n",
       "        [     0.6488,      0.5329],\n",
       "        [    -0.0616,      0.2026],\n",
       "        [     0.6541,      0.6878],\n",
       "        [     0.0301,      0.5266],\n",
       "        [     0.5735,      0.9568],\n",
       "        [     0.0831,      0.8501],\n",
       "        [     0.4610,      1.2646],\n",
       "        [     0.1237,      1.1172],\n",
       "        [     0.2748,      2.2976],\n",
       "        [    -0.0330,      1.8259],\n",
       "        [    -0.0423,      2.1680],\n",
       "        [    -0.2610,      1.5336],\n",
       "        [    -0.3348,      2.0066],\n",
       "        [    -0.4589,      1.1846],\n",
       "        [    -0.5134,      1.8153],\n",
       "        [    -0.5622,      0.8286],\n",
       "        [    -0.5296,      1.6529],\n",
       "        [    -0.5448,      0.5550],\n",
       "        [    -0.3891,      1.5991],\n",
       "        [    -0.4447,      0.4305],\n",
       "        [    -0.1715,      1.6878],\n",
       "        [    -0.3579,      0.4469],\n",
       "        [     0.0124,      1.8729],\n",
       "        [    -0.3619,      0.5228],\n",
       "        [     0.1097,      2.0594],\n",
       "        [    -0.4523,      0.5681],\n",
       "        [     0.1429,      2.1800],\n",
       "        [    -0.5781,      0.5518],\n",
       "        [     0.8490,      3.1269],\n",
       "        [    -0.2896,      0.9770],\n",
       "        [     0.8002,      2.8018],\n",
       "        [    -0.3615,      0.7770],\n",
       "        [     0.5715,      2.3418],\n",
       "        [    -0.5644,      0.4715],\n",
       "        [     0.2987,      1.8063],\n",
       "        [    -0.7625,      0.1474],\n",
       "        [     0.0956,      1.3047],\n",
       "        [    -0.8363,     -0.0663],\n",
       "        [     0.0382,      0.9703],\n",
       "        [    -0.7302,     -0.0562],\n",
       "        [     0.1148,      0.8841],\n",
       "        [    -0.5014,      0.1903],\n",
       "        [     0.2211,      1.0026],\n",
       "        [    -0.2770,      0.5507],\n",
       "        [     0.2553,      1.1831],\n",
       "        [    -0.1344,      0.8649],\n",
       "        [     0.2071,      1.3240],\n",
       "        [    -0.0659,      1.0703],\n",
       "        [     0.5201,      2.1154],\n",
       "        [     0.4960,      1.7722],\n",
       "        [     0.6507,      2.0223],\n",
       "        [     0.5601,      1.5791],\n",
       "        [     0.4936,      1.8634],\n",
       "        [     0.2971,      1.2373],\n",
       "        [     0.1095,      1.6431],\n",
       "        [    -0.1622,      0.8103],\n",
       "        [    -0.3289,      1.4282],\n",
       "        [    -0.6204,      0.4177],\n",
       "        [    -0.6237,      1.3265],\n",
       "        [    -0.8953,      0.2025],\n",
       "        [    -0.6565,      1.4378],\n",
       "        [    -0.9393,      0.2367],\n",
       "        [    -0.4842,      1.7470],\n",
       "        [    -0.8722,      0.4259],\n",
       "        [    -0.2813,      2.0913],\n",
       "        [    -0.8465,      0.5804],\n",
       "        [    -0.1658,      2.3164],\n",
       "        [    -0.9046,      0.6113],\n",
       "        [     0.6151,      3.0254],\n",
       "        [    -0.4913,      0.7941],\n",
       "        [     1.0602,      2.9082],\n",
       "        [     0.0349,      0.8609],\n",
       "        [     1.3868,      2.7389],\n",
       "        [     0.2850,      0.8013],\n",
       "        [     1.3553,      2.4234],\n",
       "        [     0.1502,      0.5887],\n",
       "        [     0.9674,      1.9960],\n",
       "        [    -0.2518,      0.3068],\n",
       "        [     0.4120,      1.5784],\n",
       "        [    -0.6579,      0.1168],\n",
       "        [    -0.0281,      1.3481],\n",
       "        [    -0.8125,      0.1849],\n",
       "        [    -0.1826,      1.4077],\n",
       "        [    -0.6831,      0.5117],\n",
       "        [    -0.1378,      1.6442],\n",
       "        [    -0.4608,      0.8932],\n",
       "        [    -0.0898,      1.8378],\n",
       "        [    -0.3166,      1.1462],\n",
       "        [    -0.0555,      2.3032],\n",
       "        [    -0.1275,      1.4937],\n",
       "        [     0.1009,      2.0249],\n",
       "        [     0.1890,      1.3288],\n",
       "        [     0.4320,      1.8819],\n",
       "        [     0.5351,      1.1906],\n",
       "        [     0.7076,      1.7809],\n",
       "        [     0.6450,      0.9823],\n",
       "        [     0.6935,      1.6575],\n",
       "        [     0.3684,      0.6853],\n",
       "        [     0.3351,      1.5208],\n",
       "        [    -0.2281,      0.3672],\n",
       "        [    -0.1959,      1.4562],\n",
       "        [    -0.8575,      0.1750],\n",
       "        [    -0.5750,      1.5928],\n",
       "        [    -1.2131,      0.2229],\n",
       "        [    -0.6314,      1.9387],\n",
       "        [    -1.2815,      0.4219],\n",
       "        [    -0.5159,      2.3095],\n",
       "        [    -1.2795,      0.5672],\n",
       "        [     0.1682,      3.0151],\n",
       "        [    -1.2969,      0.5619],\n",
       "        [     0.3090,      2.7328],\n",
       "        [    -0.9938,      0.5263],\n",
       "        [     0.5666,      2.5439],\n",
       "        [    -0.5715,      0.5633],\n",
       "        [     0.9165,      2.4246],\n",
       "        [    -0.1101,      0.6214],\n",
       "        [     1.2068,      2.3186],\n",
       "        [     0.2081,      0.6465],\n",
       "        [     1.2393,      2.1869],\n",
       "        [     0.2166,      0.6216],\n",
       "        [     0.9089,      2.0344],\n",
       "        [    -0.0923,      0.5863],\n",
       "        [     0.3466,      1.9334],\n",
       "        [    -0.4682,      0.6477],\n",
       "        [    -0.1090,      1.9923],\n",
       "        [    -0.6196,      0.8758],\n",
       "        [    -0.2891,      2.1952],\n",
       "        [    -0.5762,      1.1586],\n",
       "        [    -0.3386,      2.7778],\n",
       "        [    -0.5384,      1.4955],\n",
       "        [    -0.3978,      2.4008],\n",
       "        [    -0.5211,      1.1893],\n",
       "        [    -0.3904,      2.1080],\n",
       "        [    -0.4782,      0.9439],\n",
       "        [    -0.2967,      1.9089],\n",
       "        [    -0.3921,      0.7539],\n",
       "        [    -0.1171,      1.8028],\n",
       "        [    -0.2831,      0.6146],\n",
       "        [     0.0838,      1.7884],\n",
       "        [    -0.2422,      0.5229],\n",
       "        [     0.1709,      1.8536],\n",
       "        [    -0.4018,      0.4600],\n",
       "        [     0.0180,      1.9634],\n",
       "        [    -0.8048,      0.4028],\n",
       "        [    -0.3197,      2.1111],\n",
       "        [    -1.2626,      0.3927],\n",
       "        [    -0.5946,      2.3511],\n",
       "        [    -1.5524,      0.4679],\n",
       "        [    -0.0682,      3.1234],\n",
       "        [    -1.7304,      0.5344],\n",
       "        [     0.0432,      2.7892],\n",
       "        [    -1.5088,      0.4511],\n",
       "        [     0.1538,      2.5309],\n",
       "        [    -1.2920,      0.4267],\n",
       "        [     0.2451,      2.3438],\n",
       "        [    -1.0796,      0.4414],\n",
       "        [     0.3207,      2.2195],\n",
       "        [    -0.8539,      0.4946],\n",
       "        [     0.3925,      2.1712],\n",
       "        [    -0.6123,      0.6067],\n",
       "        [     0.4454,      2.2149],\n",
       "        [    -0.4021,      0.7819],\n",
       "        [     0.4135,      2.3250],\n",
       "        [    -0.3202,      0.9702],\n",
       "        [     0.2181,      2.4358],\n",
       "        [    -0.4244,      1.1256],\n",
       "        [    -0.1150,      2.5432],\n",
       "        [    -0.6355,      1.2838],\n",
       "        [    -0.4506,      3.0067],\n",
       "        [    -0.7351,      1.5056],\n",
       "        [    -0.5140,      2.6493],\n",
       "        [    -0.7339,      1.1847],\n",
       "        [    -0.5435,      2.3830],\n",
       "        [    -0.7664,      0.9296],\n",
       "        [    -0.5636,      2.1940],\n",
       "        [    -0.8466,      0.7150],\n",
       "        [    -0.5825,      2.0614],\n",
       "        [    -0.9624,      0.5382],\n",
       "        [    -0.5910,      1.9980],\n",
       "        [    -1.0872,      0.4308],\n",
       "        [    -0.5787,      2.0370],\n",
       "        [    -1.2004,      0.4195],\n",
       "        [    -0.5524,      2.1799],\n",
       "        [    -1.3084,      0.4723],\n",
       "        [    -0.5467,      2.3731],\n",
       "        [    -1.4457,      0.5247],\n",
       "        [    -0.6082,      2.5868],\n",
       "        [    -1.6517,      0.5751]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode = False)\n",
    "test_pred_dist_likeli = likelihood(test_pred_dist)\n",
    "test_pred_dist_likeli.mean.reshape(2, -1).T - mean_model_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice_thickness_gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
