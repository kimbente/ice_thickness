{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f61515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 12:19:43] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:19:43] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 12:19:43] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 12:19:44] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 12:19:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon WARNING @ 12:19:44] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon INFO @ 12:19:44] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 12:19:44] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 12:19:44] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: cpu_load\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 12:19:44] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 12:19:44]   Platform system: Linux-5.15.0-139-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 12:19:44]   Python version: 3.9.23\n",
      "[codecarbon INFO @ 12:19:44]   CodeCarbon version: 3.0.2\n",
      "[codecarbon INFO @ 12:19:44]   Available RAM : 62.767 GB\n",
      "[codecarbon INFO @ 12:19:44]   CPU count: 40 thread(s) in 2 physical CPU(s)\n",
      "[codecarbon INFO @ 12:19:44]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 12:19:44]   GPU count: 1\n",
      "[codecarbon INFO @ 12:19:44]   GPU model: 1 x NVIDIA GeForce RTX 4090\n",
      "[codecarbon INFO @ 12:19:48] Emissions data (if any) will be saved to file /home/kim/ice_thickness/results_real/dfNGP_grid_inference/emissions.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for REGION_LOWER_BYRD...\n",
      "=== REGION_LOWER_BYRD ===\n",
      "Training inputs shape: torch.Size([829, 2])\n",
      "Training observations shape: torch.Size([829, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== REGION_LOWER_BYRD ===\n",
      "Test inputs shape: torch.Size([900, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "\n",
      "--- Training starts ---\n",
      "\n",
      "Start Training\n",
      "region_lower_byrd dfNGP Epoch 1/2000, Training Loss (NLML): 20.0303\n",
      "Lengthscale x1: 7.184\n",
      "Lengthscale x2: 5.353\n",
      "Outputscale: 1.199\n",
      "Noise: 0.029591\n",
      "region_lower_byrd dfNGP Epoch 51/2000, Training Loss (NLML): 14.9404\n",
      "Lengthscale x1: 6.939\n",
      "Lengthscale x2: 5.095\n",
      "Outputscale: 1.361\n",
      "Noise: 0.037530\n",
      "region_lower_byrd dfNGP Epoch 101/2000, Training Loss (NLML): 11.3857\n",
      "Lengthscale x1: 6.714\n",
      "Lengthscale x2: 4.796\n",
      "Outputscale: 1.449\n",
      "Noise: 0.046299\n",
      "region_lower_byrd dfNGP Epoch 151/2000, Training Loss (NLML): 9.1912\n",
      "Lengthscale x1: 6.526\n",
      "Lengthscale x2: 4.546\n",
      "Outputscale: 1.489\n",
      "Noise: 0.055629\n",
      "region_lower_byrd dfNGP Epoch 201/2000, Training Loss (NLML): 7.6001\n",
      "Lengthscale x1: 6.365\n",
      "Lengthscale x2: 4.345\n",
      "Outputscale: 1.523\n",
      "Noise: 0.065394\n",
      "region_lower_byrd dfNGP Epoch 251/2000, Training Loss (NLML): 6.4216\n",
      "Lengthscale x1: 6.217\n",
      "Lengthscale x2: 4.169\n",
      "Outputscale: 1.555\n",
      "Noise: 0.075507\n",
      "region_lower_byrd dfNGP Epoch 301/2000, Training Loss (NLML): 5.5163\n",
      "Lengthscale x1: 6.068\n",
      "Lengthscale x2: 4.010\n",
      "Outputscale: 1.587\n",
      "Noise: 0.085870\n",
      "region_lower_byrd dfNGP Epoch 351/2000, Training Loss (NLML): 4.8421\n",
      "Lengthscale x1: 5.917\n",
      "Lengthscale x2: 3.866\n",
      "Outputscale: 1.621\n",
      "Noise: 0.096445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:20:03] Energy consumed for RAM : 0.000086 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:20:04] Delta energy consumed for CPU with cpu_load : 0.000073 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:20:04] Energy consumed for All CPU : 0.000073 kWh\n",
      "[codecarbon INFO @ 12:20:04] Energy consumed for all GPUs : 0.000332 kWh. Total GPU Power : 74.56804072164141 W\n",
      "[codecarbon INFO @ 12:20:04] 0.000491 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_lower_byrd dfNGP Epoch 401/2000, Training Loss (NLML): 4.3123\n",
      "Lengthscale x1: 5.777\n",
      "Lengthscale x2: 3.731\n",
      "Outputscale: 1.654\n",
      "Noise: 0.107246\n",
      "region_lower_byrd dfNGP Epoch 451/2000, Training Loss (NLML): 3.8925\n",
      "Lengthscale x1: 5.647\n",
      "Lengthscale x2: 3.603\n",
      "Outputscale: 1.687\n",
      "Noise: 0.118258\n",
      "region_lower_byrd dfNGP Epoch 501/2000, Training Loss (NLML): 3.5442\n",
      "Lengthscale x1: 5.523\n",
      "Lengthscale x2: 3.482\n",
      "Outputscale: 1.718\n",
      "Noise: 0.129460\n",
      "region_lower_byrd dfNGP Epoch 551/2000, Training Loss (NLML): 3.2555\n",
      "Lengthscale x1: 5.404\n",
      "Lengthscale x2: 3.364\n",
      "Outputscale: 1.748\n",
      "Noise: 0.140805\n",
      "region_lower_byrd dfNGP Epoch 601/2000, Training Loss (NLML): 3.0038\n",
      "Lengthscale x1: 5.288\n",
      "Lengthscale x2: 3.245\n",
      "Outputscale: 1.778\n",
      "Noise: 0.152237\n",
      "region_lower_byrd dfNGP Epoch 651/2000, Training Loss (NLML): 2.8016\n",
      "Lengthscale x1: 5.174\n",
      "Lengthscale x2: 3.128\n",
      "Outputscale: 1.805\n",
      "Noise: 0.163723\n",
      "region_lower_byrd dfNGP Epoch 701/2000, Training Loss (NLML): 2.6289\n",
      "Lengthscale x1: 5.063\n",
      "Lengthscale x2: 3.013\n",
      "Outputscale: 1.831\n",
      "Noise: 0.175255\n",
      "region_lower_byrd dfNGP Epoch 751/2000, Training Loss (NLML): 2.4804\n",
      "Lengthscale x1: 4.952\n",
      "Lengthscale x2: 2.902\n",
      "Outputscale: 1.856\n",
      "Noise: 0.186829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:20:18] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:20:19] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:20:19] Energy consumed for All CPU : 0.000142 kWh\n",
      "[codecarbon INFO @ 12:20:19] Energy consumed for all GPUs : 0.000664 kWh. Total GPU Power : 79.7201384770568 W\n",
      "[codecarbon INFO @ 12:20:19] 0.000972 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_lower_byrd dfNGP Epoch 801/2000, Training Loss (NLML): 2.3492\n",
      "Lengthscale x1: 4.840\n",
      "Lengthscale x2: 2.793\n",
      "Outputscale: 1.880\n",
      "Noise: 0.198413\n",
      "region_lower_byrd dfNGP Epoch 851/2000, Training Loss (NLML): 2.2370\n",
      "Lengthscale x1: 4.723\n",
      "Lengthscale x2: 2.688\n",
      "Outputscale: 1.903\n",
      "Noise: 0.209987\n",
      "region_lower_byrd dfNGP Epoch 901/2000, Training Loss (NLML): 2.1260\n",
      "Lengthscale x1: 4.603\n",
      "Lengthscale x2: 2.587\n",
      "Outputscale: 1.924\n",
      "Noise: 0.221486\n",
      "region_lower_byrd dfNGP Epoch 951/2000, Training Loss (NLML): 2.0365\n",
      "Lengthscale x1: 4.476\n",
      "Lengthscale x2: 2.494\n",
      "Outputscale: 1.946\n",
      "Noise: 0.232834\n",
      "region_lower_byrd dfNGP Epoch 1001/2000, Training Loss (NLML): 1.9629\n",
      "Lengthscale x1: 4.339\n",
      "Lengthscale x2: 2.412\n",
      "Outputscale: 1.967\n",
      "Noise: 0.244041\n",
      "region_lower_byrd dfNGP Epoch 1051/2000, Training Loss (NLML): 1.8876\n",
      "Lengthscale x1: 4.194\n",
      "Lengthscale x2: 2.342\n",
      "Outputscale: 1.987\n",
      "Noise: 0.255076\n",
      "region_lower_byrd dfNGP Epoch 1101/2000, Training Loss (NLML): 1.8280\n",
      "Lengthscale x1: 4.042\n",
      "Lengthscale x2: 2.279\n",
      "Outputscale: 2.006\n",
      "Noise: 0.265928\n",
      "region_lower_byrd dfNGP Epoch 1151/2000, Training Loss (NLML): 1.7733\n",
      "Lengthscale x1: 3.881\n",
      "Lengthscale x2: 2.229\n",
      "Outputscale: 2.025\n",
      "Noise: 0.276572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:20:33] Energy consumed for RAM : 0.000247 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:20:34] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:20:34] Energy consumed for All CPU : 0.000210 kWh\n",
      "[codecarbon INFO @ 12:20:34] Energy consumed for all GPUs : 0.000995 kWh. Total GPU Power : 79.54326882110789 W\n",
      "[codecarbon INFO @ 12:20:34] 0.001452 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_lower_byrd dfNGP Epoch 1201/2000, Training Loss (NLML): 1.7195\n",
      "Lengthscale x1: 3.712\n",
      "Lengthscale x2: 2.193\n",
      "Outputscale: 2.043\n",
      "Noise: 0.286974\n",
      "region_lower_byrd dfNGP Epoch 1251/2000, Training Loss (NLML): 1.6733\n",
      "Lengthscale x1: 3.539\n",
      "Lengthscale x2: 2.166\n",
      "Outputscale: 2.062\n",
      "Noise: 0.297158\n",
      "region_lower_byrd dfNGP Epoch 1301/2000, Training Loss (NLML): 1.6391\n",
      "Lengthscale x1: 3.365\n",
      "Lengthscale x2: 2.153\n",
      "Outputscale: 2.079\n",
      "Noise: 0.307138\n",
      "region_lower_byrd dfNGP Epoch 1351/2000, Training Loss (NLML): 1.6009\n",
      "Lengthscale x1: 3.192\n",
      "Lengthscale x2: 2.146\n",
      "Outputscale: 2.096\n",
      "Noise: 0.316886\n",
      "region_lower_byrd dfNGP Epoch 1401/2000, Training Loss (NLML): 1.5726\n",
      "Lengthscale x1: 3.025\n",
      "Lengthscale x2: 2.152\n",
      "Outputscale: 2.111\n",
      "Noise: 0.326418\n",
      "region_lower_byrd dfNGP Epoch 1451/2000, Training Loss (NLML): 1.5419\n",
      "Lengthscale x1: 2.865\n",
      "Lengthscale x2: 2.154\n",
      "Outputscale: 2.124\n",
      "Noise: 0.335738\n",
      "region_lower_byrd dfNGP Epoch 1501/2000, Training Loss (NLML): 1.5163\n",
      "Lengthscale x1: 2.713\n",
      "Lengthscale x2: 2.163\n",
      "Outputscale: 2.136\n",
      "Noise: 0.344812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:20:48] Energy consumed for RAM : 0.000328 kWh. RAM Power : 20.0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_lower_byrd dfNGP Epoch 1551/2000, Training Loss (NLML): 1.4970\n",
      "Lengthscale x1: 2.572\n",
      "Lengthscale x2: 2.180\n",
      "Outputscale: 2.144\n",
      "Noise: 0.353640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:20:49] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:20:49] Energy consumed for All CPU : 0.000279 kWh\n",
      "[codecarbon INFO @ 12:20:49] Energy consumed for all GPUs : 0.001326 kWh. Total GPU Power : 79.38079481161017 W\n",
      "[codecarbon INFO @ 12:20:49] 0.001932 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_lower_byrd dfNGP Epoch 1601/2000, Training Loss (NLML): 1.4780\n",
      "Lengthscale x1: 2.445\n",
      "Lengthscale x2: 2.195\n",
      "Outputscale: 2.151\n",
      "Noise: 0.362225\n",
      "region_lower_byrd dfNGP Epoch 1651/2000, Training Loss (NLML): 1.4486\n",
      "Lengthscale x1: 2.331\n",
      "Lengthscale x2: 2.207\n",
      "Outputscale: 2.157\n",
      "Noise: 0.370614\n",
      "region_lower_byrd dfNGP Epoch 1701/2000, Training Loss (NLML): 1.4401\n",
      "Lengthscale x1: 2.234\n",
      "Lengthscale x2: 2.218\n",
      "Outputscale: 2.160\n",
      "Noise: 0.378793\n",
      "region_lower_byrd dfNGP Epoch 1751/2000, Training Loss (NLML): 1.4279\n",
      "Lengthscale x1: 2.156\n",
      "Lengthscale x2: 2.234\n",
      "Outputscale: 2.161\n",
      "Noise: 0.386789\n",
      "region_lower_byrd dfNGP Epoch 1801/2000, Training Loss (NLML): 1.4181\n",
      "Lengthscale x1: 2.091\n",
      "Lengthscale x2: 2.250\n",
      "Outputscale: 2.161\n",
      "Noise: 0.394603\n",
      "region_lower_byrd dfNGP Epoch 1851/2000, Training Loss (NLML): 1.4137\n",
      "Lengthscale x1: 2.041\n",
      "Lengthscale x2: 2.269\n",
      "Outputscale: 2.159\n",
      "Noise: 0.402262\n",
      "region_lower_byrd dfNGP Epoch 1901/2000, Training Loss (NLML): 1.4044\n",
      "Lengthscale x1: 2.002\n",
      "Lengthscale x2: 2.286\n",
      "Outputscale: 2.156\n",
      "Noise: 0.409804\n",
      "region_lower_byrd dfNGP Epoch 1951/2000, Training Loss (NLML): 1.3858\n",
      "Lengthscale x1: 1.972\n",
      "Lengthscale x2: 2.309\n",
      "Outputscale: 2.151\n",
      "Noise: 0.417212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:21:03] Energy consumed for RAM : 0.000408 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:21:04] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:21:04] Energy consumed for All CPU : 0.000347 kWh\n",
      "[codecarbon INFO @ 12:21:04] Energy consumed for all GPUs : 0.001661 kWh. Total GPU Power : 80.51677018643748 W\n",
      "[codecarbon INFO @ 12:21:04] 0.002416 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for REGION_MID_BYRD...\n",
      "=== REGION_MID_BYRD ===\n",
      "Training inputs shape: torch.Size([722, 2])\n",
      "Training observations shape: torch.Size([722, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== REGION_MID_BYRD ===\n",
      "Test inputs shape: torch.Size([900, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "\n",
      "--- Training starts ---\n",
      "\n",
      "Start Training\n",
      "region_mid_byrd dfNGP Epoch 1/2000, Training Loss (NLML): 16.9696\n",
      "Lengthscale x1: 6.241\n",
      "Lengthscale x2: 5.811\n",
      "Outputscale: 1.050\n",
      "Noise: 0.038382\n",
      "region_mid_byrd dfNGP Epoch 51/2000, Training Loss (NLML): 9.8917\n",
      "Lengthscale x1: 5.997\n",
      "Lengthscale x2: 5.947\n",
      "Outputscale: 1.201\n",
      "Noise: 0.048334\n",
      "region_mid_byrd dfNGP Epoch 101/2000, Training Loss (NLML): 5.8337\n",
      "Lengthscale x1: 5.768\n",
      "Lengthscale x2: 5.663\n",
      "Outputscale: 1.283\n",
      "Noise: 0.057670\n",
      "region_mid_byrd dfNGP Epoch 151/2000, Training Loss (NLML): 4.7723\n",
      "Lengthscale x1: 5.555\n",
      "Lengthscale x2: 5.351\n",
      "Outputscale: 1.327\n",
      "Noise: 0.066805\n",
      "region_mid_byrd dfNGP Epoch 201/2000, Training Loss (NLML): 4.0774\n",
      "Lengthscale x1: 5.349\n",
      "Lengthscale x2: 5.081\n",
      "Outputscale: 1.365\n",
      "Noise: 0.076497\n",
      "region_mid_byrd dfNGP Epoch 251/2000, Training Loss (NLML): 3.5543\n",
      "Lengthscale x1: 5.150\n",
      "Lengthscale x2: 4.837\n",
      "Outputscale: 1.400\n",
      "Noise: 0.086645\n",
      "region_mid_byrd dfNGP Epoch 301/2000, Training Loss (NLML): 3.1638\n",
      "Lengthscale x1: 4.959\n",
      "Lengthscale x2: 4.618\n",
      "Outputscale: 1.435\n",
      "Noise: 0.097107\n",
      "region_mid_byrd dfNGP Epoch 351/2000, Training Loss (NLML): 2.8493\n",
      "Lengthscale x1: 4.775\n",
      "Lengthscale x2: 4.420\n",
      "Outputscale: 1.470\n",
      "Noise: 0.107802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:21:18] Energy consumed for RAM : 0.000489 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:21:19] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:21:19] Energy consumed for All CPU : 0.000415 kWh\n",
      "[codecarbon INFO @ 12:21:19] Energy consumed for all GPUs : 0.001984 kWh. Total GPU Power : 77.44557837674708 W\n",
      "[codecarbon INFO @ 12:21:19] 0.002888 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_mid_byrd dfNGP Epoch 401/2000, Training Loss (NLML): 2.5853\n",
      "Lengthscale x1: 4.596\n",
      "Lengthscale x2: 4.242\n",
      "Outputscale: 1.505\n",
      "Noise: 0.118649\n",
      "region_mid_byrd dfNGP Epoch 451/2000, Training Loss (NLML): 2.3769\n",
      "Lengthscale x1: 4.425\n",
      "Lengthscale x2: 4.081\n",
      "Outputscale: 1.538\n",
      "Noise: 0.129560\n",
      "region_mid_byrd dfNGP Epoch 501/2000, Training Loss (NLML): 2.2071\n",
      "Lengthscale x1: 4.260\n",
      "Lengthscale x2: 3.936\n",
      "Outputscale: 1.571\n",
      "Noise: 0.140477\n",
      "region_mid_byrd dfNGP Epoch 551/2000, Training Loss (NLML): 2.0631\n",
      "Lengthscale x1: 4.100\n",
      "Lengthscale x2: 3.803\n",
      "Outputscale: 1.602\n",
      "Noise: 0.151360\n",
      "region_mid_byrd dfNGP Epoch 601/2000, Training Loss (NLML): 1.9506\n",
      "Lengthscale x1: 3.946\n",
      "Lengthscale x2: 3.680\n",
      "Outputscale: 1.633\n",
      "Noise: 0.162194\n",
      "region_mid_byrd dfNGP Epoch 651/2000, Training Loss (NLML): 1.8483\n",
      "Lengthscale x1: 3.796\n",
      "Lengthscale x2: 3.566\n",
      "Outputscale: 1.662\n",
      "Noise: 0.172910\n",
      "region_mid_byrd dfNGP Epoch 701/2000, Training Loss (NLML): 1.7647\n",
      "Lengthscale x1: 3.651\n",
      "Lengthscale x2: 3.458\n",
      "Outputscale: 1.691\n",
      "Noise: 0.183467\n",
      "region_mid_byrd dfNGP Epoch 751/2000, Training Loss (NLML): 1.6905\n",
      "Lengthscale x1: 3.509\n",
      "Lengthscale x2: 3.356\n",
      "Outputscale: 1.718\n",
      "Noise: 0.193825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:21:33] Energy consumed for RAM : 0.000569 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:21:34] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:21:34] Energy consumed for All CPU : 0.000484 kWh\n",
      "[codecarbon INFO @ 12:21:34] Energy consumed for all GPUs : 0.002303 kWh. Total GPU Power : 76.64001202215026 W\n",
      "[codecarbon INFO @ 12:21:34] 0.003356 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_mid_byrd dfNGP Epoch 801/2000, Training Loss (NLML): 1.6257\n",
      "Lengthscale x1: 3.372\n",
      "Lengthscale x2: 3.260\n",
      "Outputscale: 1.745\n",
      "Noise: 0.203957\n",
      "region_mid_byrd dfNGP Epoch 851/2000, Training Loss (NLML): 1.5818\n",
      "Lengthscale x1: 3.239\n",
      "Lengthscale x2: 3.174\n",
      "Outputscale: 1.770\n",
      "Noise: 0.213830\n",
      "region_mid_byrd dfNGP Epoch 901/2000, Training Loss (NLML): 1.5263\n",
      "Lengthscale x1: 3.111\n",
      "Lengthscale x2: 3.094\n",
      "Outputscale: 1.794\n",
      "Noise: 0.223397\n",
      "region_mid_byrd dfNGP Epoch 951/2000, Training Loss (NLML): 1.4959\n",
      "Lengthscale x1: 2.989\n",
      "Lengthscale x2: 3.023\n",
      "Outputscale: 1.817\n",
      "Noise: 0.232675\n",
      "region_mid_byrd dfNGP Epoch 1001/2000, Training Loss (NLML): 1.4601\n",
      "Lengthscale x1: 2.875\n",
      "Lengthscale x2: 2.960\n",
      "Outputscale: 1.839\n",
      "Noise: 0.241688\n",
      "region_mid_byrd dfNGP Epoch 1051/2000, Training Loss (NLML): 1.4375\n",
      "Lengthscale x1: 2.769\n",
      "Lengthscale x2: 2.904\n",
      "Outputscale: 1.859\n",
      "Noise: 0.250427\n",
      "region_mid_byrd dfNGP Epoch 1101/2000, Training Loss (NLML): 1.4001\n",
      "Lengthscale x1: 2.671\n",
      "Lengthscale x2: 2.859\n",
      "Outputscale: 1.878\n",
      "Noise: 0.258883\n",
      "region_mid_byrd dfNGP Epoch 1151/2000, Training Loss (NLML): 1.3909\n",
      "Lengthscale x1: 2.583\n",
      "Lengthscale x2: 2.822\n",
      "Outputscale: 1.895\n",
      "Noise: 0.267072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:21:48] Energy consumed for RAM : 0.000650 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:21:49] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:21:49] Energy consumed for All CPU : 0.000552 kWh\n",
      "[codecarbon INFO @ 12:21:49] Energy consumed for all GPUs : 0.002622 kWh. Total GPU Power : 76.50128267473384 W\n",
      "[codecarbon INFO @ 12:21:49] 0.003824 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:21:49] 0.017336 g.CO2eq/s mean an estimation of 546.7118320861549 kg.CO2eq/year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_mid_byrd dfNGP Epoch 1201/2000, Training Loss (NLML): 1.3714\n",
      "Lengthscale x1: 2.504\n",
      "Lengthscale x2: 2.792\n",
      "Outputscale: 1.911\n",
      "Noise: 0.275050\n",
      "region_mid_byrd dfNGP Epoch 1251/2000, Training Loss (NLML): 1.3561\n",
      "Lengthscale x1: 2.434\n",
      "Lengthscale x2: 2.772\n",
      "Outputscale: 1.925\n",
      "Noise: 0.282816\n",
      "region_mid_byrd dfNGP Epoch 1301/2000, Training Loss (NLML): 1.3471\n",
      "Lengthscale x1: 2.375\n",
      "Lengthscale x2: 2.759\n",
      "Outputscale: 1.937\n",
      "Noise: 0.290400\n",
      "region_mid_byrd dfNGP Epoch 1351/2000, Training Loss (NLML): 1.3342\n",
      "Lengthscale x1: 2.324\n",
      "Lengthscale x2: 2.754\n",
      "Outputscale: 1.949\n",
      "Noise: 0.297812\n",
      "region_mid_byrd dfNGP Epoch 1401/2000, Training Loss (NLML): 1.3187\n",
      "Lengthscale x1: 2.281\n",
      "Lengthscale x2: 2.753\n",
      "Outputscale: 1.959\n",
      "Noise: 0.305069\n",
      "region_mid_byrd dfNGP Epoch 1451/2000, Training Loss (NLML): 1.3215\n",
      "Lengthscale x1: 2.245\n",
      "Lengthscale x2: 2.756\n",
      "Outputscale: 1.968\n",
      "Noise: 0.312221\n",
      "region_mid_byrd dfNGP Epoch 1501/2000, Training Loss (NLML): 1.3148\n",
      "Lengthscale x1: 2.218\n",
      "Lengthscale x2: 2.764\n",
      "Outputscale: 1.977\n",
      "Noise: 0.319209\n",
      "region_mid_byrd dfNGP Epoch 1551/2000, Training Loss (NLML): 1.3104\n",
      "Lengthscale x1: 2.196\n",
      "Lengthscale x2: 2.777\n",
      "Outputscale: 1.984\n",
      "Noise: 0.326124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:22:03] Energy consumed for RAM : 0.000730 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:22:04] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:22:04] Energy consumed for All CPU : 0.000621 kWh\n",
      "[codecarbon INFO @ 12:22:04] Energy consumed for all GPUs : 0.002940 kWh. Total GPU Power : 76.42421835668203 W\n",
      "[codecarbon INFO @ 12:22:04] 0.004291 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_mid_byrd dfNGP Epoch 1601/2000, Training Loss (NLML): 1.3070\n",
      "Lengthscale x1: 2.180\n",
      "Lengthscale x2: 2.793\n",
      "Outputscale: 1.991\n",
      "Noise: 0.332955\n",
      "region_mid_byrd dfNGP Epoch 1651/2000, Training Loss (NLML): 1.2895\n",
      "Lengthscale x1: 2.168\n",
      "Lengthscale x2: 2.809\n",
      "Outputscale: 1.996\n",
      "Noise: 0.339701\n",
      "region_mid_byrd dfNGP Epoch 1701/2000, Training Loss (NLML): 1.2925\n",
      "Lengthscale x1: 2.161\n",
      "Lengthscale x2: 2.830\n",
      "Outputscale: 2.002\n",
      "Noise: 0.346336\n",
      "region_mid_byrd dfNGP Epoch 1751/2000, Training Loss (NLML): 1.2939\n",
      "Lengthscale x1: 2.155\n",
      "Lengthscale x2: 2.850\n",
      "Outputscale: 2.007\n",
      "Noise: 0.352895\n",
      "region_mid_byrd dfNGP Epoch 1801/2000, Training Loss (NLML): 1.2797\n",
      "Lengthscale x1: 2.155\n",
      "Lengthscale x2: 2.873\n",
      "Outputscale: 2.011\n",
      "Noise: 0.359328\n",
      "region_mid_byrd dfNGP Epoch 1851/2000, Training Loss (NLML): 1.2838\n",
      "Lengthscale x1: 2.157\n",
      "Lengthscale x2: 2.898\n",
      "Outputscale: 2.016\n",
      "Noise: 0.365674\n",
      "region_mid_byrd dfNGP Epoch 1901/2000, Training Loss (NLML): 1.2748\n",
      "Lengthscale x1: 2.161\n",
      "Lengthscale x2: 2.926\n",
      "Outputscale: 2.019\n",
      "Noise: 0.371917\n",
      "region_mid_byrd dfNGP Epoch 1951/2000, Training Loss (NLML): 1.2763\n",
      "Lengthscale x1: 2.164\n",
      "Lengthscale x2: 2.951\n",
      "Outputscale: 2.023\n",
      "Noise: 0.378114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:22:18] Energy consumed for RAM : 0.000811 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:22:19] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:22:19] Energy consumed for All CPU : 0.000689 kWh\n",
      "[codecarbon INFO @ 12:22:19] Energy consumed for all GPUs : 0.003261 kWh. Total GPU Power : 76.9224375873614 W\n",
      "[codecarbon INFO @ 12:22:19] 0.004760 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for REGION_UPPER_BYRD...\n",
      "=== REGION_UPPER_BYRD ===\n",
      "Training inputs shape: torch.Size([746, 2])\n",
      "Training observations shape: torch.Size([746, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== REGION_UPPER_BYRD ===\n",
      "Test inputs shape: torch.Size([900, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "\n",
      "--- Training starts ---\n",
      "\n",
      "Start Training\n",
      "region_upper_byrd dfNGP Epoch 1/2000, Training Loss (NLML): 24.4229\n",
      "Lengthscale x1: 6.455\n",
      "Lengthscale x2: 6.949\n",
      "Outputscale: 1.174\n",
      "Noise: 0.030672\n",
      "region_upper_byrd dfNGP Epoch 51/2000, Training Loss (NLML): 15.1527\n",
      "Lengthscale x1: 6.195\n",
      "Lengthscale x2: 7.123\n",
      "Outputscale: 1.333\n",
      "Noise: 0.038769\n",
      "region_upper_byrd dfNGP Epoch 101/2000, Training Loss (NLML): 9.6501\n",
      "Lengthscale x1: 5.907\n",
      "Lengthscale x2: 6.922\n",
      "Outputscale: 1.419\n",
      "Noise: 0.047021\n",
      "region_upper_byrd dfNGP Epoch 151/2000, Training Loss (NLML): 7.8236\n",
      "Lengthscale x1: 5.631\n",
      "Lengthscale x2: 6.622\n",
      "Outputscale: 1.465\n",
      "Noise: 0.055406\n",
      "region_upper_byrd dfNGP Epoch 201/2000, Training Loss (NLML): 6.6093\n",
      "Lengthscale x1: 5.391\n",
      "Lengthscale x2: 6.381\n",
      "Outputscale: 1.506\n",
      "Noise: 0.064290\n",
      "region_upper_byrd dfNGP Epoch 251/2000, Training Loss (NLML): 5.7033\n",
      "Lengthscale x1: 5.177\n",
      "Lengthscale x2: 6.176\n",
      "Outputscale: 1.546\n",
      "Noise: 0.073627\n",
      "region_upper_byrd dfNGP Epoch 301/2000, Training Loss (NLML): 4.9978\n",
      "Lengthscale x1: 4.981\n",
      "Lengthscale x2: 5.997\n",
      "Outputscale: 1.585\n",
      "Noise: 0.083365\n",
      "region_upper_byrd dfNGP Epoch 351/2000, Training Loss (NLML): 4.4364\n",
      "Lengthscale x1: 4.802\n",
      "Lengthscale x2: 5.838\n",
      "Outputscale: 1.623\n",
      "Noise: 0.093438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:22:33] Energy consumed for RAM : 0.000891 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:22:34] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:22:34] Energy consumed for All CPU : 0.000758 kWh\n",
      "[codecarbon INFO @ 12:22:34] Energy consumed for all GPUs : 0.003582 kWh. Total GPU Power : 77.09139972683863 W\n",
      "[codecarbon INFO @ 12:22:34] 0.005230 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 401/2000, Training Loss (NLML): 3.9927\n",
      "Lengthscale x1: 4.638\n",
      "Lengthscale x2: 5.695\n",
      "Outputscale: 1.659\n",
      "Noise: 0.103784\n",
      "region_upper_byrd dfNGP Epoch 451/2000, Training Loss (NLML): 3.6334\n",
      "Lengthscale x1: 4.485\n",
      "Lengthscale x2: 5.568\n",
      "Outputscale: 1.695\n",
      "Noise: 0.114377\n",
      "region_upper_byrd dfNGP Epoch 501/2000, Training Loss (NLML): 3.3365\n",
      "Lengthscale x1: 4.344\n",
      "Lengthscale x2: 5.453\n",
      "Outputscale: 1.729\n",
      "Noise: 0.125195\n",
      "region_upper_byrd dfNGP Epoch 551/2000, Training Loss (NLML): 3.0858\n",
      "Lengthscale x1: 4.213\n",
      "Lengthscale x2: 5.349\n",
      "Outputscale: 1.762\n",
      "Noise: 0.136213\n",
      "region_upper_byrd dfNGP Epoch 601/2000, Training Loss (NLML): 2.8711\n",
      "Lengthscale x1: 4.091\n",
      "Lengthscale x2: 5.254\n",
      "Outputscale: 1.793\n",
      "Noise: 0.147409\n",
      "region_upper_byrd dfNGP Epoch 651/2000, Training Loss (NLML): 2.7034\n",
      "Lengthscale x1: 3.978\n",
      "Lengthscale x2: 5.167\n",
      "Outputscale: 1.823\n",
      "Noise: 0.158745\n",
      "region_upper_byrd dfNGP Epoch 701/2000, Training Loss (NLML): 2.5506\n",
      "Lengthscale x1: 3.871\n",
      "Lengthscale x2: 5.088\n",
      "Outputscale: 1.853\n",
      "Noise: 0.170195\n",
      "region_upper_byrd dfNGP Epoch 751/2000, Training Loss (NLML): 2.4106\n",
      "Lengthscale x1: 3.772\n",
      "Lengthscale x2: 5.016\n",
      "Outputscale: 1.881\n",
      "Noise: 0.181753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:22:48] Energy consumed for RAM : 0.000972 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:22:49] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:22:49] Energy consumed for All CPU : 0.000826 kWh\n",
      "[codecarbon INFO @ 12:22:49] Energy consumed for all GPUs : 0.003903 kWh. Total GPU Power : 77.18803413774276 W\n",
      "[codecarbon INFO @ 12:22:49] 0.005701 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 801/2000, Training Loss (NLML): 2.3001\n",
      "Lengthscale x1: 3.679\n",
      "Lengthscale x2: 4.950\n",
      "Outputscale: 1.908\n",
      "Noise: 0.193379\n",
      "region_upper_byrd dfNGP Epoch 851/2000, Training Loss (NLML): 2.2088\n",
      "Lengthscale x1: 3.591\n",
      "Lengthscale x2: 4.889\n",
      "Outputscale: 1.934\n",
      "Noise: 0.205056\n",
      "region_upper_byrd dfNGP Epoch 901/2000, Training Loss (NLML): 2.1179\n",
      "Lengthscale x1: 3.509\n",
      "Lengthscale x2: 4.835\n",
      "Outputscale: 1.959\n",
      "Noise: 0.216769\n",
      "region_upper_byrd dfNGP Epoch 951/2000, Training Loss (NLML): 2.0428\n",
      "Lengthscale x1: 3.431\n",
      "Lengthscale x2: 4.783\n",
      "Outputscale: 1.984\n",
      "Noise: 0.228496\n",
      "region_upper_byrd dfNGP Epoch 1001/2000, Training Loss (NLML): 1.9760\n",
      "Lengthscale x1: 3.358\n",
      "Lengthscale x2: 4.736\n",
      "Outputscale: 2.007\n",
      "Noise: 0.240210\n",
      "region_upper_byrd dfNGP Epoch 1051/2000, Training Loss (NLML): 1.9205\n",
      "Lengthscale x1: 3.290\n",
      "Lengthscale x2: 4.692\n",
      "Outputscale: 2.030\n",
      "Noise: 0.251912\n",
      "region_upper_byrd dfNGP Epoch 1101/2000, Training Loss (NLML): 1.8614\n",
      "Lengthscale x1: 3.225\n",
      "Lengthscale x2: 4.651\n",
      "Outputscale: 2.052\n",
      "Noise: 0.263581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:03] Energy consumed for RAM : 0.001052 kWh. RAM Power : 20.0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 1151/2000, Training Loss (NLML): 1.8152\n",
      "Lengthscale x1: 3.163\n",
      "Lengthscale x2: 4.613\n",
      "Outputscale: 2.073\n",
      "Noise: 0.275201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:04] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:23:04] Energy consumed for All CPU : 0.000894 kWh\n",
      "[codecarbon INFO @ 12:23:04] Energy consumed for all GPUs : 0.004225 kWh. Total GPU Power : 77.33461405649705 W\n",
      "[codecarbon INFO @ 12:23:04] 0.006172 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 1201/2000, Training Loss (NLML): 1.7754\n",
      "Lengthscale x1: 3.105\n",
      "Lengthscale x2: 4.576\n",
      "Outputscale: 2.094\n",
      "Noise: 0.286753\n",
      "region_upper_byrd dfNGP Epoch 1251/2000, Training Loss (NLML): 1.7377\n",
      "Lengthscale x1: 3.051\n",
      "Lengthscale x2: 4.542\n",
      "Outputscale: 2.114\n",
      "Noise: 0.298228\n",
      "region_upper_byrd dfNGP Epoch 1301/2000, Training Loss (NLML): 1.7056\n",
      "Lengthscale x1: 2.999\n",
      "Lengthscale x2: 4.510\n",
      "Outputscale: 2.134\n",
      "Noise: 0.309608\n",
      "region_upper_byrd dfNGP Epoch 1351/2000, Training Loss (NLML): 1.6695\n",
      "Lengthscale x1: 2.952\n",
      "Lengthscale x2: 4.480\n",
      "Outputscale: 2.152\n",
      "Noise: 0.320887\n",
      "region_upper_byrd dfNGP Epoch 1401/2000, Training Loss (NLML): 1.6451\n",
      "Lengthscale x1: 2.908\n",
      "Lengthscale x2: 4.452\n",
      "Outputscale: 2.170\n",
      "Noise: 0.332063\n",
      "region_upper_byrd dfNGP Epoch 1451/2000, Training Loss (NLML): 1.6241\n",
      "Lengthscale x1: 2.867\n",
      "Lengthscale x2: 4.426\n",
      "Outputscale: 2.188\n",
      "Noise: 0.343122\n",
      "region_upper_byrd dfNGP Epoch 1501/2000, Training Loss (NLML): 1.5954\n",
      "Lengthscale x1: 2.830\n",
      "Lengthscale x2: 4.401\n",
      "Outputscale: 2.205\n",
      "Noise: 0.354075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:18] Energy consumed for RAM : 0.001133 kWh. RAM Power : 20.0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 1551/2000, Training Loss (NLML): 1.5776\n",
      "Lengthscale x1: 2.796\n",
      "Lengthscale x2: 4.378\n",
      "Outputscale: 2.221\n",
      "Noise: 0.364886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:19] Delta energy consumed for CPU with cpu_load : 0.000068 kWh, power : 17.0 W\n",
      "[codecarbon INFO @ 12:23:19] Energy consumed for All CPU : 0.000963 kWh\n",
      "[codecarbon INFO @ 12:23:19] Energy consumed for all GPUs : 0.004547 kWh. Total GPU Power : 77.29906584196952 W\n",
      "[codecarbon INFO @ 12:23:19] 0.006643 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 1601/2000, Training Loss (NLML): 1.5556\n",
      "Lengthscale x1: 2.764\n",
      "Lengthscale x2: 4.357\n",
      "Outputscale: 2.237\n",
      "Noise: 0.375579\n",
      "region_upper_byrd dfNGP Epoch 1651/2000, Training Loss (NLML): 1.5418\n",
      "Lengthscale x1: 2.735\n",
      "Lengthscale x2: 4.339\n",
      "Outputscale: 2.252\n",
      "Noise: 0.386112\n",
      "region_upper_byrd dfNGP Epoch 1701/2000, Training Loss (NLML): 1.5245\n",
      "Lengthscale x1: 2.708\n",
      "Lengthscale x2: 4.322\n",
      "Outputscale: 2.266\n",
      "Noise: 0.396537\n",
      "region_upper_byrd dfNGP Epoch 1751/2000, Training Loss (NLML): 1.5112\n",
      "Lengthscale x1: 2.684\n",
      "Lengthscale x2: 4.308\n",
      "Outputscale: 2.280\n",
      "Noise: 0.406782\n",
      "region_upper_byrd dfNGP Epoch 1801/2000, Training Loss (NLML): 1.4933\n",
      "Lengthscale x1: 2.663\n",
      "Lengthscale x2: 4.296\n",
      "Outputscale: 2.293\n",
      "Noise: 0.416875\n",
      "region_upper_byrd dfNGP Epoch 1851/2000, Training Loss (NLML): 1.4818\n",
      "Lengthscale x1: 2.644\n",
      "Lengthscale x2: 4.287\n",
      "Outputscale: 2.306\n",
      "Noise: 0.426810\n",
      "region_upper_byrd dfNGP Epoch 1901/2000, Training Loss (NLML): 1.4756\n",
      "Lengthscale x1: 2.627\n",
      "Lengthscale x2: 4.279\n",
      "Outputscale: 2.319\n",
      "Noise: 0.436570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:33] Energy consumed for RAM : 0.001213 kWh. RAM Power : 20.0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_upper_byrd dfNGP Epoch 1951/2000, Training Loss (NLML): 1.4601\n",
      "Lengthscale x1: 2.613\n",
      "Lengthscale x2: 4.275\n",
      "Outputscale: 2.331\n",
      "Noise: 0.446139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 12:23:34] Delta energy consumed for CPU with cpu_load : 0.000069 kWh, power : 17.1275 W\n",
      "[codecarbon INFO @ 12:23:34] Energy consumed for All CPU : 0.001032 kWh\n",
      "[codecarbon INFO @ 12:23:34] Energy consumed for all GPUs : 0.004871 kWh. Total GPU Power : 77.64778546564197 W\n",
      "[codecarbon INFO @ 12:23:34] 0.007116 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:23:35] Energy consumed for RAM : 0.001223 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 12:23:36] Delta energy consumed for CPU with cpu_load : 0.000009 kWh, power : 18.4025 W\n",
      "[codecarbon INFO @ 12:23:36] Energy consumed for All CPU : 0.001041 kWh\n",
      "[codecarbon INFO @ 12:23:36] Energy consumed for all GPUs : 0.004919 kWh. Total GPU Power : 78.29739211425156 W\n",
      "[codecarbon INFO @ 12:23:36] 0.007182 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 12:23:36] 0.017187 g.CO2eq/s mean an estimation of 542.0119306886696 kg.CO2eq/year\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dfNGP\"\n",
    "from gpytorch_models import dfNGP\n",
    "\n",
    "# import configs to we can access the hypers with getattr\n",
    "import configs\n",
    "from configs import N_SIDE_INFERENCE\n",
    "from configs import PATIENCE, MAX_NUM_EPOCHS, WEIGHT_DECAY\n",
    "from configs import TRACK_EMISSIONS_BOOL\n",
    "from configs import SCALE_INPUT_region_lower_byrd, SCALE_INPUT_region_mid_byrd, SCALE_INPUT_region_upper_byrd\n",
    "from configs import REAL_L_RANGE, REAL_NOISE_VAR_RANGE, REAL_OUTPUTSCALE_VAR_RANGE\n",
    "\n",
    "SCALE_INPUT = {\n",
    "    \"region_lower_byrd\": SCALE_INPUT_region_lower_byrd,\n",
    "    \"region_mid_byrd\": SCALE_INPUT_region_mid_byrd,\n",
    "    \"region_upper_byrd\": SCALE_INPUT_region_upper_byrd,\n",
    "}\n",
    "\n",
    "# Reiterating import for visibility\n",
    "MAX_NUM_EPOCHS = MAX_NUM_EPOCHS\n",
    "WEIGHT_DECAY = WEIGHT_DECAY\n",
    "PATIENCE = PATIENCE\n",
    "\n",
    "# assign model-specific variable\n",
    "MODEL_LEARNING_RATE = getattr(configs, f\"{model_name}_REAL_LEARNING_RATE\")\n",
    "# define results directory\n",
    "RESULTS_DIR = \"results_real/dfNGP_grid_inference\"\n",
    "import os\n",
    "\n",
    "# basics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "# universals \n",
    "from utils import set_seed, make_grid\n",
    "import gc\n",
    "import warnings\n",
    "set_seed(42)\n",
    "\n",
    "# setting device to GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# overwrite if needed: # device = 'cpu'\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "### START TIMING ###\n",
    "import time\n",
    "start_time = time.time()  # Start timing after imports\n",
    "\n",
    "### START TRACKING EXPERIMENT EMISSIONS ###\n",
    "if TRACK_EMISSIONS_BOOL:\n",
    "    from codecarbon import EmissionsTracker\n",
    "    tracker = EmissionsTracker(project_name = \"dfNGP_real_grid_inference\", output_dir = RESULTS_DIR)\n",
    "    tracker.start()\n",
    "\n",
    "#############################\n",
    "### LOOP 1 - over REGIONS ###\n",
    "#############################\n",
    "\n",
    "for region_name in [\"region_lower_byrd\", \"region_mid_byrd\", \"region_upper_byrd\"]:\n",
    "    SCALE_DOMAIN = SCALE_INPUT[region_name]\n",
    "\n",
    "    print(f\"\\nTraining for {region_name.upper()}...\")\n",
    "\n",
    "    # Store metrics for the current region (used for *metrics_summary* report and *metrics_per_run*)\n",
    "    region_results = []\n",
    "\n",
    "    ##########################################\n",
    "    ### x_train & y_train, x_test & x_test ###\n",
    "    ##########################################\n",
    "\n",
    "    # define paths based on region_name\n",
    "    path_to_training_tensor = \"data/real_data/\" + region_name + \"_train_tensor.pt\"\n",
    "    path_to_test_tensor = \"data/real_data/\" + region_name + \"_test_tensor.pt\"\n",
    "\n",
    "    # load and tranpose to have rows as points\n",
    "    train = torch.load(path_to_training_tensor, weights_only = False).T \n",
    "    test = torch.load(path_to_test_tensor, weights_only = False).T\n",
    "\n",
    "    # The train and test tensors have the following columns:\n",
    "    # [:, 0] = x\n",
    "    # [:, 1] = y\n",
    "    # [:, 2] = surface elevation (s)\n",
    "    # [:, 3] = ice flux in x direction (u)\n",
    "    # [:, 4] = ice flux in y direction (v)\n",
    "    # [:, 5] = ice flux error in x direction (u_err)\n",
    "    # [:, 6] = ice flux error in y direction (v_err)\n",
    "    # [:, 7] = source age\n",
    "\n",
    "    # train\n",
    "    x_train = train[:, [0, 1]].to(device)\n",
    "    y_train = train[:, [3, 4]].to(device)\n",
    "\n",
    "    # test\n",
    "    x_test = test[:, [0, 1]].to(device)\n",
    "    y_test = test[:, [3, 4]].to(device)\n",
    "\n",
    "    # HACK: Scaling helps with numerical stability\n",
    "    # Units are not in km \n",
    "    x_test = x_test * SCALE_DOMAIN\n",
    "    x_train = x_train * SCALE_DOMAIN\n",
    "\n",
    "    # Now we combine the training inputs and observations into a single tensor to train our best predictive model\n",
    "    x_train_grid = torch.concat((x_train, x_test), dim = 0).to(device)\n",
    "    y_train_grid = torch.concat((y_test, y_train), dim = 0).to(device)\n",
    "\n",
    "    # Make test aka inference grid\n",
    "    _, x_test_grid = make_grid(n_side = N_SIDE_INFERENCE)\n",
    "    x_test_grid = x_test_grid * SCALE_DOMAIN # scale grid to match training data\n",
    "    x_test_grid.requires_grad_(True) # need gradients for divergence field\n",
    "\n",
    "    # NOTE: Here we estimate the noise variance \n",
    "\n",
    "    # Print train details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Training inputs shape: {x_train_grid.shape}\")\n",
    "    print(f\"Training observations shape: {y_train_grid.shape}\")\n",
    "    print(f\"Training inputs dtype: {x_train_grid.dtype}\")\n",
    "    print()\n",
    "\n",
    "    # Print test details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Test inputs shape: {x_test_grid.shape}\")\n",
    "    # NOTE: No test observations, only inputs\n",
    "    print(f\"Test inputs dtype: {x_test_grid.dtype}\")\n",
    "    print()\n",
    "\n",
    "    #####################\n",
    "    ### SPECFIY MODEL ###\n",
    "    #####################\n",
    "\n",
    "    print(f\"\\n--- Training starts ---\")\n",
    "\n",
    "    # Initialise the likelihood for the GP model (estimates noise)\n",
    "    # NOTE: we use a multitask likelihood for the dfNGP model but with a global noise term\n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\n",
    "        num_tasks = 2,\n",
    "        has_global_noise = True, \n",
    "        has_task_noise = False, # HACK: This still needs to be manually turned off\n",
    "        ).to(device)\n",
    "\n",
    "    # NOTE: This was needed\n",
    "    x_train_grid = x_train_grid.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Use all data to train the grid model\n",
    "    model = dfNGP(\n",
    "        x_train_grid,\n",
    "        y_train_grid, \n",
    "        likelihood\n",
    "        ).to(device)\n",
    "    \n",
    "    # Initialise hypers\n",
    "    # NOTE: Alternative is to start with best hypers from previously trained model\n",
    "    # Overwrite default lengthscale hyperparameter initialisation because we have a different input scale.\n",
    "    model.base_kernel.lengthscale = torch.empty([1, 2], device = device).uniform_( * REAL_L_RANGE)\n",
    "    # Overwrite default outputscale variance initialisation.\n",
    "    model.covar_module.outputscale = torch.empty(1, device = device).uniform_( * REAL_OUTPUTSCALE_VAR_RANGE)\n",
    "    # Overwrite default noise variance initialisation because this is real noisy data.\n",
    "    model.likelihood.noise = torch.empty(1, device = device).uniform_( * REAL_NOISE_VAR_RANGE)\n",
    "\n",
    "    # NOTE: This part is different from dfGP\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {\"params\": model.mean_module.parameters(), \n",
    "            \"weight_decay\": WEIGHT_DECAY, \"lr\": MODEL_LEARNING_RATE * 0.2},\n",
    "        {\"params\": list(model.covar_module.parameters()) + list(model.likelihood.parameters()), \n",
    "            \"weight_decay\":  WEIGHT_DECAY, \"lr\": MODEL_LEARNING_RATE},\n",
    "        ])\n",
    "    \n",
    "    # Use ExactMarginalLogLikelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_loss = float('inf')\n",
    "    # counter starts at 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    ############################\n",
    "    ### LOOP 2 - over EPOCHS ###\n",
    "    ############################\n",
    "    print(\"\\nStart Training\")\n",
    "\n",
    "    for epoch in range(MAX_NUM_EPOCHS):\n",
    "\n",
    "        # Set to train\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "\n",
    "        # Do a step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_train_grid = x_train_grid.clone().detach().requires_grad_(True)\n",
    "        train_pred_dist = model(x_train_grid.to(device))\n",
    "        loss = - mll(train_pred_dist, y_train_grid.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"{region_name} {model_name} Epoch {epoch + 1}/{MAX_NUM_EPOCHS}, Training Loss (NLML): {loss:.4f}\")\n",
    "            print(f\"Lengthscale x1: {model.base_kernel.lengthscale[:,0].cpu().detach().numpy().item():.3f}\")\n",
    "            print(f\"Lengthscale x2: {model.base_kernel.lengthscale[:,1].cpu().detach().numpy().item():.3f}\")\n",
    "            print(f\"Outputscale: {model.covar_module.outputscale.cpu().detach().numpy().item():.3f}\")\n",
    "            print(f\"Noise: {model.likelihood.noise.cpu().detach().numpy().item():3f}\")\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            # reset counter if loss improves\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            # exit epoch loop\n",
    "            break\n",
    "    \n",
    "    #################\n",
    "    ### INFERENCE ###\n",
    "    #################\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    x_test_grid.requires_grad_(True)\n",
    "\n",
    "    dist_grid = model(x_test_grid.to(device))\n",
    "    pred_dist_grid = likelihood(dist_grid)\n",
    "\n",
    "    torch.save(pred_dist_grid.mean, f\"{RESULTS_DIR}/{region_name}_{model_name}_grid_mean_predictions.pt\")\n",
    "    torch.save(pred_dist_grid.covariance_matrix, f\"{RESULTS_DIR}/{region_name}_{model_name}_grid_covar_predictions.pt\")\n",
    "    torch.save(dist_grid.covariance_matrix, f\"{RESULTS_DIR}/{region_name}_{model_name}_grid_latent_covar_predictions.pt\")\n",
    "\n",
    "#################################\n",
    "### END LOOP 1 - over REGIONS ###\n",
    "#################################\n",
    "\n",
    "# also end emission tracking. Will be saved as emissions.csv\n",
    "if TRACK_EMISSIONS_BOOL:\n",
    "    tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice_thickness_gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
