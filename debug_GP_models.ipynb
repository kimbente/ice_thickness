{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05307ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.00 MB\n",
      "Cached:    0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Cached:    {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8b675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "\n",
      "Training for REGIONC...\n",
      "=== REGIONC ===\n",
      "Training inputs shape: torch.Size([462, 2])\n",
      "Training observations shape: torch.Size([462, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== REGIONC ===\n",
      "Test inputs shape: torch.Size([115, 2])\n",
      "Test observations shape: torch.Size([115, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "\n",
      "--- Training Run 1/1 ---\n",
      "\n",
      "Start Training\n",
      "regionc dfNGP Run 1/1, Epoch 1/2000, Training Loss (NLML): 64446.4648, (RMSE): 0.3756\n",
      "regionc dfNGP Run 1/1, Epoch 2/2000, Training Loss (NLML): 63928.1055, (RMSE): 0.3733\n",
      "regionc dfNGP Run 1/1, Epoch 3/2000, Training Loss (NLML): 63227.0391, (RMSE): 0.3716\n",
      "regionc dfNGP Run 1/1, Epoch 4/2000, Training Loss (NLML): 62845.0547, (RMSE): 0.3703\n",
      "regionc dfNGP Run 1/1, Epoch 5/2000, Training Loss (NLML): 62135.0117, (RMSE): 0.3687\n",
      "regionc dfNGP Run 1/1, Epoch 6/2000, Training Loss (NLML): 61321.2656, (RMSE): 0.3657\n",
      "regionc dfNGP Run 1/1, Epoch 7/2000, Training Loss (NLML): 60987.1094, (RMSE): 0.3641\n",
      "regionc dfNGP Run 1/1, Epoch 8/2000, Training Loss (NLML): 60320.9688, (RMSE): 0.3626\n",
      "regionc dfNGP Run 1/1, Epoch 9/2000, Training Loss (NLML): 59191.4883, (RMSE): 0.3600\n",
      "regionc dfNGP Run 1/1, Epoch 10/2000, Training Loss (NLML): 58754.2070, (RMSE): 0.3595\n",
      "regionc dfNGP Run 1/1, Epoch 11/2000, Training Loss (NLML): 58195.5781, (RMSE): 0.3576\n",
      "regionc dfNGP Run 1/1, Epoch 12/2000, Training Loss (NLML): 57471.3711, (RMSE): 0.3560\n",
      "regionc dfNGP Run 1/1, Epoch 13/2000, Training Loss (NLML): 56876.4570, (RMSE): 0.3541\n",
      "regionc dfNGP Run 1/1, Epoch 14/2000, Training Loss (NLML): 56464.6602, (RMSE): 0.3530\n",
      "regionc dfNGP Run 1/1, Epoch 15/2000, Training Loss (NLML): 55793.2695, (RMSE): 0.3497\n",
      "regionc dfNGP Run 1/1, Epoch 16/2000, Training Loss (NLML): 54612.4805, (RMSE): 0.3488\n",
      "regionc dfNGP Run 1/1, Epoch 17/2000, Training Loss (NLML): 53862.7773, (RMSE): 0.3463\n",
      "regionc dfNGP Run 1/1, Epoch 18/2000, Training Loss (NLML): 53329.4297, (RMSE): 0.3450\n",
      "regionc dfNGP Run 1/1, Epoch 19/2000, Training Loss (NLML): 53059.0195, (RMSE): 0.3434\n",
      "regionc dfNGP Run 1/1, Epoch 20/2000, Training Loss (NLML): 52320.5508, (RMSE): 0.3419\n",
      "regionc dfNGP Run 1/1, Epoch 21/2000, Training Loss (NLML): 51802.0859, (RMSE): 0.3408\n",
      "regionc dfNGP Run 1/1, Epoch 22/2000, Training Loss (NLML): 51642.1641, (RMSE): 0.3392\n",
      "regionc dfNGP Run 1/1, Epoch 23/2000, Training Loss (NLML): 50993.5898, (RMSE): 0.3375\n",
      "regionc dfNGP Run 1/1, Epoch 24/2000, Training Loss (NLML): 50313.0352, (RMSE): 0.3365\n",
      "regionc dfNGP Run 1/1, Epoch 25/2000, Training Loss (NLML): 49787.1016, (RMSE): 0.3334\n",
      "regionc dfNGP Run 1/1, Epoch 26/2000, Training Loss (NLML): 48191.2930, (RMSE): 0.3330\n",
      "regionc dfNGP Run 1/1, Epoch 27/2000, Training Loss (NLML): 47731.9062, (RMSE): 0.3305\n",
      "regionc dfNGP Run 1/1, Epoch 28/2000, Training Loss (NLML): 47424.4141, (RMSE): 0.3288\n",
      "regionc dfNGP Run 1/1, Epoch 29/2000, Training Loss (NLML): 46345.8867, (RMSE): 0.3260\n",
      "regionc dfNGP Run 1/1, Epoch 30/2000, Training Loss (NLML): 45873.4492, (RMSE): 0.3244\n",
      "regionc dfNGP Run 1/1, Epoch 31/2000, Training Loss (NLML): 45242.4883, (RMSE): 0.3222\n",
      "regionc dfNGP Run 1/1, Epoch 32/2000, Training Loss (NLML): 45527.6602, (RMSE): 0.3203\n",
      "regionc dfNGP Run 1/1, Epoch 33/2000, Training Loss (NLML): 45104.7305, (RMSE): 0.3183\n",
      "regionc dfNGP Run 1/1, Epoch 34/2000, Training Loss (NLML): 43793.3125, (RMSE): 0.3157\n",
      "regionc dfNGP Run 1/1, Epoch 35/2000, Training Loss (NLML): 43178.0469, (RMSE): 0.3130\n",
      "regionc dfNGP Run 1/1, Epoch 36/2000, Training Loss (NLML): 43506.8906, (RMSE): 0.3122\n",
      "regionc dfNGP Run 1/1, Epoch 37/2000, Training Loss (NLML): 42663.9648, (RMSE): 0.3105\n",
      "regionc dfNGP Run 1/1, Epoch 38/2000, Training Loss (NLML): 41499.0977, (RMSE): 0.3045\n",
      "regionc dfNGP Run 1/1, Epoch 39/2000, Training Loss (NLML): 40759.1992, (RMSE): 0.3048\n",
      "regionc dfNGP Run 1/1, Epoch 40/2000, Training Loss (NLML): 39510.1875, (RMSE): 0.3040\n",
      "regionc dfNGP Run 1/1, Epoch 41/2000, Training Loss (NLML): 39363.4023, (RMSE): 0.3009\n",
      "regionc dfNGP Run 1/1, Epoch 42/2000, Training Loss (NLML): 38841.5664, (RMSE): 0.2975\n",
      "regionc dfNGP Run 1/1, Epoch 43/2000, Training Loss (NLML): 38228.3789, (RMSE): 0.2986\n",
      "regionc dfNGP Run 1/1, Epoch 44/2000, Training Loss (NLML): 38671.2812, (RMSE): 0.2947\n",
      "regionc dfNGP Run 1/1, Epoch 45/2000, Training Loss (NLML): 36864.5742, (RMSE): 0.2935\n",
      "regionc dfNGP Run 1/1, Epoch 46/2000, Training Loss (NLML): 3526.2852, (RMSE): 0.3110\n",
      "regionc dfNGP Run 1/1, Epoch 47/2000, Training Loss (NLML): 3472.3464, (RMSE): 0.3092\n",
      "regionc dfNGP Run 1/1, Epoch 48/2000, Training Loss (NLML): 3386.6799, (RMSE): 0.3057\n",
      "regionc dfNGP Run 1/1, Epoch 49/2000, Training Loss (NLML): 3331.3962, (RMSE): 0.3038\n",
      "regionc dfNGP Run 1/1, Epoch 50/2000, Training Loss (NLML): 3314.8135, (RMSE): 0.3033\n",
      "regionc dfNGP Run 1/1, Epoch 51/2000, Training Loss (NLML): 3297.1619, (RMSE): 0.3021\n",
      "regionc dfNGP Run 1/1, Epoch 52/2000, Training Loss (NLML): 3289.9448, (RMSE): 0.3009\n",
      "regionc dfNGP Run 1/1, Epoch 53/2000, Training Loss (NLML): 3261.5618, (RMSE): 0.3002\n",
      "regionc dfNGP Run 1/1, Epoch 54/2000, Training Loss (NLML): 3231.8926, (RMSE): 0.2989\n",
      "regionc dfNGP Run 1/1, Epoch 55/2000, Training Loss (NLML): 3205.1282, (RMSE): 0.2974\n",
      "regionc dfNGP Run 1/1, Epoch 56/2000, Training Loss (NLML): 3176.9839, (RMSE): 0.2964\n",
      "regionc dfNGP Run 1/1, Epoch 57/2000, Training Loss (NLML): 3157.8181, (RMSE): 0.2957\n",
      "regionc dfNGP Run 1/1, Epoch 58/2000, Training Loss (NLML): 3115.3740, (RMSE): 0.2940\n",
      "regionc dfNGP Run 1/1, Epoch 59/2000, Training Loss (NLML): 3098.5378, (RMSE): 0.2935\n",
      "regionc dfNGP Run 1/1, Epoch 60/2000, Training Loss (NLML): 3102.4922, (RMSE): 0.2928\n",
      "regionc dfNGP Run 1/1, Epoch 61/2000, Training Loss (NLML): 3080.5613, (RMSE): 0.2918\n",
      "regionc dfNGP Run 1/1, Epoch 62/2000, Training Loss (NLML): 3067.3059, (RMSE): 0.2908\n",
      "regionc dfNGP Run 1/1, Epoch 63/2000, Training Loss (NLML): 3050.9724, (RMSE): 0.2906\n",
      "regionc dfNGP Run 1/1, Epoch 64/2000, Training Loss (NLML): 3002.5989, (RMSE): 0.2889\n",
      "regionc dfNGP Run 1/1, Epoch 65/2000, Training Loss (NLML): 3005.1970, (RMSE): 0.2887\n",
      "regionc dfNGP Run 1/1, Epoch 66/2000, Training Loss (NLML): 2992.3000, (RMSE): 0.2885\n",
      "regionc dfNGP Run 1/1, Epoch 67/2000, Training Loss (NLML): 2979.0010, (RMSE): 0.2873\n",
      "regionc dfNGP Run 1/1, Epoch 68/2000, Training Loss (NLML): 2929.4348, (RMSE): 0.2862\n",
      "regionc dfNGP Run 1/1, Epoch 69/2000, Training Loss (NLML): 2910.6919, (RMSE): 0.2845\n",
      "regionc dfNGP Run 1/1, Epoch 70/2000, Training Loss (NLML): 2919.1333, (RMSE): 0.2844\n",
      "regionc dfNGP Run 1/1, Epoch 71/2000, Training Loss (NLML): 2881.6208, (RMSE): 0.2838\n",
      "regionc dfNGP Run 1/1, Epoch 72/2000, Training Loss (NLML): 2861.1228, (RMSE): 0.2826\n",
      "regionc dfNGP Run 1/1, Epoch 73/2000, Training Loss (NLML): 2900.0337, (RMSE): 0.2835\n",
      "regionc dfNGP Run 1/1, Epoch 74/2000, Training Loss (NLML): 2889.1516, (RMSE): 0.2834\n",
      "regionc dfNGP Run 1/1, Epoch 75/2000, Training Loss (NLML): 2871.6121, (RMSE): 0.2822\n",
      "regionc dfNGP Run 1/1, Epoch 76/2000, Training Loss (NLML): 2850.1877, (RMSE): 0.2815\n",
      "regionc dfNGP Run 1/1, Epoch 77/2000, Training Loss (NLML): 2803.3865, (RMSE): 0.2806\n",
      "regionc dfNGP Run 1/1, Epoch 78/2000, Training Loss (NLML): 2866.9268, (RMSE): 0.2815\n",
      "regionc dfNGP Run 1/1, Epoch 79/2000, Training Loss (NLML): 2820.2617, (RMSE): 0.2799\n",
      "regionc dfNGP Run 1/1, Epoch 80/2000, Training Loss (NLML): 2802.9087, (RMSE): 0.2796\n",
      "regionc dfNGP Run 1/1, Epoch 81/2000, Training Loss (NLML): 2808.3557, (RMSE): 0.2797\n",
      "regionc dfNGP Run 1/1, Epoch 82/2000, Training Loss (NLML): 2769.9910, (RMSE): 0.2776\n",
      "regionc dfNGP Run 1/1, Epoch 83/2000, Training Loss (NLML): 2755.8118, (RMSE): 0.2771\n",
      "regionc dfNGP Run 1/1, Epoch 84/2000, Training Loss (NLML): 2765.1565, (RMSE): 0.2774\n",
      "regionc dfNGP Run 1/1, Epoch 85/2000, Training Loss (NLML): 2718.4844, (RMSE): 0.2761\n",
      "regionc dfNGP Run 1/1, Epoch 86/2000, Training Loss (NLML): 2724.6360, (RMSE): 0.2762\n",
      "regionc dfNGP Run 1/1, Epoch 87/2000, Training Loss (NLML): 2700.2759, (RMSE): 0.2752\n",
      "regionc dfNGP Run 1/1, Epoch 88/2000, Training Loss (NLML): 2696.1843, (RMSE): 0.2737\n",
      "regionc dfNGP Run 1/1, Epoch 89/2000, Training Loss (NLML): 2663.0818, (RMSE): 0.2736\n",
      "regionc dfNGP Run 1/1, Epoch 90/2000, Training Loss (NLML): 2657.1248, (RMSE): 0.2735\n",
      "regionc dfNGP Run 1/1, Epoch 91/2000, Training Loss (NLML): 2634.8992, (RMSE): 0.2724\n",
      "regionc dfNGP Run 1/1, Epoch 92/2000, Training Loss (NLML): 2611.2954, (RMSE): 0.2720\n",
      "regionc dfNGP Run 1/1, Epoch 93/2000, Training Loss (NLML): 2600.9958, (RMSE): 0.2713\n",
      "regionc dfNGP Run 1/1, Epoch 94/2000, Training Loss (NLML): 2599.8696, (RMSE): 0.2707\n",
      "regionc dfNGP Run 1/1, Epoch 95/2000, Training Loss (NLML): 2574.6738, (RMSE): 0.2708\n",
      "regionc dfNGP Run 1/1, Epoch 96/2000, Training Loss (NLML): 2583.1064, (RMSE): 0.2708\n",
      "regionc dfNGP Run 1/1, Epoch 97/2000, Training Loss (NLML): 2578.9045, (RMSE): 0.2713\n",
      "regionc dfNGP Run 1/1, Epoch 98/2000, Training Loss (NLML): 2570.5127, (RMSE): 0.2697\n",
      "regionc dfNGP Run 1/1, Epoch 99/2000, Training Loss (NLML): 2572.4583, (RMSE): 0.2702\n",
      "regionc dfNGP Run 1/1, Epoch 100/2000, Training Loss (NLML): 2537.6101, (RMSE): 0.2689\n",
      "regionc dfNGP Run 1/1, Epoch 101/2000, Training Loss (NLML): 2535.6919, (RMSE): 0.2688\n",
      "regionc dfNGP Run 1/1, Epoch 102/2000, Training Loss (NLML): 2543.3647, (RMSE): 0.2693\n",
      "regionc dfNGP Run 1/1, Epoch 103/2000, Training Loss (NLML): 2540.5647, (RMSE): 0.2703\n",
      "regionc dfNGP Run 1/1, Epoch 104/2000, Training Loss (NLML): 2531.6816, (RMSE): 0.2695\n",
      "regionc dfNGP Run 1/1, Epoch 105/2000, Training Loss (NLML): 2540.3542, (RMSE): 0.2689\n",
      "regionc dfNGP Run 1/1, Epoch 106/2000, Training Loss (NLML): 2509.1956, (RMSE): 0.2688\n",
      "regionc dfNGP Run 1/1, Epoch 107/2000, Training Loss (NLML): 2497.8601, (RMSE): 0.2676\n",
      "regionc dfNGP Run 1/1, Epoch 108/2000, Training Loss (NLML): 2472.7834, (RMSE): 0.2675\n",
      "regionc dfNGP Run 1/1, Epoch 109/2000, Training Loss (NLML): 2464.1047, (RMSE): 0.2672\n",
      "regionc dfNGP Run 1/1, Epoch 110/2000, Training Loss (NLML): 2474.6970, (RMSE): 0.2669\n",
      "regionc dfNGP Run 1/1, Epoch 111/2000, Training Loss (NLML): 2446.1030, (RMSE): 0.2665\n",
      "regionc dfNGP Run 1/1, Epoch 112/2000, Training Loss (NLML): 2446.1062, (RMSE): 0.2664\n",
      "regionc dfNGP Run 1/1, Epoch 113/2000, Training Loss (NLML): 2412.6995, (RMSE): 0.2653\n",
      "regionc dfNGP Run 1/1, Epoch 114/2000, Training Loss (NLML): 2409.0615, (RMSE): 0.2647\n",
      "regionc dfNGP Run 1/1, Epoch 115/2000, Training Loss (NLML): 2355.8931, (RMSE): 0.2641\n",
      "regionc dfNGP Run 1/1, Epoch 116/2000, Training Loss (NLML): 2329.5271, (RMSE): 0.2627\n",
      "regionc dfNGP Run 1/1, Epoch 117/2000, Training Loss (NLML): 2332.5945, (RMSE): 0.2626\n",
      "regionc dfNGP Run 1/1, Epoch 118/2000, Training Loss (NLML): 2307.1438, (RMSE): 0.2617\n",
      "regionc dfNGP Run 1/1, Epoch 119/2000, Training Loss (NLML): 2313.3232, (RMSE): 0.2618\n",
      "regionc dfNGP Run 1/1, Epoch 120/2000, Training Loss (NLML): 2301.4946, (RMSE): 0.2606\n",
      "regionc dfNGP Run 1/1, Epoch 121/2000, Training Loss (NLML): 2283.6328, (RMSE): 0.2605\n",
      "regionc dfNGP Run 1/1, Epoch 122/2000, Training Loss (NLML): 2272.6455, (RMSE): 0.2608\n",
      "regionc dfNGP Run 1/1, Epoch 123/2000, Training Loss (NLML): 2266.5220, (RMSE): 0.2601\n",
      "regionc dfNGP Run 1/1, Epoch 124/2000, Training Loss (NLML): 2240.6541, (RMSE): 0.2595\n",
      "regionc dfNGP Run 1/1, Epoch 125/2000, Training Loss (NLML): 2241.2676, (RMSE): 0.2586\n",
      "regionc dfNGP Run 1/1, Epoch 126/2000, Training Loss (NLML): 2234.5266, (RMSE): 0.2586\n",
      "regionc dfNGP Run 1/1, Epoch 127/2000, Training Loss (NLML): 2215.3975, (RMSE): 0.2581\n",
      "regionc dfNGP Run 1/1, Epoch 128/2000, Training Loss (NLML): 2210.6628, (RMSE): 0.2582\n",
      "regionc dfNGP Run 1/1, Epoch 129/2000, Training Loss (NLML): 2179.8037, (RMSE): 0.2575\n",
      "regionc dfNGP Run 1/1, Epoch 130/2000, Training Loss (NLML): 2201.0986, (RMSE): 0.2573\n",
      "regionc dfNGP Run 1/1, Epoch 131/2000, Training Loss (NLML): 2162.0889, (RMSE): 0.2561\n",
      "regionc dfNGP Run 1/1, Epoch 132/2000, Training Loss (NLML): 2140.6182, (RMSE): 0.2557\n",
      "regionc dfNGP Run 1/1, Epoch 133/2000, Training Loss (NLML): 2127.7476, (RMSE): 0.2550\n",
      "regionc dfNGP Run 1/1, Epoch 134/2000, Training Loss (NLML): 2117.3726, (RMSE): 0.2548\n",
      "regionc dfNGP Run 1/1, Epoch 135/2000, Training Loss (NLML): 2123.9172, (RMSE): 0.2547\n",
      "regionc dfNGP Run 1/1, Epoch 136/2000, Training Loss (NLML): 2084.2927, (RMSE): 0.2537\n",
      "regionc dfNGP Run 1/1, Epoch 137/2000, Training Loss (NLML): 2085.6440, (RMSE): 0.2529\n",
      "regionc dfNGP Run 1/1, Epoch 138/2000, Training Loss (NLML): 2080.6050, (RMSE): 0.2535\n",
      "regionc dfNGP Run 1/1, Epoch 139/2000, Training Loss (NLML): 2060.2219, (RMSE): 0.2528\n",
      "regionc dfNGP Run 1/1, Epoch 140/2000, Training Loss (NLML): 2051.8657, (RMSE): 0.2517\n",
      "regionc dfNGP Run 1/1, Epoch 141/2000, Training Loss (NLML): 2055.7432, (RMSE): 0.2513\n",
      "regionc dfNGP Run 1/1, Epoch 142/2000, Training Loss (NLML): 2049.2222, (RMSE): 0.2517\n",
      "regionc dfNGP Run 1/1, Epoch 143/2000, Training Loss (NLML): 2055.4993, (RMSE): 0.2520\n",
      "regionc dfNGP Run 1/1, Epoch 144/2000, Training Loss (NLML): 2034.7600, (RMSE): 0.2518\n",
      "regionc dfNGP Run 1/1, Epoch 145/2000, Training Loss (NLML): 2029.1177, (RMSE): 0.2511\n",
      "regionc dfNGP Run 1/1, Epoch 146/2000, Training Loss (NLML): 2020.6042, (RMSE): 0.2505\n",
      "regionc dfNGP Run 1/1, Epoch 147/2000, Training Loss (NLML): 1998.2839, (RMSE): 0.2497\n",
      "regionc dfNGP Run 1/1, Epoch 148/2000, Training Loss (NLML): 1989.1825, (RMSE): 0.2494\n",
      "regionc dfNGP Run 1/1, Epoch 149/2000, Training Loss (NLML): 1994.7977, (RMSE): 0.2489\n",
      "regionc dfNGP Run 1/1, Epoch 150/2000, Training Loss (NLML): 1973.8766, (RMSE): 0.2487\n",
      "regionc dfNGP Run 1/1, Epoch 151/2000, Training Loss (NLML): 1954.7097, (RMSE): 0.2479\n",
      "regionc dfNGP Run 1/1, Epoch 152/2000, Training Loss (NLML): 1964.9404, (RMSE): 0.2481\n",
      "regionc dfNGP Run 1/1, Epoch 153/2000, Training Loss (NLML): 1945.6912, (RMSE): 0.2481\n",
      "regionc dfNGP Run 1/1, Epoch 154/2000, Training Loss (NLML): 1945.3838, (RMSE): 0.2477\n",
      "regionc dfNGP Run 1/1, Epoch 155/2000, Training Loss (NLML): 1932.2448, (RMSE): 0.2472\n",
      "regionc dfNGP Run 1/1, Epoch 156/2000, Training Loss (NLML): 1902.6074, (RMSE): 0.2464\n",
      "regionc dfNGP Run 1/1, Epoch 157/2000, Training Loss (NLML): 1887.6827, (RMSE): 0.2455\n",
      "regionc dfNGP Run 1/1, Epoch 158/2000, Training Loss (NLML): 1870.5714, (RMSE): 0.2442\n",
      "regionc dfNGP Run 1/1, Epoch 159/2000, Training Loss (NLML): 1852.3055, (RMSE): 0.2443\n",
      "regionc dfNGP Run 1/1, Epoch 160/2000, Training Loss (NLML): 1844.8075, (RMSE): 0.2441\n",
      "regionc dfNGP Run 1/1, Epoch 161/2000, Training Loss (NLML): 1834.0616, (RMSE): 0.2437\n",
      "regionc dfNGP Run 1/1, Epoch 162/2000, Training Loss (NLML): 1836.5598, (RMSE): 0.2436\n",
      "regionc dfNGP Run 1/1, Epoch 163/2000, Training Loss (NLML): 1816.1954, (RMSE): 0.2432\n",
      "regionc dfNGP Run 1/1, Epoch 164/2000, Training Loss (NLML): 1786.2170, (RMSE): 0.2420\n",
      "regionc dfNGP Run 1/1, Epoch 165/2000, Training Loss (NLML): 1763.3433, (RMSE): 0.2409\n",
      "regionc dfNGP Run 1/1, Epoch 166/2000, Training Loss (NLML): 1750.4204, (RMSE): 0.2408\n",
      "regionc dfNGP Run 1/1, Epoch 167/2000, Training Loss (NLML): 1767.5590, (RMSE): 0.2409\n",
      "regionc dfNGP Run 1/1, Epoch 168/2000, Training Loss (NLML): 1758.1375, (RMSE): 0.2413\n",
      "regionc dfNGP Run 1/1, Epoch 169/2000, Training Loss (NLML): 1725.5070, (RMSE): 0.2397\n",
      "regionc dfNGP Run 1/1, Epoch 170/2000, Training Loss (NLML): 1728.3790, (RMSE): 0.2396\n",
      "regionc dfNGP Run 1/1, Epoch 171/2000, Training Loss (NLML): 1711.4043, (RMSE): 0.2391\n",
      "regionc dfNGP Run 1/1, Epoch 172/2000, Training Loss (NLML): 1708.2950, (RMSE): 0.2385\n",
      "regionc dfNGP Run 1/1, Epoch 173/2000, Training Loss (NLML): 1670.7076, (RMSE): 0.2378\n",
      "regionc dfNGP Run 1/1, Epoch 174/2000, Training Loss (NLML): 1662.3877, (RMSE): 0.2371\n",
      "regionc dfNGP Run 1/1, Epoch 175/2000, Training Loss (NLML): 1643.7919, (RMSE): 0.2367\n",
      "regionc dfNGP Run 1/1, Epoch 176/2000, Training Loss (NLML): 1637.1785, (RMSE): 0.2359\n",
      "regionc dfNGP Run 1/1, Epoch 177/2000, Training Loss (NLML): 1632.2533, (RMSE): 0.2358\n",
      "regionc dfNGP Run 1/1, Epoch 178/2000, Training Loss (NLML): 1613.8794, (RMSE): 0.2354\n",
      "regionc dfNGP Run 1/1, Epoch 179/2000, Training Loss (NLML): 1583.1040, (RMSE): 0.2338\n",
      "regionc dfNGP Run 1/1, Epoch 180/2000, Training Loss (NLML): 1571.2217, (RMSE): 0.2336\n",
      "regionc dfNGP Run 1/1, Epoch 181/2000, Training Loss (NLML): 1533.7679, (RMSE): 0.2325\n",
      "regionc dfNGP Run 1/1, Epoch 182/2000, Training Loss (NLML): 1527.7614, (RMSE): 0.2321\n",
      "regionc dfNGP Run 1/1, Epoch 183/2000, Training Loss (NLML): 1524.9783, (RMSE): 0.2318\n",
      "regionc dfNGP Run 1/1, Epoch 184/2000, Training Loss (NLML): 1491.3281, (RMSE): 0.2308\n",
      "regionc dfNGP Run 1/1, Epoch 185/2000, Training Loss (NLML): 1493.6797, (RMSE): 0.2307\n",
      "regionc dfNGP Run 1/1, Epoch 186/2000, Training Loss (NLML): 1476.6479, (RMSE): 0.2301\n",
      "regionc dfNGP Run 1/1, Epoch 187/2000, Training Loss (NLML): 1474.3073, (RMSE): 0.2303\n",
      "regionc dfNGP Run 1/1, Epoch 188/2000, Training Loss (NLML): 1492.5757, (RMSE): 0.2305\n",
      "regionc dfNGP Run 1/1, Epoch 189/2000, Training Loss (NLML): 1493.6066, (RMSE): 0.2316\n",
      "regionc dfNGP Run 1/1, Epoch 190/2000, Training Loss (NLML): 1521.7408, (RMSE): 0.2323\n",
      "regionc dfNGP Run 1/1, Epoch 191/2000, Training Loss (NLML): 1526.8730, (RMSE): 0.2321\n",
      "regionc dfNGP Run 1/1, Epoch 192/2000, Training Loss (NLML): 1557.9912, (RMSE): 0.2342\n",
      "regionc dfNGP Run 1/1, Epoch 193/2000, Training Loss (NLML): 1567.4156, (RMSE): 0.2340\n",
      "regionc dfNGP Run 1/1, Epoch 194/2000, Training Loss (NLML): 1534.4204, (RMSE): 0.2326\n",
      "regionc dfNGP Run 1/1, Epoch 195/2000, Training Loss (NLML): 1505.4556, (RMSE): 0.2309\n",
      "regionc dfNGP Run 1/1, Epoch 196/2000, Training Loss (NLML): 1455.4009, (RMSE): 0.2289\n",
      "regionc dfNGP Run 1/1, Epoch 197/2000, Training Loss (NLML): 1424.2537, (RMSE): 0.2276\n",
      "regionc dfNGP Run 1/1, Epoch 198/2000, Training Loss (NLML): 1415.1095, (RMSE): 0.2272\n",
      "regionc dfNGP Run 1/1, Epoch 199/2000, Training Loss (NLML): 1395.2783, (RMSE): 0.2258\n",
      "regionc dfNGP Run 1/1, Epoch 200/2000, Training Loss (NLML): 1388.4688, (RMSE): 0.2263\n",
      "regionc dfNGP Run 1/1, Epoch 201/2000, Training Loss (NLML): 1404.8232, (RMSE): 0.2275\n",
      "regionc dfNGP Run 1/1, Epoch 202/2000, Training Loss (NLML): 1394.7175, (RMSE): 0.2267\n",
      "regionc dfNGP Run 1/1, Epoch 203/2000, Training Loss (NLML): 1384.0873, (RMSE): 0.2264\n",
      "regionc dfNGP Run 1/1, Epoch 204/2000, Training Loss (NLML): 1377.4968, (RMSE): 0.2258\n",
      "regionc dfNGP Run 1/1, Epoch 205/2000, Training Loss (NLML): 1369.7183, (RMSE): 0.2253\n",
      "regionc dfNGP Run 1/1, Epoch 206/2000, Training Loss (NLML): 1370.7882, (RMSE): 0.2264\n",
      "regionc dfNGP Run 1/1, Epoch 207/2000, Training Loss (NLML): 1358.3024, (RMSE): 0.2259\n",
      "regionc dfNGP Run 1/1, Epoch 208/2000, Training Loss (NLML): 1357.3257, (RMSE): 0.2258\n",
      "regionc dfNGP Run 1/1, Epoch 209/2000, Training Loss (NLML): 1348.1456, (RMSE): 0.2254\n",
      "regionc dfNGP Run 1/1, Epoch 210/2000, Training Loss (NLML): 1353.3655, (RMSE): 0.2253\n",
      "regionc dfNGP Run 1/1, Epoch 211/2000, Training Loss (NLML): 1337.6760, (RMSE): 0.2246\n",
      "regionc dfNGP Run 1/1, Epoch 212/2000, Training Loss (NLML): 1320.8131, (RMSE): 0.2241\n",
      "regionc dfNGP Run 1/1, Epoch 213/2000, Training Loss (NLML): 1334.5828, (RMSE): 0.2244\n",
      "regionc dfNGP Run 1/1, Epoch 214/2000, Training Loss (NLML): 1341.3030, (RMSE): 0.2245\n",
      "regionc dfNGP Run 1/1, Epoch 215/2000, Training Loss (NLML): 1334.1475, (RMSE): 0.2245\n",
      "regionc dfNGP Run 1/1, Epoch 216/2000, Training Loss (NLML): 1320.0828, (RMSE): 0.2240\n",
      "regionc dfNGP Run 1/1, Epoch 217/2000, Training Loss (NLML): 1282.6068, (RMSE): 0.2225\n",
      "regionc dfNGP Run 1/1, Epoch 218/2000, Training Loss (NLML): 1265.6581, (RMSE): 0.2217\n",
      "regionc dfNGP Run 1/1, Epoch 219/2000, Training Loss (NLML): 1263.8242, (RMSE): 0.2213\n",
      "regionc dfNGP Run 1/1, Epoch 220/2000, Training Loss (NLML): 1269.9476, (RMSE): 0.2217\n",
      "regionc dfNGP Run 1/1, Epoch 221/2000, Training Loss (NLML): 1259.0566, (RMSE): 0.2217\n",
      "regionc dfNGP Run 1/1, Epoch 222/2000, Training Loss (NLML): 1227.0339, (RMSE): 0.2206\n",
      "regionc dfNGP Run 1/1, Epoch 223/2000, Training Loss (NLML): 1224.0835, (RMSE): 0.2192\n",
      "regionc dfNGP Run 1/1, Epoch 224/2000, Training Loss (NLML): 1199.0237, (RMSE): 0.2185\n",
      "regionc dfNGP Run 1/1, Epoch 225/2000, Training Loss (NLML): 1185.6663, (RMSE): 0.2185\n",
      "regionc dfNGP Run 1/1, Epoch 226/2000, Training Loss (NLML): 1182.3953, (RMSE): 0.2182\n",
      "regionc dfNGP Run 1/1, Epoch 227/2000, Training Loss (NLML): 1203.7773, (RMSE): 0.2191\n",
      "regionc dfNGP Run 1/1, Epoch 228/2000, Training Loss (NLML): 1186.5435, (RMSE): 0.2180\n",
      "regionc dfNGP Run 1/1, Epoch 229/2000, Training Loss (NLML): 1167.5164, (RMSE): 0.2177\n",
      "regionc dfNGP Run 1/1, Epoch 230/2000, Training Loss (NLML): 1169.0978, (RMSE): 0.2172\n",
      "regionc dfNGP Run 1/1, Epoch 231/2000, Training Loss (NLML): 1160.2446, (RMSE): 0.2168\n",
      "regionc dfNGP Run 1/1, Epoch 232/2000, Training Loss (NLML): 1141.9185, (RMSE): 0.2165\n",
      "regionc dfNGP Run 1/1, Epoch 233/2000, Training Loss (NLML): 1134.5405, (RMSE): 0.2162\n",
      "regionc dfNGP Run 1/1, Epoch 234/2000, Training Loss (NLML): 1129.5000, (RMSE): 0.2160\n",
      "regionc dfNGP Run 1/1, Epoch 235/2000, Training Loss (NLML): 1134.1697, (RMSE): 0.2157\n",
      "regionc dfNGP Run 1/1, Epoch 236/2000, Training Loss (NLML): 1129.6553, (RMSE): 0.2155\n",
      "regionc dfNGP Run 1/1, Epoch 237/2000, Training Loss (NLML): 1122.0535, (RMSE): 0.2149\n",
      "regionc dfNGP Run 1/1, Epoch 238/2000, Training Loss (NLML): 1108.4443, (RMSE): 0.2144\n",
      "regionc dfNGP Run 1/1, Epoch 239/2000, Training Loss (NLML): 1107.7969, (RMSE): 0.2148\n",
      "regionc dfNGP Run 1/1, Epoch 240/2000, Training Loss (NLML): 1109.6882, (RMSE): 0.2146\n",
      "regionc dfNGP Run 1/1, Epoch 241/2000, Training Loss (NLML): 1094.3530, (RMSE): 0.2142\n",
      "regionc dfNGP Run 1/1, Epoch 242/2000, Training Loss (NLML): 1084.2728, (RMSE): 0.2134\n",
      "regionc dfNGP Run 1/1, Epoch 243/2000, Training Loss (NLML): 1080.9072, (RMSE): 0.2129\n",
      "regionc dfNGP Run 1/1, Epoch 244/2000, Training Loss (NLML): 1072.9833, (RMSE): 0.2129\n",
      "regionc dfNGP Run 1/1, Epoch 245/2000, Training Loss (NLML): 1049.9596, (RMSE): 0.2122\n",
      "regionc dfNGP Run 1/1, Epoch 246/2000, Training Loss (NLML): 1043.2058, (RMSE): 0.2118\n",
      "regionc dfNGP Run 1/1, Epoch 247/2000, Training Loss (NLML): 1046.5038, (RMSE): 0.2116\n",
      "regionc dfNGP Run 1/1, Epoch 248/2000, Training Loss (NLML): 1030.9182, (RMSE): 0.2109\n",
      "regionc dfNGP Run 1/1, Epoch 249/2000, Training Loss (NLML): 1026.0659, (RMSE): 0.2100\n",
      "regionc dfNGP Run 1/1, Epoch 250/2000, Training Loss (NLML): 1017.5284, (RMSE): 0.2099\n",
      "regionc dfNGP Run 1/1, Epoch 251/2000, Training Loss (NLML): 1010.7415, (RMSE): 0.2101\n",
      "regionc dfNGP Run 1/1, Epoch 252/2000, Training Loss (NLML): 1001.3887, (RMSE): 0.2095\n",
      "regionc dfNGP Run 1/1, Epoch 253/2000, Training Loss (NLML): 998.1301, (RMSE): 0.2089\n",
      "regionc dfNGP Run 1/1, Epoch 254/2000, Training Loss (NLML): 986.3972, (RMSE): 0.2089\n",
      "regionc dfNGP Run 1/1, Epoch 255/2000, Training Loss (NLML): 995.0156, (RMSE): 0.2090\n",
      "regionc dfNGP Run 1/1, Epoch 256/2000, Training Loss (NLML): 972.6863, (RMSE): 0.2079\n",
      "regionc dfNGP Run 1/1, Epoch 257/2000, Training Loss (NLML): 967.1100, (RMSE): 0.2074\n",
      "regionc dfNGP Run 1/1, Epoch 258/2000, Training Loss (NLML): 955.4261, (RMSE): 0.2075\n",
      "regionc dfNGP Run 1/1, Epoch 259/2000, Training Loss (NLML): 960.3696, (RMSE): 0.2070\n",
      "regionc dfNGP Run 1/1, Epoch 260/2000, Training Loss (NLML): 948.8018, (RMSE): 0.2070\n",
      "regionc dfNGP Run 1/1, Epoch 261/2000, Training Loss (NLML): 940.9614, (RMSE): 0.2061\n",
      "regionc dfNGP Run 1/1, Epoch 262/2000, Training Loss (NLML): 932.7266, (RMSE): 0.2060\n",
      "regionc dfNGP Run 1/1, Epoch 263/2000, Training Loss (NLML): 925.6493, (RMSE): 0.2056\n",
      "regionc dfNGP Run 1/1, Epoch 264/2000, Training Loss (NLML): 918.4172, (RMSE): 0.2051\n",
      "regionc dfNGP Run 1/1, Epoch 265/2000, Training Loss (NLML): 921.1018, (RMSE): 0.2057\n",
      "regionc dfNGP Run 1/1, Epoch 266/2000, Training Loss (NLML): 923.3685, (RMSE): 0.2052\n",
      "regionc dfNGP Run 1/1, Epoch 267/2000, Training Loss (NLML): 932.8979, (RMSE): 0.2063\n",
      "regionc dfNGP Run 1/1, Epoch 268/2000, Training Loss (NLML): 908.7130, (RMSE): 0.2049\n",
      "regionc dfNGP Run 1/1, Epoch 269/2000, Training Loss (NLML): 899.7795, (RMSE): 0.2040\n",
      "regionc dfNGP Run 1/1, Epoch 270/2000, Training Loss (NLML): 888.0876, (RMSE): 0.2039\n",
      "regionc dfNGP Run 1/1, Epoch 271/2000, Training Loss (NLML): 878.6630, (RMSE): 0.2037\n",
      "regionc dfNGP Run 1/1, Epoch 272/2000, Training Loss (NLML): 878.6216, (RMSE): 0.2030\n",
      "regionc dfNGP Run 1/1, Epoch 273/2000, Training Loss (NLML): 870.2333, (RMSE): 0.2027\n",
      "regionc dfNGP Run 1/1, Epoch 274/2000, Training Loss (NLML): 868.4675, (RMSE): 0.2026\n",
      "regionc dfNGP Run 1/1, Epoch 275/2000, Training Loss (NLML): 870.5345, (RMSE): 0.2024\n",
      "regionc dfNGP Run 1/1, Epoch 276/2000, Training Loss (NLML): 879.4833, (RMSE): 0.2027\n",
      "regionc dfNGP Run 1/1, Epoch 277/2000, Training Loss (NLML): 895.8875, (RMSE): 0.2043\n",
      "regionc dfNGP Run 1/1, Epoch 278/2000, Training Loss (NLML): 889.7214, (RMSE): 0.2042\n",
      "regionc dfNGP Run 1/1, Epoch 279/2000, Training Loss (NLML): 883.7029, (RMSE): 0.2032\n",
      "regionc dfNGP Run 1/1, Epoch 280/2000, Training Loss (NLML): 877.8671, (RMSE): 0.2031\n",
      "regionc dfNGP Run 1/1, Epoch 281/2000, Training Loss (NLML): 892.6218, (RMSE): 0.2036\n",
      "regionc dfNGP Run 1/1, Epoch 282/2000, Training Loss (NLML): 874.0830, (RMSE): 0.2026\n",
      "regionc dfNGP Run 1/1, Epoch 283/2000, Training Loss (NLML): 861.1644, (RMSE): 0.2019\n",
      "regionc dfNGP Run 1/1, Epoch 284/2000, Training Loss (NLML): 856.0634, (RMSE): 0.2016\n",
      "regionc dfNGP Run 1/1, Epoch 285/2000, Training Loss (NLML): 866.9576, (RMSE): 0.2019\n",
      "regionc dfNGP Run 1/1, Epoch 286/2000, Training Loss (NLML): 848.5656, (RMSE): 0.2014\n",
      "regionc dfNGP Run 1/1, Epoch 287/2000, Training Loss (NLML): 856.2463, (RMSE): 0.2020\n",
      "regionc dfNGP Run 1/1, Epoch 288/2000, Training Loss (NLML): 841.5892, (RMSE): 0.2010\n",
      "regionc dfNGP Run 1/1, Epoch 289/2000, Training Loss (NLML): 847.6919, (RMSE): 0.2009\n",
      "regionc dfNGP Run 1/1, Epoch 290/2000, Training Loss (NLML): 822.6659, (RMSE): 0.2003\n",
      "regionc dfNGP Run 1/1, Epoch 291/2000, Training Loss (NLML): 814.5193, (RMSE): 0.1987\n",
      "regionc dfNGP Run 1/1, Epoch 292/2000, Training Loss (NLML): 795.1759, (RMSE): 0.1984\n",
      "regionc dfNGP Run 1/1, Epoch 293/2000, Training Loss (NLML): 790.5725, (RMSE): 0.1983\n",
      "regionc dfNGP Run 1/1, Epoch 294/2000, Training Loss (NLML): 779.0708, (RMSE): 0.1974\n",
      "regionc dfNGP Run 1/1, Epoch 295/2000, Training Loss (NLML): 770.2546, (RMSE): 0.1969\n",
      "regionc dfNGP Run 1/1, Epoch 296/2000, Training Loss (NLML): 769.1754, (RMSE): 0.1964\n",
      "regionc dfNGP Run 1/1, Epoch 297/2000, Training Loss (NLML): 762.6204, (RMSE): 0.1964\n",
      "regionc dfNGP Run 1/1, Epoch 298/2000, Training Loss (NLML): 750.9395, (RMSE): 0.1958\n",
      "regionc dfNGP Run 1/1, Epoch 299/2000, Training Loss (NLML): 754.7145, (RMSE): 0.1964\n",
      "regionc dfNGP Run 1/1, Epoch 300/2000, Training Loss (NLML): 755.0540, (RMSE): 0.1959\n",
      "regionc dfNGP Run 1/1, Epoch 301/2000, Training Loss (NLML): 748.6611, (RMSE): 0.1961\n",
      "regionc dfNGP Run 1/1, Epoch 302/2000, Training Loss (NLML): 738.4651, (RMSE): 0.1953\n",
      "regionc dfNGP Run 1/1, Epoch 303/2000, Training Loss (NLML): 738.1469, (RMSE): 0.1950\n",
      "regionc dfNGP Run 1/1, Epoch 304/2000, Training Loss (NLML): 727.4507, (RMSE): 0.1941\n",
      "regionc dfNGP Run 1/1, Epoch 305/2000, Training Loss (NLML): 719.2061, (RMSE): 0.1941\n",
      "regionc dfNGP Run 1/1, Epoch 306/2000, Training Loss (NLML): 712.8096, (RMSE): 0.1937\n",
      "regionc dfNGP Run 1/1, Epoch 307/2000, Training Loss (NLML): 696.7371, (RMSE): 0.1928\n",
      "regionc dfNGP Run 1/1, Epoch 308/2000, Training Loss (NLML): 686.6394, (RMSE): 0.1926\n",
      "regionc dfNGP Run 1/1, Epoch 309/2000, Training Loss (NLML): 686.4218, (RMSE): 0.1918\n",
      "regionc dfNGP Run 1/1, Epoch 310/2000, Training Loss (NLML): 681.2965, (RMSE): 0.1914\n",
      "regionc dfNGP Run 1/1, Epoch 311/2000, Training Loss (NLML): 666.3447, (RMSE): 0.1910\n",
      "regionc dfNGP Run 1/1, Epoch 312/2000, Training Loss (NLML): 669.1865, (RMSE): 0.1912\n",
      "regionc dfNGP Run 1/1, Epoch 313/2000, Training Loss (NLML): 660.1742, (RMSE): 0.1909\n",
      "regionc dfNGP Run 1/1, Epoch 314/2000, Training Loss (NLML): 665.9944, (RMSE): 0.1907\n",
      "regionc dfNGP Run 1/1, Epoch 315/2000, Training Loss (NLML): 649.3785, (RMSE): 0.1899\n",
      "regionc dfNGP Run 1/1, Epoch 316/2000, Training Loss (NLML): 650.3921, (RMSE): 0.1901\n",
      "regionc dfNGP Run 1/1, Epoch 317/2000, Training Loss (NLML): 647.7972, (RMSE): 0.1898\n",
      "regionc dfNGP Run 1/1, Epoch 318/2000, Training Loss (NLML): 645.9034, (RMSE): 0.1893\n",
      "regionc dfNGP Run 1/1, Epoch 319/2000, Training Loss (NLML): 638.4739, (RMSE): 0.1891\n",
      "regionc dfNGP Run 1/1, Epoch 320/2000, Training Loss (NLML): 637.6714, (RMSE): 0.1890\n",
      "regionc dfNGP Run 1/1, Epoch 321/2000, Training Loss (NLML): 625.4948, (RMSE): 0.1885\n",
      "regionc dfNGP Run 1/1, Epoch 322/2000, Training Loss (NLML): 633.8202, (RMSE): 0.1888\n",
      "regionc dfNGP Run 1/1, Epoch 323/2000, Training Loss (NLML): 618.6074, (RMSE): 0.1877\n",
      "regionc dfNGP Run 1/1, Epoch 324/2000, Training Loss (NLML): 605.9779, (RMSE): 0.1869\n",
      "regionc dfNGP Run 1/1, Epoch 325/2000, Training Loss (NLML): 606.5096, (RMSE): 0.1871\n",
      "regionc dfNGP Run 1/1, Epoch 326/2000, Training Loss (NLML): 608.4362, (RMSE): 0.1867\n",
      "regionc dfNGP Run 1/1, Epoch 327/2000, Training Loss (NLML): 594.4567, (RMSE): 0.1866\n",
      "regionc dfNGP Run 1/1, Epoch 328/2000, Training Loss (NLML): 603.4836, (RMSE): 0.1866\n",
      "regionc dfNGP Run 1/1, Epoch 329/2000, Training Loss (NLML): 586.6726, (RMSE): 0.1856\n",
      "regionc dfNGP Run 1/1, Epoch 330/2000, Training Loss (NLML): 596.7679, (RMSE): 0.1863\n",
      "regionc dfNGP Run 1/1, Epoch 331/2000, Training Loss (NLML): 595.3016, (RMSE): 0.1856\n",
      "regionc dfNGP Run 1/1, Epoch 332/2000, Training Loss (NLML): 583.0819, (RMSE): 0.1853\n",
      "regionc dfNGP Run 1/1, Epoch 333/2000, Training Loss (NLML): 580.3867, (RMSE): 0.1851\n",
      "regionc dfNGP Run 1/1, Epoch 334/2000, Training Loss (NLML): 571.2682, (RMSE): 0.1851\n",
      "regionc dfNGP Run 1/1, Epoch 335/2000, Training Loss (NLML): 577.1780, (RMSE): 0.1851\n",
      "regionc dfNGP Run 1/1, Epoch 336/2000, Training Loss (NLML): 568.8218, (RMSE): 0.1846\n",
      "regionc dfNGP Run 1/1, Epoch 337/2000, Training Loss (NLML): 558.2467, (RMSE): 0.1845\n",
      "regionc dfNGP Run 1/1, Epoch 338/2000, Training Loss (NLML): 552.1715, (RMSE): 0.1837\n",
      "regionc dfNGP Run 1/1, Epoch 339/2000, Training Loss (NLML): 544.3285, (RMSE): 0.1834\n",
      "regionc dfNGP Run 1/1, Epoch 340/2000, Training Loss (NLML): 543.6587, (RMSE): 0.1828\n",
      "regionc dfNGP Run 1/1, Epoch 341/2000, Training Loss (NLML): 535.2029, (RMSE): 0.1830\n",
      "regionc dfNGP Run 1/1, Epoch 342/2000, Training Loss (NLML): 536.1276, (RMSE): 0.1825\n",
      "regionc dfNGP Run 1/1, Epoch 343/2000, Training Loss (NLML): 536.0082, (RMSE): 0.1823\n",
      "regionc dfNGP Run 1/1, Epoch 344/2000, Training Loss (NLML): 519.7091, (RMSE): 0.1823\n",
      "regionc dfNGP Run 1/1, Epoch 345/2000, Training Loss (NLML): 508.5788, (RMSE): 0.1820\n",
      "regionc dfNGP Run 1/1, Epoch 346/2000, Training Loss (NLML): 517.7076, (RMSE): 0.1822\n",
      "regionc dfNGP Run 1/1, Epoch 347/2000, Training Loss (NLML): 504.3817, (RMSE): 0.1812\n",
      "regionc dfNGP Run 1/1, Epoch 348/2000, Training Loss (NLML): 502.9239, (RMSE): 0.1816\n",
      "regionc dfNGP Run 1/1, Epoch 349/2000, Training Loss (NLML): 496.6155, (RMSE): 0.1810\n",
      "regionc dfNGP Run 1/1, Epoch 350/2000, Training Loss (NLML): 491.8535, (RMSE): 0.1807\n",
      "regionc dfNGP Run 1/1, Epoch 351/2000, Training Loss (NLML): 494.2209, (RMSE): 0.1807\n",
      "regionc dfNGP Run 1/1, Epoch 352/2000, Training Loss (NLML): 490.0562, (RMSE): 0.1807\n",
      "regionc dfNGP Run 1/1, Epoch 353/2000, Training Loss (NLML): 486.5418, (RMSE): 0.1801\n",
      "regionc dfNGP Run 1/1, Epoch 354/2000, Training Loss (NLML): 473.1294, (RMSE): 0.1803\n",
      "regionc dfNGP Run 1/1, Epoch 355/2000, Training Loss (NLML): 476.2508, (RMSE): 0.1803\n",
      "regionc dfNGP Run 1/1, Epoch 356/2000, Training Loss (NLML): 474.5183, (RMSE): 0.1803\n",
      "regionc dfNGP Run 1/1, Epoch 357/2000, Training Loss (NLML): 470.0508, (RMSE): 0.1796\n",
      "regionc dfNGP Run 1/1, Epoch 358/2000, Training Loss (NLML): 470.9221, (RMSE): 0.1801\n",
      "regionc dfNGP Run 1/1, Epoch 359/2000, Training Loss (NLML): 462.2746, (RMSE): 0.1793\n",
      "regionc dfNGP Run 1/1, Epoch 360/2000, Training Loss (NLML): 465.8565, (RMSE): 0.1793\n",
      "regionc dfNGP Run 1/1, Epoch 361/2000, Training Loss (NLML): 459.6254, (RMSE): 0.1796\n",
      "regionc dfNGP Run 1/1, Epoch 362/2000, Training Loss (NLML): 455.1317, (RMSE): 0.1791\n",
      "regionc dfNGP Run 1/1, Epoch 363/2000, Training Loss (NLML): 451.5962, (RMSE): 0.1785\n",
      "regionc dfNGP Run 1/1, Epoch 364/2000, Training Loss (NLML): 448.3103, (RMSE): 0.1787\n",
      "regionc dfNGP Run 1/1, Epoch 365/2000, Training Loss (NLML): 451.1726, (RMSE): 0.1787\n",
      "regionc dfNGP Run 1/1, Epoch 366/2000, Training Loss (NLML): 453.3413, (RMSE): 0.1785\n",
      "regionc dfNGP Run 1/1, Epoch 367/2000, Training Loss (NLML): 449.2305, (RMSE): 0.1788\n",
      "regionc dfNGP Run 1/1, Epoch 368/2000, Training Loss (NLML): 445.5371, (RMSE): 0.1785\n",
      "regionc dfNGP Run 1/1, Epoch 369/2000, Training Loss (NLML): 444.8633, (RMSE): 0.1780\n",
      "regionc dfNGP Run 1/1, Epoch 370/2000, Training Loss (NLML): 448.3372, (RMSE): 0.1776\n",
      "regionc dfNGP Run 1/1, Epoch 371/2000, Training Loss (NLML): 439.3561, (RMSE): 0.1778\n",
      "regionc dfNGP Run 1/1, Epoch 372/2000, Training Loss (NLML): 438.9916, (RMSE): 0.1777\n",
      "regionc dfNGP Run 1/1, Epoch 373/2000, Training Loss (NLML): 435.1475, (RMSE): 0.1778\n",
      "regionc dfNGP Run 1/1, Epoch 374/2000, Training Loss (NLML): 422.6305, (RMSE): 0.1776\n",
      "regionc dfNGP Run 1/1, Epoch 375/2000, Training Loss (NLML): 432.7713, (RMSE): 0.1777\n",
      "regionc dfNGP Run 1/1, Epoch 376/2000, Training Loss (NLML): 429.7865, (RMSE): 0.1773\n",
      "regionc dfNGP Run 1/1, Epoch 377/2000, Training Loss (NLML): 428.6371, (RMSE): 0.1774\n",
      "regionc dfNGP Run 1/1, Epoch 378/2000, Training Loss (NLML): 425.3892, (RMSE): 0.1773\n",
      "regionc dfNGP Run 1/1, Epoch 379/2000, Training Loss (NLML): 428.6180, (RMSE): 0.1776\n",
      "regionc dfNGP Run 1/1, Epoch 380/2000, Training Loss (NLML): 425.0930, (RMSE): 0.1771\n",
      "regionc dfNGP Run 1/1, Epoch 381/2000, Training Loss (NLML): 12382.1904, (RMSE): 0.1826\n",
      "regionc dfNGP Run 1/1, Epoch 382/2000, Training Loss (NLML): 415.0218, (RMSE): 0.1768\n",
      "regionc dfNGP Run 1/1, Epoch 383/2000, Training Loss (NLML): 414.5346, (RMSE): 0.1764\n",
      "regionc dfNGP Run 1/1, Epoch 384/2000, Training Loss (NLML): 416.4458, (RMSE): 0.1761\n",
      "regionc dfNGP Run 1/1, Epoch 385/2000, Training Loss (NLML): 411.5713, (RMSE): 0.1759\n",
      "regionc dfNGP Run 1/1, Epoch 386/2000, Training Loss (NLML): 408.3112, (RMSE): 0.1758\n",
      "regionc dfNGP Run 1/1, Epoch 387/2000, Training Loss (NLML): 403.1123, (RMSE): 0.1757\n",
      "regionc dfNGP Run 1/1, Epoch 388/2000, Training Loss (NLML): 392.0811, (RMSE): 0.1750\n",
      "regionc dfNGP Run 1/1, Epoch 389/2000, Training Loss (NLML): 392.5415, (RMSE): 0.1753\n",
      "regionc dfNGP Run 1/1, Epoch 390/2000, Training Loss (NLML): 390.1077, (RMSE): 0.1747\n",
      "regionc dfNGP Run 1/1, Epoch 391/2000, Training Loss (NLML): 387.1712, (RMSE): 0.1744\n",
      "regionc dfNGP Run 1/1, Epoch 392/2000, Training Loss (NLML): 393.4709, (RMSE): 0.1745\n",
      "regionc dfNGP Run 1/1, Epoch 393/2000, Training Loss (NLML): 389.0321, (RMSE): 0.1746\n",
      "regionc dfNGP Run 1/1, Epoch 394/2000, Training Loss (NLML): 385.3429, (RMSE): 0.1743\n",
      "regionc dfNGP Run 1/1, Epoch 395/2000, Training Loss (NLML): 386.1896, (RMSE): 0.1743\n",
      "regionc dfNGP Run 1/1, Epoch 396/2000, Training Loss (NLML): 386.3897, (RMSE): 0.1743\n",
      "regionc dfNGP Run 1/1, Epoch 397/2000, Training Loss (NLML): 382.0262, (RMSE): 0.1739\n",
      "regionc dfNGP Run 1/1, Epoch 398/2000, Training Loss (NLML): 382.8540, (RMSE): 0.1737\n",
      "regionc dfNGP Run 1/1, Epoch 399/2000, Training Loss (NLML): 388.9458, (RMSE): 0.1736\n",
      "regionc dfNGP Run 1/1, Epoch 400/2000, Training Loss (NLML): 387.1232, (RMSE): 0.1736\n",
      "regionc dfNGP Run 1/1, Epoch 401/2000, Training Loss (NLML): 382.3151, (RMSE): 0.1731\n",
      "regionc dfNGP Run 1/1, Epoch 402/2000, Training Loss (NLML): 380.5509, (RMSE): 0.1731\n",
      "regionc dfNGP Run 1/1, Epoch 403/2000, Training Loss (NLML): 10324.1943, (RMSE): 0.1731\n",
      "regionc dfNGP Run 1/1, Epoch 404/2000, Training Loss (NLML): 372.6169, (RMSE): 0.1732\n",
      "regionc dfNGP Run 1/1, Epoch 405/2000, Training Loss (NLML): 369.3203, (RMSE): 0.1728\n",
      "regionc dfNGP Run 1/1, Epoch 406/2000, Training Loss (NLML): 9451.6729, (RMSE): 0.1723\n",
      "regionc dfNGP Run 1/1, Epoch 407/2000, Training Loss (NLML): 10686.7383, (RMSE): 0.1748\n",
      "regionc dfNGP Run 1/1, Epoch 408/2000, Training Loss (NLML): 358.4081, (RMSE): 0.1698\n",
      "regionc dfNGP Run 1/1, Epoch 409/2000, Training Loss (NLML): 356.5887, (RMSE): 0.1682\n",
      "regionc dfNGP Run 1/1, Epoch 410/2000, Training Loss (NLML): 345.8815, (RMSE): 0.1667\n",
      "regionc dfNGP Run 1/1, Epoch 411/2000, Training Loss (NLML): 330.0022, (RMSE): 0.1652\n",
      "regionc dfNGP Run 1/1, Epoch 412/2000, Training Loss (NLML): 323.7880, (RMSE): 0.1635\n",
      "regionc dfNGP Run 1/1, Epoch 413/2000, Training Loss (NLML): 318.7359, (RMSE): 0.1621\n",
      "regionc dfNGP Run 1/1, Epoch 414/2000, Training Loss (NLML): 313.9965, (RMSE): 0.1607\n",
      "regionc dfNGP Run 1/1, Epoch 415/2000, Training Loss (NLML): 296.4240, (RMSE): 0.1589\n",
      "regionc dfNGP Run 1/1, Epoch 416/2000, Training Loss (NLML): 285.2388, (RMSE): 0.1571\n",
      "regionc dfNGP Run 1/1, Epoch 417/2000, Training Loss (NLML): 275.9058, (RMSE): 0.1561\n",
      "regionc dfNGP Run 1/1, Epoch 418/2000, Training Loss (NLML): 268.6081, (RMSE): 0.1545\n",
      "regionc dfNGP Run 1/1, Epoch 419/2000, Training Loss (NLML): 7599.8379, (RMSE): 0.1528\n",
      "regionc dfNGP Run 1/1, Epoch 420/2000, Training Loss (NLML): 227.7766, (RMSE): 0.1502\n",
      "regionc dfNGP Run 1/1, Epoch 421/2000, Training Loss (NLML): 208.2433, (RMSE): 0.1478\n",
      "regionc dfNGP Run 1/1, Epoch 422/2000, Training Loss (NLML): 6942.8809, (RMSE): 0.1502\n",
      "regionc dfNGP Run 1/1, Epoch 423/2000, Training Loss (NLML): 175.5233, (RMSE): 0.1416\n",
      "regionc dfNGP Run 1/1, Epoch 424/2000, Training Loss (NLML): 159.0005, (RMSE): 0.1384\n",
      "regionc dfNGP Run 1/1, Epoch 425/2000, Training Loss (NLML): 138.5828, (RMSE): 0.1356\n",
      "regionc dfNGP Run 1/1, Epoch 426/2000, Training Loss (NLML): 134.2113, (RMSE): 0.1324\n",
      "regionc dfNGP Run 1/1, Epoch 427/2000, Training Loss (NLML): 123.3162, (RMSE): 0.1295\n",
      "regionc dfNGP Run 1/1, Epoch 428/2000, Training Loss (NLML): 107.0274, (RMSE): 0.1266\n",
      "regionc dfNGP Run 1/1, Epoch 429/2000, Training Loss (NLML): 93.8357, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 430/2000, Training Loss (NLML): 87.7434, (RMSE): 0.1207\n",
      "regionc dfNGP Run 1/1, Epoch 431/2000, Training Loss (NLML): 72.5173, (RMSE): 0.1180\n",
      "regionc dfNGP Run 1/1, Epoch 432/2000, Training Loss (NLML): 72.2174, (RMSE): 0.1163\n",
      "regionc dfNGP Run 1/1, Epoch 433/2000, Training Loss (NLML): 66.7135, (RMSE): 0.1141\n",
      "regionc dfNGP Run 1/1, Epoch 434/2000, Training Loss (NLML): 54.7472, (RMSE): 0.1123\n",
      "regionc dfNGP Run 1/1, Epoch 435/2000, Training Loss (NLML): 63.0884, (RMSE): 0.1118\n",
      "regionc dfNGP Run 1/1, Epoch 436/2000, Training Loss (NLML): 58.5186, (RMSE): 0.1111\n",
      "regionc dfNGP Run 1/1, Epoch 437/2000, Training Loss (NLML): 59.8018, (RMSE): 0.1100\n",
      "regionc dfNGP Run 1/1, Epoch 438/2000, Training Loss (NLML): 55.7818, (RMSE): 0.1096\n",
      "regionc dfNGP Run 1/1, Epoch 439/2000, Training Loss (NLML): 48.0490, (RMSE): 0.1087\n",
      "regionc dfNGP Run 1/1, Epoch 440/2000, Training Loss (NLML): 53.6321, (RMSE): 0.1083\n",
      "regionc dfNGP Run 1/1, Epoch 441/2000, Training Loss (NLML): 50.3424, (RMSE): 0.1080\n",
      "regionc dfNGP Run 1/1, Epoch 442/2000, Training Loss (NLML): 52.3278, (RMSE): 0.1082\n",
      "regionc dfNGP Run 1/1, Epoch 443/2000, Training Loss (NLML): 49.8803, (RMSE): 0.1077\n",
      "regionc dfNGP Run 1/1, Epoch 444/2000, Training Loss (NLML): 46.8452, (RMSE): 0.1073\n",
      "regionc dfNGP Run 1/1, Epoch 445/2000, Training Loss (NLML): 39.4714, (RMSE): 0.1082\n",
      "regionc dfNGP Run 1/1, Epoch 446/2000, Training Loss (NLML): 40.7130, (RMSE): 0.1080\n",
      "regionc dfNGP Run 1/1, Epoch 447/2000, Training Loss (NLML): 40.0055, (RMSE): 0.1083\n",
      "regionc dfNGP Run 1/1, Epoch 448/2000, Training Loss (NLML): 28.5025, (RMSE): 0.1079\n",
      "regionc dfNGP Run 1/1, Epoch 449/2000, Training Loss (NLML): 22.5113, (RMSE): 0.1087\n",
      "regionc dfNGP Run 1/1, Epoch 450/2000, Training Loss (NLML): 25.4391, (RMSE): 0.1090\n",
      "regionc dfNGP Run 1/1, Epoch 451/2000, Training Loss (NLML): 18.3634, (RMSE): 0.1091\n",
      "regionc dfNGP Run 1/1, Epoch 452/2000, Training Loss (NLML): 10.4807, (RMSE): 0.1099\n",
      "regionc dfNGP Run 1/1, Epoch 453/2000, Training Loss (NLML): 13.6615, (RMSE): 0.1107\n",
      "regionc dfNGP Run 1/1, Epoch 454/2000, Training Loss (NLML): 5.3005, (RMSE): 0.1104\n",
      "regionc dfNGP Run 1/1, Epoch 455/2000, Training Loss (NLML): 3.7502, (RMSE): 0.1113\n",
      "regionc dfNGP Run 1/1, Epoch 456/2000, Training Loss (NLML): -1.5265, (RMSE): 0.1116\n",
      "regionc dfNGP Run 1/1, Epoch 457/2000, Training Loss (NLML): -1.5260, (RMSE): 0.1118\n",
      "regionc dfNGP Run 1/1, Epoch 458/2000, Training Loss (NLML): -9.2674, (RMSE): 0.1118\n",
      "regionc dfNGP Run 1/1, Epoch 459/2000, Training Loss (NLML): -8.5969, (RMSE): 0.1124\n",
      "regionc dfNGP Run 1/1, Epoch 460/2000, Training Loss (NLML): -11.0647, (RMSE): 0.1134\n",
      "regionc dfNGP Run 1/1, Epoch 461/2000, Training Loss (NLML): -15.2545, (RMSE): 0.1140\n",
      "regionc dfNGP Run 1/1, Epoch 462/2000, Training Loss (NLML): -15.3515, (RMSE): 0.1144\n",
      "regionc dfNGP Run 1/1, Epoch 463/2000, Training Loss (NLML): -15.7145, (RMSE): 0.1152\n",
      "regionc dfNGP Run 1/1, Epoch 464/2000, Training Loss (NLML): -20.6442, (RMSE): 0.1155\n",
      "regionc dfNGP Run 1/1, Epoch 465/2000, Training Loss (NLML): -13.6924, (RMSE): 0.1160\n",
      "regionc dfNGP Run 1/1, Epoch 466/2000, Training Loss (NLML): -21.7188, (RMSE): 0.1160\n",
      "regionc dfNGP Run 1/1, Epoch 467/2000, Training Loss (NLML): -14.0401, (RMSE): 0.1166\n",
      "regionc dfNGP Run 1/1, Epoch 468/2000, Training Loss (NLML): -17.6739, (RMSE): 0.1166\n",
      "regionc dfNGP Run 1/1, Epoch 469/2000, Training Loss (NLML): -18.9151, (RMSE): 0.1175\n",
      "regionc dfNGP Run 1/1, Epoch 470/2000, Training Loss (NLML): -18.4935, (RMSE): 0.1174\n",
      "regionc dfNGP Run 1/1, Epoch 471/2000, Training Loss (NLML): -24.0296, (RMSE): 0.1178\n",
      "regionc dfNGP Run 1/1, Epoch 472/2000, Training Loss (NLML): -19.9680, (RMSE): 0.1180\n",
      "regionc dfNGP Run 1/1, Epoch 473/2000, Training Loss (NLML): -26.3648, (RMSE): 0.1183\n",
      "regionc dfNGP Run 1/1, Epoch 474/2000, Training Loss (NLML): -19.7873, (RMSE): 0.1180\n",
      "regionc dfNGP Run 1/1, Epoch 475/2000, Training Loss (NLML): -20.2947, (RMSE): 0.1185\n",
      "regionc dfNGP Run 1/1, Epoch 476/2000, Training Loss (NLML): -27.9186, (RMSE): 0.1186\n",
      "regionc dfNGP Run 1/1, Epoch 477/2000, Training Loss (NLML): -29.8062, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 478/2000, Training Loss (NLML): -34.3446, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 479/2000, Training Loss (NLML): -31.7183, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 480/2000, Training Loss (NLML): -31.4120, (RMSE): 0.1193\n",
      "regionc dfNGP Run 1/1, Epoch 481/2000, Training Loss (NLML): -37.9950, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 482/2000, Training Loss (NLML): -39.4698, (RMSE): 0.1192\n",
      "regionc dfNGP Run 1/1, Epoch 483/2000, Training Loss (NLML): -36.6390, (RMSE): 0.1191\n",
      "regionc dfNGP Run 1/1, Epoch 484/2000, Training Loss (NLML): -36.0199, (RMSE): 0.1186\n",
      "regionc dfNGP Run 1/1, Epoch 485/2000, Training Loss (NLML): -35.3488, (RMSE): 0.1191\n",
      "regionc dfNGP Run 1/1, Epoch 486/2000, Training Loss (NLML): -37.6814, (RMSE): 0.1191\n",
      "regionc dfNGP Run 1/1, Epoch 487/2000, Training Loss (NLML): -33.9824, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 488/2000, Training Loss (NLML): -41.6947, (RMSE): 0.1192\n",
      "regionc dfNGP Run 1/1, Epoch 489/2000, Training Loss (NLML): -38.9275, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 490/2000, Training Loss (NLML): -34.0477, (RMSE): 0.1192\n",
      "regionc dfNGP Run 1/1, Epoch 491/2000, Training Loss (NLML): -31.2909, (RMSE): 0.1191\n",
      "regionc dfNGP Run 1/1, Epoch 492/2000, Training Loss (NLML): -43.1613, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 493/2000, Training Loss (NLML): -43.1798, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 494/2000, Training Loss (NLML): -41.4748, (RMSE): 0.1190\n",
      "regionc dfNGP Run 1/1, Epoch 495/2000, Training Loss (NLML): -38.2039, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 496/2000, Training Loss (NLML): -43.4842, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 497/2000, Training Loss (NLML): -38.6605, (RMSE): 0.1185\n",
      "regionc dfNGP Run 1/1, Epoch 498/2000, Training Loss (NLML): -40.8272, (RMSE): 0.1184\n",
      "regionc dfNGP Run 1/1, Epoch 499/2000, Training Loss (NLML): -49.4745, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 500/2000, Training Loss (NLML): -48.3399, (RMSE): 0.1182\n",
      "regionc dfNGP Run 1/1, Epoch 501/2000, Training Loss (NLML): -52.6122, (RMSE): 0.1182\n",
      "regionc dfNGP Run 1/1, Epoch 502/2000, Training Loss (NLML): -47.5727, (RMSE): 0.1182\n",
      "regionc dfNGP Run 1/1, Epoch 503/2000, Training Loss (NLML): -47.5244, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 504/2000, Training Loss (NLML): -46.6135, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 505/2000, Training Loss (NLML): -41.7591, (RMSE): 0.1181\n",
      "regionc dfNGP Run 1/1, Epoch 506/2000, Training Loss (NLML): -43.5789, (RMSE): 0.1186\n",
      "regionc dfNGP Run 1/1, Epoch 507/2000, Training Loss (NLML): -41.9056, (RMSE): 0.1182\n",
      "regionc dfNGP Run 1/1, Epoch 508/2000, Training Loss (NLML): -53.1564, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 509/2000, Training Loss (NLML): -51.5728, (RMSE): 0.1182\n",
      "regionc dfNGP Run 1/1, Epoch 510/2000, Training Loss (NLML): -48.3825, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 511/2000, Training Loss (NLML): -46.2339, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 512/2000, Training Loss (NLML): -47.9502, (RMSE): 0.1181\n",
      "regionc dfNGP Run 1/1, Epoch 513/2000, Training Loss (NLML): -44.4701, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 514/2000, Training Loss (NLML): -53.6498, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 515/2000, Training Loss (NLML): -39.6241, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 516/2000, Training Loss (NLML): -49.3882, (RMSE): 0.1185\n",
      "regionc dfNGP Run 1/1, Epoch 517/2000, Training Loss (NLML): -53.6006, (RMSE): 0.1179\n",
      "regionc dfNGP Run 1/1, Epoch 518/2000, Training Loss (NLML): -52.5249, (RMSE): 0.1185\n",
      "regionc dfNGP Run 1/1, Epoch 519/2000, Training Loss (NLML): -52.4803, (RMSE): 0.1187\n",
      "regionc dfNGP Run 1/1, Epoch 520/2000, Training Loss (NLML): -53.8969, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 521/2000, Training Loss (NLML): -57.3137, (RMSE): 0.1191\n",
      "regionc dfNGP Run 1/1, Epoch 522/2000, Training Loss (NLML): -55.5404, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 523/2000, Training Loss (NLML): -58.1608, (RMSE): 0.1189\n",
      "regionc dfNGP Run 1/1, Epoch 524/2000, Training Loss (NLML): -58.9372, (RMSE): 0.1185\n",
      "regionc dfNGP Run 1/1, Epoch 525/2000, Training Loss (NLML): -59.8447, (RMSE): 0.1190\n",
      "regionc dfNGP Run 1/1, Epoch 526/2000, Training Loss (NLML): -59.2773, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 527/2000, Training Loss (NLML): -69.8554, (RMSE): 0.1190\n",
      "regionc dfNGP Run 1/1, Epoch 528/2000, Training Loss (NLML): -61.1925, (RMSE): 0.1194\n",
      "regionc dfNGP Run 1/1, Epoch 529/2000, Training Loss (NLML): -62.2602, (RMSE): 0.1197\n",
      "regionc dfNGP Run 1/1, Epoch 530/2000, Training Loss (NLML): -49.0166, (RMSE): 0.1198\n",
      "regionc dfNGP Run 1/1, Epoch 531/2000, Training Loss (NLML): -62.3806, (RMSE): 0.1188\n",
      "regionc dfNGP Run 1/1, Epoch 532/2000, Training Loss (NLML): -63.8405, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 533/2000, Training Loss (NLML): -65.3991, (RMSE): 0.1198\n",
      "regionc dfNGP Run 1/1, Epoch 534/2000, Training Loss (NLML): -61.1674, (RMSE): 0.1193\n",
      "regionc dfNGP Run 1/1, Epoch 535/2000, Training Loss (NLML): -62.7527, (RMSE): 0.1197\n",
      "regionc dfNGP Run 1/1, Epoch 536/2000, Training Loss (NLML): -61.5794, (RMSE): 0.1196\n",
      "regionc dfNGP Run 1/1, Epoch 537/2000, Training Loss (NLML): -60.4349, (RMSE): 0.1193\n",
      "regionc dfNGP Run 1/1, Epoch 538/2000, Training Loss (NLML): -60.3670, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 539/2000, Training Loss (NLML): -71.2000, (RMSE): 0.1198\n",
      "regionc dfNGP Run 1/1, Epoch 540/2000, Training Loss (NLML): -60.7124, (RMSE): 0.1202\n",
      "regionc dfNGP Run 1/1, Epoch 541/2000, Training Loss (NLML): -61.4928, (RMSE): 0.1199\n",
      "regionc dfNGP Run 1/1, Epoch 542/2000, Training Loss (NLML): -62.9291, (RMSE): 0.1195\n",
      "regionc dfNGP Run 1/1, Epoch 543/2000, Training Loss (NLML): -62.3706, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 544/2000, Training Loss (NLML): -68.0224, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 545/2000, Training Loss (NLML): -64.2168, (RMSE): 0.1200\n",
      "regionc dfNGP Run 1/1, Epoch 546/2000, Training Loss (NLML): -67.7887, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 547/2000, Training Loss (NLML): -70.8477, (RMSE): 0.1202\n",
      "regionc dfNGP Run 1/1, Epoch 548/2000, Training Loss (NLML): -64.8220, (RMSE): 0.1197\n",
      "regionc dfNGP Run 1/1, Epoch 549/2000, Training Loss (NLML): -65.2492, (RMSE): 0.1200\n",
      "regionc dfNGP Run 1/1, Epoch 550/2000, Training Loss (NLML): -71.2144, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 551/2000, Training Loss (NLML): -64.2479, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 552/2000, Training Loss (NLML): -69.0866, (RMSE): 0.1204\n",
      "regionc dfNGP Run 1/1, Epoch 553/2000, Training Loss (NLML): -65.1249, (RMSE): 0.1205\n",
      "regionc dfNGP Run 1/1, Epoch 554/2000, Training Loss (NLML): -62.4644, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 555/2000, Training Loss (NLML): -66.7975, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 556/2000, Training Loss (NLML): -64.6281, (RMSE): 0.1205\n",
      "regionc dfNGP Run 1/1, Epoch 557/2000, Training Loss (NLML): -60.9257, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 558/2000, Training Loss (NLML): -73.8027, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 559/2000, Training Loss (NLML): -71.3609, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 560/2000, Training Loss (NLML): -63.9994, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 561/2000, Training Loss (NLML): -72.5500, (RMSE): 0.1207\n",
      "regionc dfNGP Run 1/1, Epoch 562/2000, Training Loss (NLML): -63.3559, (RMSE): 0.1208\n",
      "regionc dfNGP Run 1/1, Epoch 563/2000, Training Loss (NLML): -63.1857, (RMSE): 0.1207\n",
      "regionc dfNGP Run 1/1, Epoch 564/2000, Training Loss (NLML): -66.9392, (RMSE): 0.1209\n",
      "regionc dfNGP Run 1/1, Epoch 565/2000, Training Loss (NLML): -65.3524, (RMSE): 0.1205\n",
      "regionc dfNGP Run 1/1, Epoch 566/2000, Training Loss (NLML): -56.5608, (RMSE): 0.1208\n",
      "regionc dfNGP Run 1/1, Epoch 567/2000, Training Loss (NLML): -69.6829, (RMSE): 0.1207\n",
      "regionc dfNGP Run 1/1, Epoch 568/2000, Training Loss (NLML): -65.8379, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 569/2000, Training Loss (NLML): -70.9893, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 570/2000, Training Loss (NLML): -62.6220, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 571/2000, Training Loss (NLML): -77.5859, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 572/2000, Training Loss (NLML): -80.2279, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 573/2000, Training Loss (NLML): -74.7610, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 574/2000, Training Loss (NLML): -70.5879, (RMSE): 0.1211\n",
      "regionc dfNGP Run 1/1, Epoch 575/2000, Training Loss (NLML): -74.7110, (RMSE): 0.1203\n",
      "regionc dfNGP Run 1/1, Epoch 576/2000, Training Loss (NLML): -71.2794, (RMSE): 0.1206\n",
      "regionc dfNGP Run 1/1, Epoch 577/2000, Training Loss (NLML): -79.2824, (RMSE): 0.1201\n",
      "regionc dfNGP Run 1/1, Epoch 578/2000, Training Loss (NLML): -76.9411, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 579/2000, Training Loss (NLML): -77.8188, (RMSE): 0.1206\n",
      "regionc dfNGP Run 1/1, Epoch 580/2000, Training Loss (NLML): -70.0101, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 581/2000, Training Loss (NLML): -74.3551, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 582/2000, Training Loss (NLML): -73.7821, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 583/2000, Training Loss (NLML): -75.7765, (RMSE): 0.1211\n",
      "regionc dfNGP Run 1/1, Epoch 584/2000, Training Loss (NLML): -66.9927, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 585/2000, Training Loss (NLML): -78.1873, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 586/2000, Training Loss (NLML): -73.8112, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 587/2000, Training Loss (NLML): -64.9406, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 588/2000, Training Loss (NLML): -79.0607, (RMSE): 0.1209\n",
      "regionc dfNGP Run 1/1, Epoch 589/2000, Training Loss (NLML): -71.9353, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 590/2000, Training Loss (NLML): -72.5220, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 591/2000, Training Loss (NLML): -62.6322, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 592/2000, Training Loss (NLML): -73.5519, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 593/2000, Training Loss (NLML): -69.6465, (RMSE): 0.1206\n",
      "regionc dfNGP Run 1/1, Epoch 594/2000, Training Loss (NLML): -66.6613, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 595/2000, Training Loss (NLML): -75.5528, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 596/2000, Training Loss (NLML): -68.2914, (RMSE): 0.1209\n",
      "regionc dfNGP Run 1/1, Epoch 597/2000, Training Loss (NLML): -75.1913, (RMSE): 0.1210\n",
      "regionc dfNGP Run 1/1, Epoch 598/2000, Training Loss (NLML): -71.3302, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 599/2000, Training Loss (NLML): -67.7491, (RMSE): 0.1209\n",
      "regionc dfNGP Run 1/1, Epoch 600/2000, Training Loss (NLML): -71.1515, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 601/2000, Training Loss (NLML): -74.0581, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 602/2000, Training Loss (NLML): -73.5663, (RMSE): 0.1211\n",
      "regionc dfNGP Run 1/1, Epoch 603/2000, Training Loss (NLML): -68.2030, (RMSE): 0.1215\n",
      "regionc dfNGP Run 1/1, Epoch 604/2000, Training Loss (NLML): -79.1491, (RMSE): 0.1215\n",
      "regionc dfNGP Run 1/1, Epoch 605/2000, Training Loss (NLML): -70.6584, (RMSE): 0.1208\n",
      "regionc dfNGP Run 1/1, Epoch 606/2000, Training Loss (NLML): -85.0038, (RMSE): 0.1215\n",
      "regionc dfNGP Run 1/1, Epoch 607/2000, Training Loss (NLML): -72.6659, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 608/2000, Training Loss (NLML): -70.1198, (RMSE): 0.1211\n",
      "regionc dfNGP Run 1/1, Epoch 609/2000, Training Loss (NLML): -84.4950, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 610/2000, Training Loss (NLML): -78.1602, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 611/2000, Training Loss (NLML): -81.3437, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 612/2000, Training Loss (NLML): -82.9690, (RMSE): 0.1209\n",
      "regionc dfNGP Run 1/1, Epoch 613/2000, Training Loss (NLML): -75.5204, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 614/2000, Training Loss (NLML): -72.0884, (RMSE): 0.1208\n",
      "regionc dfNGP Run 1/1, Epoch 615/2000, Training Loss (NLML): -72.1536, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 616/2000, Training Loss (NLML): -79.6001, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 617/2000, Training Loss (NLML): -76.8481, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 618/2000, Training Loss (NLML): -77.6490, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 619/2000, Training Loss (NLML): -72.8614, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 620/2000, Training Loss (NLML): -73.7485, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 621/2000, Training Loss (NLML): -75.6518, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 622/2000, Training Loss (NLML): -77.7042, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 623/2000, Training Loss (NLML): -73.8984, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 624/2000, Training Loss (NLML): -71.7184, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 625/2000, Training Loss (NLML): -75.2594, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 626/2000, Training Loss (NLML): -82.0418, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 627/2000, Training Loss (NLML): -78.1952, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 628/2000, Training Loss (NLML): -72.0560, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 629/2000, Training Loss (NLML): -82.2394, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 630/2000, Training Loss (NLML): -78.1110, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 631/2000, Training Loss (NLML): -81.6070, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 632/2000, Training Loss (NLML): -89.4590, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 633/2000, Training Loss (NLML): -77.9833, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 634/2000, Training Loss (NLML): -80.0332, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 635/2000, Training Loss (NLML): -77.9377, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 636/2000, Training Loss (NLML): -84.3601, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 637/2000, Training Loss (NLML): -89.3822, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 638/2000, Training Loss (NLML): -85.9513, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 639/2000, Training Loss (NLML): -80.1352, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 640/2000, Training Loss (NLML): -79.5202, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 641/2000, Training Loss (NLML): -84.8878, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 642/2000, Training Loss (NLML): -74.1905, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 643/2000, Training Loss (NLML): -76.3175, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 644/2000, Training Loss (NLML): -76.0814, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 645/2000, Training Loss (NLML): -73.8055, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 646/2000, Training Loss (NLML): -74.9042, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 647/2000, Training Loss (NLML): -76.8712, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 648/2000, Training Loss (NLML): -73.5949, (RMSE): 0.1213\n",
      "regionc dfNGP Run 1/1, Epoch 649/2000, Training Loss (NLML): -76.2385, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 650/2000, Training Loss (NLML): -86.8390, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 651/2000, Training Loss (NLML): -81.5171, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 652/2000, Training Loss (NLML): -90.3810, (RMSE): 0.1215\n",
      "regionc dfNGP Run 1/1, Epoch 653/2000, Training Loss (NLML): -86.4755, (RMSE): 0.1215\n",
      "regionc dfNGP Run 1/1, Epoch 654/2000, Training Loss (NLML): -76.5860, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 655/2000, Training Loss (NLML): -79.9392, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 656/2000, Training Loss (NLML): -81.6812, (RMSE): 0.1212\n",
      "regionc dfNGP Run 1/1, Epoch 657/2000, Training Loss (NLML): -87.4729, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 658/2000, Training Loss (NLML): -88.1523, (RMSE): 0.1214\n",
      "regionc dfNGP Run 1/1, Epoch 659/2000, Training Loss (NLML): -80.8946, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 660/2000, Training Loss (NLML): -85.2315, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 661/2000, Training Loss (NLML): -72.7451, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 662/2000, Training Loss (NLML): -75.2384, (RMSE): 0.1217\n",
      "regionc dfNGP Run 1/1, Epoch 663/2000, Training Loss (NLML): -89.2553, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 664/2000, Training Loss (NLML): -82.3092, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 665/2000, Training Loss (NLML): -81.9764, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 666/2000, Training Loss (NLML): -83.4422, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 667/2000, Training Loss (NLML): -86.4756, (RMSE): 0.1218\n",
      "regionc dfNGP Run 1/1, Epoch 668/2000, Training Loss (NLML): -87.2376, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 669/2000, Training Loss (NLML): -90.0873, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 670/2000, Training Loss (NLML): -80.1906, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 671/2000, Training Loss (NLML): -83.7337, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 672/2000, Training Loss (NLML): -80.5141, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 673/2000, Training Loss (NLML): -80.1656, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 674/2000, Training Loss (NLML): -77.4177, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 675/2000, Training Loss (NLML): -81.8455, (RMSE): 0.1216\n",
      "regionc dfNGP Run 1/1, Epoch 676/2000, Training Loss (NLML): -89.9493, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 677/2000, Training Loss (NLML): -87.4968, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 678/2000, Training Loss (NLML): -83.4235, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 679/2000, Training Loss (NLML): -93.2744, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 680/2000, Training Loss (NLML): -87.6138, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 681/2000, Training Loss (NLML): -79.7887, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 682/2000, Training Loss (NLML): -94.8613, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 683/2000, Training Loss (NLML): -85.9673, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 684/2000, Training Loss (NLML): -82.4298, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 685/2000, Training Loss (NLML): -82.1253, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 686/2000, Training Loss (NLML): -74.6117, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 687/2000, Training Loss (NLML): -86.7039, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 688/2000, Training Loss (NLML): -83.7387, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 689/2000, Training Loss (NLML): -88.3421, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 690/2000, Training Loss (NLML): -90.3641, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 691/2000, Training Loss (NLML): -85.6087, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 692/2000, Training Loss (NLML): -86.7699, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 693/2000, Training Loss (NLML): -91.1811, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 694/2000, Training Loss (NLML): -86.8859, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 695/2000, Training Loss (NLML): -86.5055, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 696/2000, Training Loss (NLML): -73.9071, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 697/2000, Training Loss (NLML): -91.5953, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 698/2000, Training Loss (NLML): -86.1535, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 699/2000, Training Loss (NLML): -85.6467, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 700/2000, Training Loss (NLML): -93.3470, (RMSE): 0.1220\n",
      "regionc dfNGP Run 1/1, Epoch 701/2000, Training Loss (NLML): -86.9341, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 702/2000, Training Loss (NLML): -94.3331, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 703/2000, Training Loss (NLML): -94.9380, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 704/2000, Training Loss (NLML): -83.9309, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 705/2000, Training Loss (NLML): -87.0832, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 706/2000, Training Loss (NLML): -91.5903, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 707/2000, Training Loss (NLML): -81.3888, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 708/2000, Training Loss (NLML): -87.8746, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 709/2000, Training Loss (NLML): -84.7437, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 710/2000, Training Loss (NLML): -82.8051, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 711/2000, Training Loss (NLML): -86.2597, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 712/2000, Training Loss (NLML): -93.2523, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 713/2000, Training Loss (NLML): -85.1327, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 714/2000, Training Loss (NLML): -82.6521, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 715/2000, Training Loss (NLML): -90.6433, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 716/2000, Training Loss (NLML): -86.2279, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 717/2000, Training Loss (NLML): -84.3868, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 718/2000, Training Loss (NLML): -88.6938, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 719/2000, Training Loss (NLML): -88.8615, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 720/2000, Training Loss (NLML): -84.0800, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 721/2000, Training Loss (NLML): -88.4395, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 722/2000, Training Loss (NLML): -80.3900, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 723/2000, Training Loss (NLML): -79.1326, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 724/2000, Training Loss (NLML): -84.4884, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 725/2000, Training Loss (NLML): -79.3203, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 726/2000, Training Loss (NLML): -78.6252, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 727/2000, Training Loss (NLML): -87.0414, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 728/2000, Training Loss (NLML): -82.6164, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 729/2000, Training Loss (NLML): -80.8794, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 730/2000, Training Loss (NLML): -85.1997, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 731/2000, Training Loss (NLML): -83.5567, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 732/2000, Training Loss (NLML): -79.8366, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 733/2000, Training Loss (NLML): -83.4607, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 734/2000, Training Loss (NLML): -85.5902, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 735/2000, Training Loss (NLML): -84.5816, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 736/2000, Training Loss (NLML): -83.3690, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 737/2000, Training Loss (NLML): -93.7152, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 738/2000, Training Loss (NLML): -89.7274, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 739/2000, Training Loss (NLML): -87.4215, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 740/2000, Training Loss (NLML): -87.7916, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 741/2000, Training Loss (NLML): -82.6068, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 742/2000, Training Loss (NLML): -91.1283, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 743/2000, Training Loss (NLML): -96.3914, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 744/2000, Training Loss (NLML): -91.7845, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 745/2000, Training Loss (NLML): -95.1255, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 746/2000, Training Loss (NLML): -92.7356, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 747/2000, Training Loss (NLML): -92.6356, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 748/2000, Training Loss (NLML): -98.4275, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 749/2000, Training Loss (NLML): -96.9425, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 750/2000, Training Loss (NLML): -92.7961, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 751/2000, Training Loss (NLML): -96.3547, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 752/2000, Training Loss (NLML): -96.8008, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 753/2000, Training Loss (NLML): -99.5824, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 754/2000, Training Loss (NLML): -86.5465, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 755/2000, Training Loss (NLML): -97.7763, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 756/2000, Training Loss (NLML): -94.4217, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 757/2000, Training Loss (NLML): -90.2862, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 758/2000, Training Loss (NLML): -84.0547, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 759/2000, Training Loss (NLML): -89.0222, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 760/2000, Training Loss (NLML): -93.0054, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 761/2000, Training Loss (NLML): -86.2398, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 762/2000, Training Loss (NLML): -80.6515, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 763/2000, Training Loss (NLML): -93.5888, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 764/2000, Training Loss (NLML): -90.2989, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 765/2000, Training Loss (NLML): -88.0570, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 766/2000, Training Loss (NLML): -92.6202, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 767/2000, Training Loss (NLML): -74.8879, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 768/2000, Training Loss (NLML): -93.6470, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 769/2000, Training Loss (NLML): -87.2808, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 770/2000, Training Loss (NLML): -90.1403, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 771/2000, Training Loss (NLML): -83.6827, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 772/2000, Training Loss (NLML): -90.6581, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 773/2000, Training Loss (NLML): -90.7417, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 774/2000, Training Loss (NLML): -90.7612, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 775/2000, Training Loss (NLML): -82.5487, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 776/2000, Training Loss (NLML): -95.2025, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 777/2000, Training Loss (NLML): -92.5749, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 778/2000, Training Loss (NLML): -86.9276, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 779/2000, Training Loss (NLML): -91.6044, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 780/2000, Training Loss (NLML): -87.3485, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 781/2000, Training Loss (NLML): -97.8341, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 782/2000, Training Loss (NLML): -85.4512, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 783/2000, Training Loss (NLML): -94.3380, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 784/2000, Training Loss (NLML): -95.4802, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 785/2000, Training Loss (NLML): -93.9971, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 786/2000, Training Loss (NLML): -90.1230, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 787/2000, Training Loss (NLML): -95.4843, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 788/2000, Training Loss (NLML): -97.0339, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 789/2000, Training Loss (NLML): -90.6339, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 790/2000, Training Loss (NLML): -92.6855, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 791/2000, Training Loss (NLML): -92.9377, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 792/2000, Training Loss (NLML): -95.1290, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 793/2000, Training Loss (NLML): -94.3701, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 794/2000, Training Loss (NLML): -93.4522, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 795/2000, Training Loss (NLML): -100.0142, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 796/2000, Training Loss (NLML): -90.8528, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 797/2000, Training Loss (NLML): -87.7906, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 798/2000, Training Loss (NLML): -101.3266, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 799/2000, Training Loss (NLML): -94.2986, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 800/2000, Training Loss (NLML): -89.6788, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 801/2000, Training Loss (NLML): -103.4400, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 802/2000, Training Loss (NLML): -96.3149, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 803/2000, Training Loss (NLML): -93.9424, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 804/2000, Training Loss (NLML): -97.4844, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 805/2000, Training Loss (NLML): -93.2323, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 806/2000, Training Loss (NLML): -83.5777, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 807/2000, Training Loss (NLML): -92.8621, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 808/2000, Training Loss (NLML): -99.2231, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 809/2000, Training Loss (NLML): -91.1524, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 810/2000, Training Loss (NLML): -93.9466, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 811/2000, Training Loss (NLML): -91.3821, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 812/2000, Training Loss (NLML): -85.6303, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 813/2000, Training Loss (NLML): -98.4672, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 814/2000, Training Loss (NLML): -99.1745, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 815/2000, Training Loss (NLML): -86.1883, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 816/2000, Training Loss (NLML): -92.7655, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 817/2000, Training Loss (NLML): -92.2718, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 818/2000, Training Loss (NLML): -94.9986, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 819/2000, Training Loss (NLML): -92.7340, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 820/2000, Training Loss (NLML): -96.6472, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 821/2000, Training Loss (NLML): -80.9789, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 822/2000, Training Loss (NLML): -73.1150, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 823/2000, Training Loss (NLML): -72.5365, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 824/2000, Training Loss (NLML): -76.1420, (RMSE): 0.1261\n",
      "regionc dfNGP Run 1/1, Epoch 825/2000, Training Loss (NLML): -88.5497, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 826/2000, Training Loss (NLML): -80.2876, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 827/2000, Training Loss (NLML): -84.9663, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 828/2000, Training Loss (NLML): -84.5889, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 829/2000, Training Loss (NLML): -88.7977, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 830/2000, Training Loss (NLML): -86.4316, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 831/2000, Training Loss (NLML): -87.6435, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 832/2000, Training Loss (NLML): -86.6989, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 833/2000, Training Loss (NLML): -96.5060, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 834/2000, Training Loss (NLML): -93.1427, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 835/2000, Training Loss (NLML): -96.5827, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 836/2000, Training Loss (NLML): -104.6427, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 837/2000, Training Loss (NLML): -96.2590, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 838/2000, Training Loss (NLML): -98.3226, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 839/2000, Training Loss (NLML): -96.2854, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 840/2000, Training Loss (NLML): -98.9861, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 841/2000, Training Loss (NLML): -90.2633, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 842/2000, Training Loss (NLML): -94.6875, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 843/2000, Training Loss (NLML): -96.5227, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 844/2000, Training Loss (NLML): -96.8097, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 845/2000, Training Loss (NLML): -98.2604, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 846/2000, Training Loss (NLML): -99.8260, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 847/2000, Training Loss (NLML): -98.3020, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 848/2000, Training Loss (NLML): -88.9701, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 849/2000, Training Loss (NLML): -92.9093, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 850/2000, Training Loss (NLML): -98.8261, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 851/2000, Training Loss (NLML): -92.6966, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 852/2000, Training Loss (NLML): -101.6229, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 853/2000, Training Loss (NLML): -100.0175, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 854/2000, Training Loss (NLML): -107.0915, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 855/2000, Training Loss (NLML): -105.5070, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 856/2000, Training Loss (NLML): -97.3368, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 857/2000, Training Loss (NLML): -94.8750, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 858/2000, Training Loss (NLML): -100.1497, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 859/2000, Training Loss (NLML): -99.4728, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 860/2000, Training Loss (NLML): -100.2839, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 861/2000, Training Loss (NLML): -93.2220, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 862/2000, Training Loss (NLML): -98.6594, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 863/2000, Training Loss (NLML): -102.3943, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 864/2000, Training Loss (NLML): -93.4129, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 865/2000, Training Loss (NLML): -94.6549, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 866/2000, Training Loss (NLML): -105.7537, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 867/2000, Training Loss (NLML): -98.5396, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 868/2000, Training Loss (NLML): -95.3357, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 869/2000, Training Loss (NLML): -99.0113, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 870/2000, Training Loss (NLML): -86.9228, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 871/2000, Training Loss (NLML): -109.1302, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 872/2000, Training Loss (NLML): -98.9883, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 873/2000, Training Loss (NLML): -94.4859, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 874/2000, Training Loss (NLML): -88.7351, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 875/2000, Training Loss (NLML): -84.8181, (RMSE): 0.1257\n",
      "regionc dfNGP Run 1/1, Epoch 876/2000, Training Loss (NLML): -80.6126, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 877/2000, Training Loss (NLML): -95.8507, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 878/2000, Training Loss (NLML): -88.0636, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 879/2000, Training Loss (NLML): -83.6284, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 880/2000, Training Loss (NLML): -89.0793, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 881/2000, Training Loss (NLML): -107.8026, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 882/2000, Training Loss (NLML): -95.8089, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 883/2000, Training Loss (NLML): -98.4079, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 884/2000, Training Loss (NLML): -102.0215, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 885/2000, Training Loss (NLML): -99.4901, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 886/2000, Training Loss (NLML): -95.6148, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 887/2000, Training Loss (NLML): -99.0565, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 888/2000, Training Loss (NLML): -97.2352, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 889/2000, Training Loss (NLML): -96.0951, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 890/2000, Training Loss (NLML): -99.5802, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 891/2000, Training Loss (NLML): -96.1469, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 892/2000, Training Loss (NLML): -103.0178, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 893/2000, Training Loss (NLML): -101.8891, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 894/2000, Training Loss (NLML): -105.5902, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 895/2000, Training Loss (NLML): -101.8554, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 896/2000, Training Loss (NLML): -95.4812, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 897/2000, Training Loss (NLML): -96.4851, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 898/2000, Training Loss (NLML): -101.5768, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 899/2000, Training Loss (NLML): -93.8595, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 900/2000, Training Loss (NLML): -89.2112, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 901/2000, Training Loss (NLML): -98.1336, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 902/2000, Training Loss (NLML): -102.2926, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 903/2000, Training Loss (NLML): -96.7143, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 904/2000, Training Loss (NLML): -95.8997, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 905/2000, Training Loss (NLML): -98.5182, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 906/2000, Training Loss (NLML): -105.9175, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 907/2000, Training Loss (NLML): -94.9912, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 908/2000, Training Loss (NLML): -94.8216, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 909/2000, Training Loss (NLML): -104.9386, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 910/2000, Training Loss (NLML): -96.2385, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 911/2000, Training Loss (NLML): -89.3304, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 912/2000, Training Loss (NLML): -100.5421, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 913/2000, Training Loss (NLML): -94.4081, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 914/2000, Training Loss (NLML): -97.4286, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 915/2000, Training Loss (NLML): -105.1203, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 916/2000, Training Loss (NLML): -109.1209, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 917/2000, Training Loss (NLML): -106.2052, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 918/2000, Training Loss (NLML): -95.1398, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 919/2000, Training Loss (NLML): -105.0439, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 920/2000, Training Loss (NLML): -99.1015, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 921/2000, Training Loss (NLML): -89.8376, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 922/2000, Training Loss (NLML): -96.6695, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 923/2000, Training Loss (NLML): -99.2158, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 924/2000, Training Loss (NLML): -90.3257, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 925/2000, Training Loss (NLML): -106.3441, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 926/2000, Training Loss (NLML): -94.7024, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 927/2000, Training Loss (NLML): -98.7581, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 928/2000, Training Loss (NLML): -100.8033, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 929/2000, Training Loss (NLML): -92.8153, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 930/2000, Training Loss (NLML): -95.9759, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 931/2000, Training Loss (NLML): -100.0499, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 932/2000, Training Loss (NLML): -94.7127, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 933/2000, Training Loss (NLML): -107.0865, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 934/2000, Training Loss (NLML): -109.2889, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 935/2000, Training Loss (NLML): -82.5171, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 936/2000, Training Loss (NLML): -101.2181, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 937/2000, Training Loss (NLML): -98.7235, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 938/2000, Training Loss (NLML): -102.4021, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 939/2000, Training Loss (NLML): -108.3848, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 940/2000, Training Loss (NLML): -96.7564, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 941/2000, Training Loss (NLML): -95.3544, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 942/2000, Training Loss (NLML): -97.3836, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 943/2000, Training Loss (NLML): -98.0800, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 944/2000, Training Loss (NLML): -93.7681, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 945/2000, Training Loss (NLML): -102.2058, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 946/2000, Training Loss (NLML): -103.1740, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 947/2000, Training Loss (NLML): -99.7666, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 948/2000, Training Loss (NLML): -95.4102, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 949/2000, Training Loss (NLML): -87.5912, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 950/2000, Training Loss (NLML): -96.3682, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 951/2000, Training Loss (NLML): -96.8143, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 952/2000, Training Loss (NLML): -98.8872, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 953/2000, Training Loss (NLML): -104.8051, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 954/2000, Training Loss (NLML): -89.1460, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 955/2000, Training Loss (NLML): -101.9408, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 956/2000, Training Loss (NLML): -93.6854, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 957/2000, Training Loss (NLML): -97.4380, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 958/2000, Training Loss (NLML): -104.3555, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 959/2000, Training Loss (NLML): -96.5416, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 960/2000, Training Loss (NLML): -93.0450, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 961/2000, Training Loss (NLML): -97.1764, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 962/2000, Training Loss (NLML): -97.3626, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 963/2000, Training Loss (NLML): -100.2600, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 964/2000, Training Loss (NLML): -98.5278, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 965/2000, Training Loss (NLML): -97.2606, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 966/2000, Training Loss (NLML): -90.9514, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 967/2000, Training Loss (NLML): -96.9979, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 968/2000, Training Loss (NLML): -94.7586, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 969/2000, Training Loss (NLML): -99.0464, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 970/2000, Training Loss (NLML): -106.8344, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 971/2000, Training Loss (NLML): -104.3882, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 972/2000, Training Loss (NLML): -98.1155, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 973/2000, Training Loss (NLML): -93.5092, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 974/2000, Training Loss (NLML): -106.9022, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 975/2000, Training Loss (NLML): -93.8661, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 976/2000, Training Loss (NLML): -102.0664, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 977/2000, Training Loss (NLML): -101.5615, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 978/2000, Training Loss (NLML): -101.7733, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 979/2000, Training Loss (NLML): -89.5360, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 980/2000, Training Loss (NLML): -97.0748, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 981/2000, Training Loss (NLML): -97.9657, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 982/2000, Training Loss (NLML): -100.0631, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 983/2000, Training Loss (NLML): -93.1599, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 984/2000, Training Loss (NLML): -101.5879, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 985/2000, Training Loss (NLML): -92.1478, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 986/2000, Training Loss (NLML): -103.4307, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 987/2000, Training Loss (NLML): -97.3048, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 988/2000, Training Loss (NLML): -101.6441, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 989/2000, Training Loss (NLML): -93.4419, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 990/2000, Training Loss (NLML): -105.5380, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 991/2000, Training Loss (NLML): -105.6745, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 992/2000, Training Loss (NLML): -91.1934, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 993/2000, Training Loss (NLML): -104.3450, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 994/2000, Training Loss (NLML): -102.9029, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 995/2000, Training Loss (NLML): -103.0655, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 996/2000, Training Loss (NLML): -101.7434, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 997/2000, Training Loss (NLML): -99.5104, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 998/2000, Training Loss (NLML): -101.6757, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 999/2000, Training Loss (NLML): -93.0321, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1000/2000, Training Loss (NLML): -90.6075, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1001/2000, Training Loss (NLML): -94.3930, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1002/2000, Training Loss (NLML): -88.0172, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1003/2000, Training Loss (NLML): -104.9283, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1004/2000, Training Loss (NLML): -101.8320, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1005/2000, Training Loss (NLML): -103.6037, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1006/2000, Training Loss (NLML): -101.8590, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1007/2000, Training Loss (NLML): -99.9486, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1008/2000, Training Loss (NLML): -104.8582, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1009/2000, Training Loss (NLML): -102.4756, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1010/2000, Training Loss (NLML): -102.4978, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1011/2000, Training Loss (NLML): -96.5072, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1012/2000, Training Loss (NLML): -98.4277, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1013/2000, Training Loss (NLML): -101.9277, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1014/2000, Training Loss (NLML): -96.0727, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1015/2000, Training Loss (NLML): -105.6467, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1016/2000, Training Loss (NLML): -98.6439, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1017/2000, Training Loss (NLML): -97.0569, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1018/2000, Training Loss (NLML): -100.0500, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1019/2000, Training Loss (NLML): -90.5611, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 1020/2000, Training Loss (NLML): -89.0611, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1021/2000, Training Loss (NLML): -101.6690, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1022/2000, Training Loss (NLML): -101.1137, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1023/2000, Training Loss (NLML): -106.0625, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1024/2000, Training Loss (NLML): -103.3281, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1025/2000, Training Loss (NLML): -97.6622, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1026/2000, Training Loss (NLML): -95.9209, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1027/2000, Training Loss (NLML): -98.1920, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1028/2000, Training Loss (NLML): -101.9128, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1029/2000, Training Loss (NLML): -94.5753, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1030/2000, Training Loss (NLML): -93.1482, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1031/2000, Training Loss (NLML): -91.5660, (RMSE): 0.1257\n",
      "regionc dfNGP Run 1/1, Epoch 1032/2000, Training Loss (NLML): -98.7449, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1033/2000, Training Loss (NLML): -97.2693, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1034/2000, Training Loss (NLML): -96.4442, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1035/2000, Training Loss (NLML): -99.5335, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1036/2000, Training Loss (NLML): -94.1465, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1037/2000, Training Loss (NLML): -92.3822, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1038/2000, Training Loss (NLML): -102.8251, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1039/2000, Training Loss (NLML): -98.4096, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1040/2000, Training Loss (NLML): -95.7800, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1041/2000, Training Loss (NLML): -98.9925, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1042/2000, Training Loss (NLML): -95.9393, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1043/2000, Training Loss (NLML): -103.2818, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1044/2000, Training Loss (NLML): -94.9107, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1045/2000, Training Loss (NLML): -96.1018, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1046/2000, Training Loss (NLML): -96.5572, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1047/2000, Training Loss (NLML): -94.5504, (RMSE): 0.1255\n",
      "regionc dfNGP Run 1/1, Epoch 1048/2000, Training Loss (NLML): -86.9065, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1049/2000, Training Loss (NLML): -99.1801, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1050/2000, Training Loss (NLML): -101.2855, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1051/2000, Training Loss (NLML): -102.1175, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1052/2000, Training Loss (NLML): -102.4889, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1053/2000, Training Loss (NLML): -97.5593, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1054/2000, Training Loss (NLML): -92.2931, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1055/2000, Training Loss (NLML): -89.2710, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1056/2000, Training Loss (NLML): -91.5151, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1057/2000, Training Loss (NLML): -90.8601, (RMSE): 0.1256\n",
      "regionc dfNGP Run 1/1, Epoch 1058/2000, Training Loss (NLML): -87.6609, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1059/2000, Training Loss (NLML): -96.7461, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1060/2000, Training Loss (NLML): -98.2692, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1061/2000, Training Loss (NLML): -100.4345, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1062/2000, Training Loss (NLML): -108.0579, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1063/2000, Training Loss (NLML): -95.2984, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1064/2000, Training Loss (NLML): -106.5695, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1065/2000, Training Loss (NLML): -98.8290, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1066/2000, Training Loss (NLML): -99.9414, (RMSE): 0.1255\n",
      "regionc dfNGP Run 1/1, Epoch 1067/2000, Training Loss (NLML): -99.8579, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1068/2000, Training Loss (NLML): -99.7866, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1069/2000, Training Loss (NLML): -105.7856, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1070/2000, Training Loss (NLML): -93.8078, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1071/2000, Training Loss (NLML): -92.8642, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1072/2000, Training Loss (NLML): -104.7584, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1073/2000, Training Loss (NLML): -108.3022, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1074/2000, Training Loss (NLML): -95.6555, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 1075/2000, Training Loss (NLML): -84.7157, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 1076/2000, Training Loss (NLML): -81.9377, (RMSE): 0.1255\n",
      "regionc dfNGP Run 1/1, Epoch 1077/2000, Training Loss (NLML): -102.4236, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1078/2000, Training Loss (NLML): -98.9057, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1079/2000, Training Loss (NLML): -98.7693, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1080/2000, Training Loss (NLML): -97.3370, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1081/2000, Training Loss (NLML): -103.4007, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1082/2000, Training Loss (NLML): -82.1274, (RMSE): 0.1255\n",
      "regionc dfNGP Run 1/1, Epoch 1083/2000, Training Loss (NLML): -98.5870, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1084/2000, Training Loss (NLML): -104.0684, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1085/2000, Training Loss (NLML): -97.0910, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1086/2000, Training Loss (NLML): -102.5589, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 1087/2000, Training Loss (NLML): -90.0666, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1088/2000, Training Loss (NLML): -95.4626, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1089/2000, Training Loss (NLML): -96.6681, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1090/2000, Training Loss (NLML): -89.8357, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1091/2000, Training Loss (NLML): -99.9804, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1092/2000, Training Loss (NLML): -98.0762, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1093/2000, Training Loss (NLML): -104.8754, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1094/2000, Training Loss (NLML): -107.0927, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1095/2000, Training Loss (NLML): -100.3625, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1096/2000, Training Loss (NLML): -96.0368, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1097/2000, Training Loss (NLML): -101.8911, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1098/2000, Training Loss (NLML): -94.9137, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1099/2000, Training Loss (NLML): -94.8426, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 1100/2000, Training Loss (NLML): -97.6131, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1101/2000, Training Loss (NLML): -108.8563, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1102/2000, Training Loss (NLML): -99.9500, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1103/2000, Training Loss (NLML): -107.5025, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1104/2000, Training Loss (NLML): -110.5122, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1105/2000, Training Loss (NLML): -100.5356, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1106/2000, Training Loss (NLML): -103.2448, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1107/2000, Training Loss (NLML): -98.8228, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1108/2000, Training Loss (NLML): -91.7242, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1109/2000, Training Loss (NLML): -100.2981, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1110/2000, Training Loss (NLML): -102.4158, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1111/2000, Training Loss (NLML): -99.8927, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1112/2000, Training Loss (NLML): -96.0323, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1113/2000, Training Loss (NLML): -102.9596, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1114/2000, Training Loss (NLML): -98.9118, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1115/2000, Training Loss (NLML): -111.2856, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1116/2000, Training Loss (NLML): -97.2171, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1117/2000, Training Loss (NLML): -103.2479, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1118/2000, Training Loss (NLML): -104.5165, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1119/2000, Training Loss (NLML): -94.7410, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1120/2000, Training Loss (NLML): -90.3216, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1121/2000, Training Loss (NLML): -105.9221, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1122/2000, Training Loss (NLML): -102.4284, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1123/2000, Training Loss (NLML): -103.3488, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1124/2000, Training Loss (NLML): -93.5829, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1125/2000, Training Loss (NLML): -93.1935, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1126/2000, Training Loss (NLML): -95.0692, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1127/2000, Training Loss (NLML): -91.6939, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1128/2000, Training Loss (NLML): -92.3760, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1129/2000, Training Loss (NLML): -95.9097, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1130/2000, Training Loss (NLML): -108.7000, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1131/2000, Training Loss (NLML): -104.3836, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1132/2000, Training Loss (NLML): -99.3669, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1133/2000, Training Loss (NLML): -102.1604, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1134/2000, Training Loss (NLML): -101.8746, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1135/2000, Training Loss (NLML): -97.0269, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1136/2000, Training Loss (NLML): -103.7073, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1137/2000, Training Loss (NLML): -95.2431, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1138/2000, Training Loss (NLML): -86.7451, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1139/2000, Training Loss (NLML): -103.7003, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1140/2000, Training Loss (NLML): -110.7904, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1141/2000, Training Loss (NLML): -109.1706, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1142/2000, Training Loss (NLML): -101.6546, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1143/2000, Training Loss (NLML): -98.3898, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1144/2000, Training Loss (NLML): -107.2940, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1145/2000, Training Loss (NLML): -99.0268, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1146/2000, Training Loss (NLML): -96.3384, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1147/2000, Training Loss (NLML): -106.4004, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1148/2000, Training Loss (NLML): -107.7129, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1149/2000, Training Loss (NLML): -104.1451, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1150/2000, Training Loss (NLML): -96.4846, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1151/2000, Training Loss (NLML): -101.0916, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1152/2000, Training Loss (NLML): -108.9265, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1153/2000, Training Loss (NLML): -104.0536, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1154/2000, Training Loss (NLML): -114.2616, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1155/2000, Training Loss (NLML): -102.3907, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1156/2000, Training Loss (NLML): -102.6725, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1157/2000, Training Loss (NLML): -90.2804, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1158/2000, Training Loss (NLML): -94.2904, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1159/2000, Training Loss (NLML): -95.9603, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1160/2000, Training Loss (NLML): -110.4590, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1161/2000, Training Loss (NLML): -104.9382, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1162/2000, Training Loss (NLML): -104.1071, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1163/2000, Training Loss (NLML): -104.7998, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1164/2000, Training Loss (NLML): -104.3916, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1165/2000, Training Loss (NLML): -105.3973, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1166/2000, Training Loss (NLML): -109.0886, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1167/2000, Training Loss (NLML): -111.6984, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1168/2000, Training Loss (NLML): -92.5138, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1169/2000, Training Loss (NLML): -97.3046, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1170/2000, Training Loss (NLML): -102.0293, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 1171/2000, Training Loss (NLML): -101.1187, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1172/2000, Training Loss (NLML): -108.0648, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1173/2000, Training Loss (NLML): -104.1480, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1174/2000, Training Loss (NLML): -97.5936, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1175/2000, Training Loss (NLML): -104.4561, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1176/2000, Training Loss (NLML): -104.5895, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1177/2000, Training Loss (NLML): -93.4862, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1178/2000, Training Loss (NLML): -99.8211, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1179/2000, Training Loss (NLML): -95.2940, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1180/2000, Training Loss (NLML): -95.7777, (RMSE): 0.1253\n",
      "regionc dfNGP Run 1/1, Epoch 1181/2000, Training Loss (NLML): -93.7522, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1182/2000, Training Loss (NLML): -102.1269, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1183/2000, Training Loss (NLML): -100.3333, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1184/2000, Training Loss (NLML): -103.7657, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1185/2000, Training Loss (NLML): -93.6786, (RMSE): 0.1259\n",
      "regionc dfNGP Run 1/1, Epoch 1186/2000, Training Loss (NLML): -89.8197, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1187/2000, Training Loss (NLML): -98.0564, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1188/2000, Training Loss (NLML): -108.1321, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1189/2000, Training Loss (NLML): -109.0163, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1190/2000, Training Loss (NLML): -89.6785, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 1191/2000, Training Loss (NLML): -100.4507, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1192/2000, Training Loss (NLML): -110.1662, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1193/2000, Training Loss (NLML): -95.6494, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1194/2000, Training Loss (NLML): -103.6280, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1195/2000, Training Loss (NLML): -97.5507, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1196/2000, Training Loss (NLML): -92.8446, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1197/2000, Training Loss (NLML): -102.0606, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1198/2000, Training Loss (NLML): -94.7577, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1199/2000, Training Loss (NLML): -90.4095, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1200/2000, Training Loss (NLML): -94.0839, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1201/2000, Training Loss (NLML): -105.7415, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1202/2000, Training Loss (NLML): -95.4352, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1203/2000, Training Loss (NLML): -98.4164, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1204/2000, Training Loss (NLML): -101.3859, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1205/2000, Training Loss (NLML): -100.0814, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1206/2000, Training Loss (NLML): -101.2056, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1207/2000, Training Loss (NLML): -105.7064, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1208/2000, Training Loss (NLML): -104.0931, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1209/2000, Training Loss (NLML): -101.7494, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1210/2000, Training Loss (NLML): -109.5096, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1211/2000, Training Loss (NLML): -107.8825, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1212/2000, Training Loss (NLML): -101.1246, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1213/2000, Training Loss (NLML): -96.5673, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1214/2000, Training Loss (NLML): -108.1990, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1215/2000, Training Loss (NLML): -107.0318, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1216/2000, Training Loss (NLML): -100.8558, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1217/2000, Training Loss (NLML): -103.4033, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1218/2000, Training Loss (NLML): -104.4348, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1219/2000, Training Loss (NLML): -110.2758, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1220/2000, Training Loss (NLML): -109.1756, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1221/2000, Training Loss (NLML): -107.6018, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1222/2000, Training Loss (NLML): -103.0343, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1223/2000, Training Loss (NLML): -92.8527, (RMSE): 0.1252\n",
      "regionc dfNGP Run 1/1, Epoch 1224/2000, Training Loss (NLML): -107.0198, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1225/2000, Training Loss (NLML): -97.4055, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1226/2000, Training Loss (NLML): -102.7357, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1227/2000, Training Loss (NLML): -107.1963, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1228/2000, Training Loss (NLML): -110.9121, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1229/2000, Training Loss (NLML): -104.1105, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1230/2000, Training Loss (NLML): -103.4165, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1231/2000, Training Loss (NLML): -101.2887, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1232/2000, Training Loss (NLML): -107.3982, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1233/2000, Training Loss (NLML): -106.8927, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1234/2000, Training Loss (NLML): -103.1514, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1235/2000, Training Loss (NLML): -108.2008, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1236/2000, Training Loss (NLML): -117.4494, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1237/2000, Training Loss (NLML): -104.5724, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1238/2000, Training Loss (NLML): -105.4605, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1239/2000, Training Loss (NLML): -101.7622, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1240/2000, Training Loss (NLML): -99.1911, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1241/2000, Training Loss (NLML): -101.5259, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1242/2000, Training Loss (NLML): -101.9690, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1243/2000, Training Loss (NLML): -85.3520, (RMSE): 0.1256\n",
      "regionc dfNGP Run 1/1, Epoch 1244/2000, Training Loss (NLML): -88.0709, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1245/2000, Training Loss (NLML): -93.0474, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1246/2000, Training Loss (NLML): -93.6844, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1247/2000, Training Loss (NLML): -93.8672, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1248/2000, Training Loss (NLML): -92.1231, (RMSE): 0.1258\n",
      "regionc dfNGP Run 1/1, Epoch 1249/2000, Training Loss (NLML): -93.3833, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1250/2000, Training Loss (NLML): -97.0045, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1251/2000, Training Loss (NLML): -100.4543, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1252/2000, Training Loss (NLML): -103.6670, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1253/2000, Training Loss (NLML): -103.4879, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1254/2000, Training Loss (NLML): -98.0029, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1255/2000, Training Loss (NLML): -103.7010, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1256/2000, Training Loss (NLML): -100.1732, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1257/2000, Training Loss (NLML): -108.2904, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1258/2000, Training Loss (NLML): -104.4074, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1259/2000, Training Loss (NLML): -107.6669, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1260/2000, Training Loss (NLML): -105.5519, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1261/2000, Training Loss (NLML): -94.3628, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1262/2000, Training Loss (NLML): -100.3942, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1263/2000, Training Loss (NLML): -100.8518, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1264/2000, Training Loss (NLML): -96.6212, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1265/2000, Training Loss (NLML): -104.5341, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1266/2000, Training Loss (NLML): -106.1283, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1267/2000, Training Loss (NLML): -107.8984, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1268/2000, Training Loss (NLML): -106.1351, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1269/2000, Training Loss (NLML): -109.8847, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1270/2000, Training Loss (NLML): -104.0063, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1271/2000, Training Loss (NLML): -106.1302, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1272/2000, Training Loss (NLML): -111.5800, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1273/2000, Training Loss (NLML): -105.7005, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1274/2000, Training Loss (NLML): -95.3487, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1275/2000, Training Loss (NLML): -97.3707, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1276/2000, Training Loss (NLML): -107.4690, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1277/2000, Training Loss (NLML): -105.8869, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1278/2000, Training Loss (NLML): -100.8536, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1279/2000, Training Loss (NLML): -106.7067, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1280/2000, Training Loss (NLML): -98.5207, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1281/2000, Training Loss (NLML): -105.9134, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1282/2000, Training Loss (NLML): -108.7901, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1283/2000, Training Loss (NLML): -104.3262, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1284/2000, Training Loss (NLML): -104.4107, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1285/2000, Training Loss (NLML): -97.6380, (RMSE): 0.1254\n",
      "regionc dfNGP Run 1/1, Epoch 1286/2000, Training Loss (NLML): -104.2132, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1287/2000, Training Loss (NLML): -105.8156, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1288/2000, Training Loss (NLML): -104.4848, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1289/2000, Training Loss (NLML): -114.1156, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1290/2000, Training Loss (NLML): -107.8613, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1291/2000, Training Loss (NLML): -100.6501, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1292/2000, Training Loss (NLML): -102.9352, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1293/2000, Training Loss (NLML): -110.6316, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1294/2000, Training Loss (NLML): -110.0813, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1295/2000, Training Loss (NLML): -113.7342, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1296/2000, Training Loss (NLML): -103.9230, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1297/2000, Training Loss (NLML): -108.2385, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1298/2000, Training Loss (NLML): -108.4251, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1299/2000, Training Loss (NLML): -105.8734, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1300/2000, Training Loss (NLML): -100.4782, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1301/2000, Training Loss (NLML): -105.5876, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1302/2000, Training Loss (NLML): -114.9926, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1303/2000, Training Loss (NLML): -107.3189, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1304/2000, Training Loss (NLML): -104.1232, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1305/2000, Training Loss (NLML): -108.1022, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1306/2000, Training Loss (NLML): -109.2829, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1307/2000, Training Loss (NLML): -117.3747, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1308/2000, Training Loss (NLML): -112.8464, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1309/2000, Training Loss (NLML): -117.8397, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1310/2000, Training Loss (NLML): -114.0361, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1311/2000, Training Loss (NLML): -121.5770, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1312/2000, Training Loss (NLML): -111.4306, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1313/2000, Training Loss (NLML): -112.6054, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1314/2000, Training Loss (NLML): -111.9182, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1315/2000, Training Loss (NLML): -114.2093, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1316/2000, Training Loss (NLML): -113.5023, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1317/2000, Training Loss (NLML): -114.6229, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1318/2000, Training Loss (NLML): -108.0977, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1319/2000, Training Loss (NLML): -102.2248, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1320/2000, Training Loss (NLML): -110.0977, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1321/2000, Training Loss (NLML): -102.9914, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1322/2000, Training Loss (NLML): -103.2603, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1323/2000, Training Loss (NLML): -102.1158, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1324/2000, Training Loss (NLML): -100.2487, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1325/2000, Training Loss (NLML): -98.7434, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1326/2000, Training Loss (NLML): -93.8878, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1327/2000, Training Loss (NLML): -89.7892, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1328/2000, Training Loss (NLML): -92.9995, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1329/2000, Training Loss (NLML): -97.4675, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1330/2000, Training Loss (NLML): -95.5634, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1331/2000, Training Loss (NLML): -103.5745, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1332/2000, Training Loss (NLML): -103.0078, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1333/2000, Training Loss (NLML): -95.7375, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1334/2000, Training Loss (NLML): -105.6102, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1335/2000, Training Loss (NLML): -105.3761, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1336/2000, Training Loss (NLML): -100.5975, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1337/2000, Training Loss (NLML): -103.6657, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1338/2000, Training Loss (NLML): -100.9403, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1339/2000, Training Loss (NLML): -102.9911, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1340/2000, Training Loss (NLML): -108.0341, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1341/2000, Training Loss (NLML): -104.9853, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1342/2000, Training Loss (NLML): -102.5320, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1343/2000, Training Loss (NLML): -103.8667, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1344/2000, Training Loss (NLML): -100.3588, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1345/2000, Training Loss (NLML): -107.1937, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1346/2000, Training Loss (NLML): -105.7536, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1347/2000, Training Loss (NLML): -103.7569, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1348/2000, Training Loss (NLML): -107.1502, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1349/2000, Training Loss (NLML): -109.6037, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1350/2000, Training Loss (NLML): -102.1206, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1351/2000, Training Loss (NLML): -102.4574, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1352/2000, Training Loss (NLML): -107.5639, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1353/2000, Training Loss (NLML): -105.3878, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1354/2000, Training Loss (NLML): -105.5973, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1355/2000, Training Loss (NLML): -107.8312, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1356/2000, Training Loss (NLML): -107.2938, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1357/2000, Training Loss (NLML): -103.0622, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1358/2000, Training Loss (NLML): -114.7861, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1359/2000, Training Loss (NLML): -101.5266, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1360/2000, Training Loss (NLML): -109.9930, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1361/2000, Training Loss (NLML): -104.8568, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1362/2000, Training Loss (NLML): -109.3645, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1363/2000, Training Loss (NLML): -103.7566, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1364/2000, Training Loss (NLML): -110.3570, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1365/2000, Training Loss (NLML): -112.2185, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1366/2000, Training Loss (NLML): -96.7982, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1367/2000, Training Loss (NLML): -105.0902, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1368/2000, Training Loss (NLML): -111.6403, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1369/2000, Training Loss (NLML): -103.5819, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1370/2000, Training Loss (NLML): -110.1194, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1371/2000, Training Loss (NLML): -113.2202, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1372/2000, Training Loss (NLML): -107.5023, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1373/2000, Training Loss (NLML): -101.7891, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1374/2000, Training Loss (NLML): -108.8588, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1375/2000, Training Loss (NLML): -120.4232, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1376/2000, Training Loss (NLML): -111.2390, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1377/2000, Training Loss (NLML): -111.8710, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1378/2000, Training Loss (NLML): -108.0799, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1379/2000, Training Loss (NLML): -113.3763, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1380/2000, Training Loss (NLML): -107.9283, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1381/2000, Training Loss (NLML): -108.6360, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1382/2000, Training Loss (NLML): -108.9086, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1383/2000, Training Loss (NLML): -101.6504, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1384/2000, Training Loss (NLML): -95.7014, (RMSE): 0.1250\n",
      "regionc dfNGP Run 1/1, Epoch 1385/2000, Training Loss (NLML): -109.9917, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1386/2000, Training Loss (NLML): -101.9283, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1387/2000, Training Loss (NLML): -111.4508, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1388/2000, Training Loss (NLML): -109.4533, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1389/2000, Training Loss (NLML): -108.4478, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1390/2000, Training Loss (NLML): -107.6284, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1391/2000, Training Loss (NLML): -111.1487, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1392/2000, Training Loss (NLML): -107.6024, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1393/2000, Training Loss (NLML): -108.3222, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1394/2000, Training Loss (NLML): -112.5941, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1395/2000, Training Loss (NLML): -116.2285, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1396/2000, Training Loss (NLML): -116.5170, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1397/2000, Training Loss (NLML): -107.0321, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1398/2000, Training Loss (NLML): -112.3668, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1399/2000, Training Loss (NLML): -114.9383, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1400/2000, Training Loss (NLML): -110.1234, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1401/2000, Training Loss (NLML): -110.5033, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1402/2000, Training Loss (NLML): -112.0567, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1403/2000, Training Loss (NLML): -110.1548, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1404/2000, Training Loss (NLML): -111.6048, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1405/2000, Training Loss (NLML): -109.6275, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1406/2000, Training Loss (NLML): -107.8619, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1407/2000, Training Loss (NLML): -112.5760, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1408/2000, Training Loss (NLML): -108.9947, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1409/2000, Training Loss (NLML): -108.5127, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1410/2000, Training Loss (NLML): -110.1617, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1411/2000, Training Loss (NLML): -108.4901, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1412/2000, Training Loss (NLML): -110.7935, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1413/2000, Training Loss (NLML): -112.0602, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1414/2000, Training Loss (NLML): -109.2632, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1415/2000, Training Loss (NLML): -104.8100, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1416/2000, Training Loss (NLML): -104.6837, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1417/2000, Training Loss (NLML): -112.5895, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1418/2000, Training Loss (NLML): -116.5246, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1419/2000, Training Loss (NLML): -124.0068, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1420/2000, Training Loss (NLML): -113.7099, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1421/2000, Training Loss (NLML): -107.5186, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1422/2000, Training Loss (NLML): -111.6105, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1423/2000, Training Loss (NLML): -109.4925, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1424/2000, Training Loss (NLML): -109.1396, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1425/2000, Training Loss (NLML): -108.7697, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1426/2000, Training Loss (NLML): -105.0248, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1427/2000, Training Loss (NLML): -107.2727, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1428/2000, Training Loss (NLML): -117.5223, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1429/2000, Training Loss (NLML): -118.0862, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1430/2000, Training Loss (NLML): -109.7691, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1431/2000, Training Loss (NLML): -116.6733, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1432/2000, Training Loss (NLML): -106.0011, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1433/2000, Training Loss (NLML): -110.7577, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1434/2000, Training Loss (NLML): -116.0132, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1435/2000, Training Loss (NLML): -107.8905, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1436/2000, Training Loss (NLML): -116.8673, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1437/2000, Training Loss (NLML): -112.9168, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1438/2000, Training Loss (NLML): -113.8559, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1439/2000, Training Loss (NLML): -115.9607, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1440/2000, Training Loss (NLML): -116.3648, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1441/2000, Training Loss (NLML): -118.4793, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1442/2000, Training Loss (NLML): -117.8355, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1443/2000, Training Loss (NLML): -105.9806, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1444/2000, Training Loss (NLML): -103.3893, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1445/2000, Training Loss (NLML): -101.2666, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1446/2000, Training Loss (NLML): -110.6894, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1447/2000, Training Loss (NLML): -109.9287, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1448/2000, Training Loss (NLML): -113.4333, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1449/2000, Training Loss (NLML): -112.8186, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1450/2000, Training Loss (NLML): -115.9079, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1451/2000, Training Loss (NLML): -108.9991, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1452/2000, Training Loss (NLML): -115.5215, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1453/2000, Training Loss (NLML): -114.3819, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1454/2000, Training Loss (NLML): -117.6679, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1455/2000, Training Loss (NLML): -120.3396, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1456/2000, Training Loss (NLML): -120.6893, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1457/2000, Training Loss (NLML): -108.8015, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1458/2000, Training Loss (NLML): -117.4649, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1459/2000, Training Loss (NLML): -116.3195, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1460/2000, Training Loss (NLML): -117.5611, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1461/2000, Training Loss (NLML): -108.7536, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1462/2000, Training Loss (NLML): -107.5073, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1463/2000, Training Loss (NLML): -117.2628, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1464/2000, Training Loss (NLML): -122.5592, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1465/2000, Training Loss (NLML): -123.1892, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1466/2000, Training Loss (NLML): -121.1484, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1467/2000, Training Loss (NLML): -119.3897, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1468/2000, Training Loss (NLML): -111.9515, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1469/2000, Training Loss (NLML): -106.1397, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1470/2000, Training Loss (NLML): -108.3075, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1471/2000, Training Loss (NLML): -109.4410, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1472/2000, Training Loss (NLML): -115.7354, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1473/2000, Training Loss (NLML): -112.8397, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1474/2000, Training Loss (NLML): -111.8672, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1475/2000, Training Loss (NLML): -115.2494, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1476/2000, Training Loss (NLML): -111.1604, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1477/2000, Training Loss (NLML): -111.8648, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1478/2000, Training Loss (NLML): -123.1180, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1479/2000, Training Loss (NLML): -119.3137, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1480/2000, Training Loss (NLML): -116.0664, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1481/2000, Training Loss (NLML): -117.5737, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1482/2000, Training Loss (NLML): -115.8148, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1483/2000, Training Loss (NLML): -119.1279, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1484/2000, Training Loss (NLML): -116.5205, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1485/2000, Training Loss (NLML): -119.6114, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1486/2000, Training Loss (NLML): -118.9045, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1487/2000, Training Loss (NLML): -118.8771, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1488/2000, Training Loss (NLML): -108.9586, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1489/2000, Training Loss (NLML): -98.4735, (RMSE): 0.1251\n",
      "regionc dfNGP Run 1/1, Epoch 1490/2000, Training Loss (NLML): -100.3482, (RMSE): 0.1249\n",
      "regionc dfNGP Run 1/1, Epoch 1491/2000, Training Loss (NLML): -105.6684, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1492/2000, Training Loss (NLML): -112.4118, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1493/2000, Training Loss (NLML): -112.2141, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1494/2000, Training Loss (NLML): -115.2511, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1495/2000, Training Loss (NLML): -115.7937, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1496/2000, Training Loss (NLML): -111.5038, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1497/2000, Training Loss (NLML): -111.3557, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1498/2000, Training Loss (NLML): -116.3847, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1499/2000, Training Loss (NLML): -119.6805, (RMSE): 0.1239\n",
      "regionc dfNGP Run 1/1, Epoch 1500/2000, Training Loss (NLML): -119.8795, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1501/2000, Training Loss (NLML): -121.0082, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1502/2000, Training Loss (NLML): -115.8907, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1503/2000, Training Loss (NLML): -109.6308, (RMSE): 0.1248\n",
      "regionc dfNGP Run 1/1, Epoch 1504/2000, Training Loss (NLML): -102.3759, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1505/2000, Training Loss (NLML): -106.3111, (RMSE): 0.1247\n",
      "regionc dfNGP Run 1/1, Epoch 1506/2000, Training Loss (NLML): -109.7859, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1507/2000, Training Loss (NLML): -112.0432, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1508/2000, Training Loss (NLML): -107.3238, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1509/2000, Training Loss (NLML): -109.1077, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1510/2000, Training Loss (NLML): -106.5743, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1511/2000, Training Loss (NLML): -111.1154, (RMSE): 0.1245\n",
      "regionc dfNGP Run 1/1, Epoch 1512/2000, Training Loss (NLML): -115.4895, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1513/2000, Training Loss (NLML): -118.6684, (RMSE): 0.1243\n",
      "regionc dfNGP Run 1/1, Epoch 1514/2000, Training Loss (NLML): -119.5025, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1515/2000, Training Loss (NLML): -119.6689, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1516/2000, Training Loss (NLML): -112.5261, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1517/2000, Training Loss (NLML): -116.9151, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1518/2000, Training Loss (NLML): -118.4815, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1519/2000, Training Loss (NLML): -116.3417, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1520/2000, Training Loss (NLML): -112.4774, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1521/2000, Training Loss (NLML): -114.9500, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1522/2000, Training Loss (NLML): -115.5818, (RMSE): 0.1246\n",
      "regionc dfNGP Run 1/1, Epoch 1523/2000, Training Loss (NLML): -111.7101, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1524/2000, Training Loss (NLML): -115.1936, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1525/2000, Training Loss (NLML): -117.9107, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1526/2000, Training Loss (NLML): -120.9949, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1527/2000, Training Loss (NLML): -119.6302, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1528/2000, Training Loss (NLML): -116.4744, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1529/2000, Training Loss (NLML): -104.9886, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1530/2000, Training Loss (NLML): -106.4685, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1531/2000, Training Loss (NLML): -104.1779, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1532/2000, Training Loss (NLML): -108.7341, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1533/2000, Training Loss (NLML): -111.1302, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1534/2000, Training Loss (NLML): -118.2226, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1535/2000, Training Loss (NLML): -115.4876, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1536/2000, Training Loss (NLML): -116.2760, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1537/2000, Training Loss (NLML): -109.2846, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1538/2000, Training Loss (NLML): -115.9706, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1539/2000, Training Loss (NLML): -105.2740, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1540/2000, Training Loss (NLML): -107.7713, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1541/2000, Training Loss (NLML): -113.6732, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1542/2000, Training Loss (NLML): -110.9288, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1543/2000, Training Loss (NLML): -110.7633, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1544/2000, Training Loss (NLML): -115.2013, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1545/2000, Training Loss (NLML): -110.3324, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1546/2000, Training Loss (NLML): -113.5685, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1547/2000, Training Loss (NLML): -114.7086, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1548/2000, Training Loss (NLML): -110.2163, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1549/2000, Training Loss (NLML): -110.5310, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1550/2000, Training Loss (NLML): -115.9470, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1551/2000, Training Loss (NLML): -111.1348, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1552/2000, Training Loss (NLML): -112.8194, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1553/2000, Training Loss (NLML): -115.9794, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1554/2000, Training Loss (NLML): -116.8028, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1555/2000, Training Loss (NLML): -112.4680, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1556/2000, Training Loss (NLML): -115.3322, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1557/2000, Training Loss (NLML): -105.3407, (RMSE): 0.1240\n",
      "regionc dfNGP Run 1/1, Epoch 1558/2000, Training Loss (NLML): -114.3713, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1559/2000, Training Loss (NLML): -111.9856, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1560/2000, Training Loss (NLML): -116.2168, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1561/2000, Training Loss (NLML): -113.7880, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1562/2000, Training Loss (NLML): -112.6296, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1563/2000, Training Loss (NLML): -110.7224, (RMSE): 0.1242\n",
      "regionc dfNGP Run 1/1, Epoch 1564/2000, Training Loss (NLML): -117.1845, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1565/2000, Training Loss (NLML): -111.9050, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1566/2000, Training Loss (NLML): -118.3838, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1567/2000, Training Loss (NLML): -113.8527, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1568/2000, Training Loss (NLML): -109.4889, (RMSE): 0.1244\n",
      "regionc dfNGP Run 1/1, Epoch 1569/2000, Training Loss (NLML): -109.7871, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1570/2000, Training Loss (NLML): -119.3825, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1571/2000, Training Loss (NLML): -115.8099, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1572/2000, Training Loss (NLML): -116.0512, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1573/2000, Training Loss (NLML): -118.2048, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1574/2000, Training Loss (NLML): -117.6302, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1575/2000, Training Loss (NLML): -121.0417, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1576/2000, Training Loss (NLML): -119.2401, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1577/2000, Training Loss (NLML): -120.3732, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1578/2000, Training Loss (NLML): -117.3722, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1579/2000, Training Loss (NLML): -118.1411, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1580/2000, Training Loss (NLML): -107.4907, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1581/2000, Training Loss (NLML): -123.1178, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1582/2000, Training Loss (NLML): -115.1701, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1583/2000, Training Loss (NLML): -123.6263, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1584/2000, Training Loss (NLML): -118.2296, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1585/2000, Training Loss (NLML): -124.4654, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1586/2000, Training Loss (NLML): -118.6778, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1587/2000, Training Loss (NLML): -126.3888, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 1588/2000, Training Loss (NLML): -122.8955, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1589/2000, Training Loss (NLML): -121.3974, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1590/2000, Training Loss (NLML): -117.0414, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1591/2000, Training Loss (NLML): -110.6864, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1592/2000, Training Loss (NLML): -119.3098, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1593/2000, Training Loss (NLML): -120.6379, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1594/2000, Training Loss (NLML): -123.5486, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1595/2000, Training Loss (NLML): -119.0654, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1596/2000, Training Loss (NLML): -123.8192, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1597/2000, Training Loss (NLML): -118.9397, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1598/2000, Training Loss (NLML): -120.9660, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1599/2000, Training Loss (NLML): -116.8985, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1600/2000, Training Loss (NLML): -113.1463, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1601/2000, Training Loss (NLML): -116.8509, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1602/2000, Training Loss (NLML): -106.4744, (RMSE): 0.1241\n",
      "regionc dfNGP Run 1/1, Epoch 1603/2000, Training Loss (NLML): -115.2184, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1604/2000, Training Loss (NLML): -113.9861, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1605/2000, Training Loss (NLML): -113.8354, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1606/2000, Training Loss (NLML): -118.6941, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1607/2000, Training Loss (NLML): -118.6662, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1608/2000, Training Loss (NLML): -114.8827, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1609/2000, Training Loss (NLML): -116.7302, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1610/2000, Training Loss (NLML): -116.3212, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1611/2000, Training Loss (NLML): -114.1678, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1612/2000, Training Loss (NLML): -119.9552, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1613/2000, Training Loss (NLML): -114.8159, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1614/2000, Training Loss (NLML): -120.3960, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1615/2000, Training Loss (NLML): -119.2406, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1616/2000, Training Loss (NLML): -119.2278, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1617/2000, Training Loss (NLML): -121.1723, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1618/2000, Training Loss (NLML): -119.5222, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1619/2000, Training Loss (NLML): -118.0715, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1620/2000, Training Loss (NLML): -117.7943, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1621/2000, Training Loss (NLML): -118.0194, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1622/2000, Training Loss (NLML): -120.3023, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1623/2000, Training Loss (NLML): -121.7081, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1624/2000, Training Loss (NLML): -118.6751, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1625/2000, Training Loss (NLML): -118.5466, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1626/2000, Training Loss (NLML): -116.5117, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1627/2000, Training Loss (NLML): -117.1884, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1628/2000, Training Loss (NLML): -124.8086, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1629/2000, Training Loss (NLML): -121.0250, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1630/2000, Training Loss (NLML): -122.6978, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1631/2000, Training Loss (NLML): -122.2979, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1632/2000, Training Loss (NLML): -120.6126, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1633/2000, Training Loss (NLML): -111.9427, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1634/2000, Training Loss (NLML): -113.1243, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1635/2000, Training Loss (NLML): -119.5740, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1636/2000, Training Loss (NLML): -122.4552, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1637/2000, Training Loss (NLML): -121.2265, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1638/2000, Training Loss (NLML): -119.0706, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1639/2000, Training Loss (NLML): -116.2027, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1640/2000, Training Loss (NLML): -116.5446, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1641/2000, Training Loss (NLML): -115.8248, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1642/2000, Training Loss (NLML): -113.1919, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1643/2000, Training Loss (NLML): -114.3255, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1644/2000, Training Loss (NLML): -109.8380, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1645/2000, Training Loss (NLML): -121.2732, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1646/2000, Training Loss (NLML): -121.9660, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1647/2000, Training Loss (NLML): -121.6613, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 1648/2000, Training Loss (NLML): -122.1140, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1649/2000, Training Loss (NLML): -121.0883, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1650/2000, Training Loss (NLML): -124.5214, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 1651/2000, Training Loss (NLML): -115.7566, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1652/2000, Training Loss (NLML): -115.0414, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1653/2000, Training Loss (NLML): -119.7407, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1654/2000, Training Loss (NLML): -123.9496, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1655/2000, Training Loss (NLML): -123.4979, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1656/2000, Training Loss (NLML): -116.0661, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1657/2000, Training Loss (NLML): -112.7915, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1658/2000, Training Loss (NLML): -122.1596, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1659/2000, Training Loss (NLML): -119.3197, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1660/2000, Training Loss (NLML): -114.6599, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1661/2000, Training Loss (NLML): -122.3727, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1662/2000, Training Loss (NLML): -120.5586, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1663/2000, Training Loss (NLML): -120.6858, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1664/2000, Training Loss (NLML): -113.5253, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1665/2000, Training Loss (NLML): -120.8344, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1666/2000, Training Loss (NLML): -116.7408, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1667/2000, Training Loss (NLML): -121.5871, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1668/2000, Training Loss (NLML): -123.0556, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1669/2000, Training Loss (NLML): -129.7622, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1670/2000, Training Loss (NLML): -119.6673, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1671/2000, Training Loss (NLML): -125.7165, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1672/2000, Training Loss (NLML): -121.9181, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1673/2000, Training Loss (NLML): -116.0771, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1674/2000, Training Loss (NLML): -123.4789, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1675/2000, Training Loss (NLML): -124.2126, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1676/2000, Training Loss (NLML): -126.7736, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1677/2000, Training Loss (NLML): -120.2064, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1678/2000, Training Loss (NLML): -121.2705, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1679/2000, Training Loss (NLML): -114.1897, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1680/2000, Training Loss (NLML): -117.9264, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1681/2000, Training Loss (NLML): -119.6331, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1682/2000, Training Loss (NLML): -113.5004, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1683/2000, Training Loss (NLML): -118.9736, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1684/2000, Training Loss (NLML): -128.5426, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1685/2000, Training Loss (NLML): -127.7123, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1686/2000, Training Loss (NLML): -122.0620, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1687/2000, Training Loss (NLML): -126.7560, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1688/2000, Training Loss (NLML): -127.4744, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1689/2000, Training Loss (NLML): -126.5787, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1690/2000, Training Loss (NLML): -124.3703, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 1691/2000, Training Loss (NLML): -126.3931, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1692/2000, Training Loss (NLML): -122.5379, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1693/2000, Training Loss (NLML): -121.5550, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1694/2000, Training Loss (NLML): -123.2623, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1695/2000, Training Loss (NLML): -123.2564, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1696/2000, Training Loss (NLML): -115.2714, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1697/2000, Training Loss (NLML): -108.1045, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1698/2000, Training Loss (NLML): -113.8992, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1699/2000, Training Loss (NLML): -110.9494, (RMSE): 0.1238\n",
      "regionc dfNGP Run 1/1, Epoch 1700/2000, Training Loss (NLML): -121.7676, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1701/2000, Training Loss (NLML): -119.9221, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1702/2000, Training Loss (NLML): -120.2875, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1703/2000, Training Loss (NLML): -129.0275, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1704/2000, Training Loss (NLML): -121.9994, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1705/2000, Training Loss (NLML): -125.7688, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1706/2000, Training Loss (NLML): -124.7355, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1707/2000, Training Loss (NLML): -118.1953, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1708/2000, Training Loss (NLML): -118.7761, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1709/2000, Training Loss (NLML): -118.2449, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1710/2000, Training Loss (NLML): -120.1609, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1711/2000, Training Loss (NLML): -125.5193, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1712/2000, Training Loss (NLML): -117.7000, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1713/2000, Training Loss (NLML): -113.0011, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1714/2000, Training Loss (NLML): -111.6939, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1715/2000, Training Loss (NLML): -111.0146, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1716/2000, Training Loss (NLML): -114.5826, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1717/2000, Training Loss (NLML): -122.9117, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1718/2000, Training Loss (NLML): -118.0490, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1719/2000, Training Loss (NLML): -113.0577, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1720/2000, Training Loss (NLML): -114.5790, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1721/2000, Training Loss (NLML): -111.6676, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1722/2000, Training Loss (NLML): -120.0254, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1723/2000, Training Loss (NLML): -122.0269, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1724/2000, Training Loss (NLML): -130.2514, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1725/2000, Training Loss (NLML): -124.3305, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1726/2000, Training Loss (NLML): -115.0083, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1727/2000, Training Loss (NLML): -115.9175, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1728/2000, Training Loss (NLML): -118.8296, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1729/2000, Training Loss (NLML): -126.0909, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1730/2000, Training Loss (NLML): -129.5155, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1731/2000, Training Loss (NLML): -125.8324, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1732/2000, Training Loss (NLML): -116.1389, (RMSE): 0.1237\n",
      "regionc dfNGP Run 1/1, Epoch 1733/2000, Training Loss (NLML): -112.5536, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1734/2000, Training Loss (NLML): -123.4472, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1735/2000, Training Loss (NLML): -125.3280, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1736/2000, Training Loss (NLML): -120.5872, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1737/2000, Training Loss (NLML): -119.9237, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1738/2000, Training Loss (NLML): -129.6316, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1739/2000, Training Loss (NLML): -129.8926, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1740/2000, Training Loss (NLML): -129.1284, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1741/2000, Training Loss (NLML): -126.6035, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1742/2000, Training Loss (NLML): -121.7076, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1743/2000, Training Loss (NLML): -121.2146, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1744/2000, Training Loss (NLML): -112.1465, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1745/2000, Training Loss (NLML): -127.2426, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1746/2000, Training Loss (NLML): -126.5372, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1747/2000, Training Loss (NLML): -129.0589, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1748/2000, Training Loss (NLML): -128.8566, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1749/2000, Training Loss (NLML): -123.7835, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1750/2000, Training Loss (NLML): -126.9421, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1751/2000, Training Loss (NLML): -114.6593, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1752/2000, Training Loss (NLML): -114.1549, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1753/2000, Training Loss (NLML): -114.6953, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1754/2000, Training Loss (NLML): -117.0005, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1755/2000, Training Loss (NLML): -126.7153, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1756/2000, Training Loss (NLML): -123.4737, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1757/2000, Training Loss (NLML): -126.9640, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1758/2000, Training Loss (NLML): -128.7721, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1759/2000, Training Loss (NLML): -125.4352, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1760/2000, Training Loss (NLML): -119.0116, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1761/2000, Training Loss (NLML): -120.0209, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1762/2000, Training Loss (NLML): -118.7226, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1763/2000, Training Loss (NLML): -122.4267, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1764/2000, Training Loss (NLML): -118.1552, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1765/2000, Training Loss (NLML): -132.9686, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1766/2000, Training Loss (NLML): -131.7395, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1767/2000, Training Loss (NLML): -127.0246, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1768/2000, Training Loss (NLML): -118.1825, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1769/2000, Training Loss (NLML): -124.8785, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1770/2000, Training Loss (NLML): -116.0468, (RMSE): 0.1235\n",
      "regionc dfNGP Run 1/1, Epoch 1771/2000, Training Loss (NLML): -123.7694, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1772/2000, Training Loss (NLML): -122.4808, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1773/2000, Training Loss (NLML): -126.1183, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 1774/2000, Training Loss (NLML): -124.1018, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1775/2000, Training Loss (NLML): -126.1124, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1776/2000, Training Loss (NLML): -125.0534, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1777/2000, Training Loss (NLML): -129.2410, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1778/2000, Training Loss (NLML): -125.4603, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1779/2000, Training Loss (NLML): -126.4365, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1780/2000, Training Loss (NLML): -123.7835, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1781/2000, Training Loss (NLML): -129.8034, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1782/2000, Training Loss (NLML): -131.4358, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1783/2000, Training Loss (NLML): -128.4940, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1784/2000, Training Loss (NLML): -125.9546, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1785/2000, Training Loss (NLML): -123.4986, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1786/2000, Training Loss (NLML): -123.4153, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1787/2000, Training Loss (NLML): -118.6167, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1788/2000, Training Loss (NLML): -127.6048, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1789/2000, Training Loss (NLML): -131.8082, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1790/2000, Training Loss (NLML): -128.7586, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1791/2000, Training Loss (NLML): -127.0619, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1792/2000, Training Loss (NLML): -125.5988, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1793/2000, Training Loss (NLML): -125.5520, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1794/2000, Training Loss (NLML): -127.5467, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1795/2000, Training Loss (NLML): -118.4725, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1796/2000, Training Loss (NLML): -127.7813, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1797/2000, Training Loss (NLML): -122.2814, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1798/2000, Training Loss (NLML): -126.8411, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1799/2000, Training Loss (NLML): -129.1895, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1800/2000, Training Loss (NLML): -126.0067, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1801/2000, Training Loss (NLML): -130.7773, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1802/2000, Training Loss (NLML): -126.9309, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1803/2000, Training Loss (NLML): -126.6938, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1804/2000, Training Loss (NLML): -135.1643, (RMSE): 0.1222\n",
      "regionc dfNGP Run 1/1, Epoch 1805/2000, Training Loss (NLML): -127.5614, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1806/2000, Training Loss (NLML): -126.0052, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1807/2000, Training Loss (NLML): -129.2039, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1808/2000, Training Loss (NLML): -133.4751, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1809/2000, Training Loss (NLML): -129.6760, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1810/2000, Training Loss (NLML): -121.0378, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1811/2000, Training Loss (NLML): -117.3293, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1812/2000, Training Loss (NLML): -131.0674, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1813/2000, Training Loss (NLML): -135.9831, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1814/2000, Training Loss (NLML): -124.9229, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1815/2000, Training Loss (NLML): -130.1683, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1816/2000, Training Loss (NLML): -133.0905, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1817/2000, Training Loss (NLML): -127.4933, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1818/2000, Training Loss (NLML): -132.4176, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1819/2000, Training Loss (NLML): -122.4768, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1820/2000, Training Loss (NLML): -126.3315, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1821/2000, Training Loss (NLML): -123.7000, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1822/2000, Training Loss (NLML): -120.2428, (RMSE): 0.1234\n",
      "regionc dfNGP Run 1/1, Epoch 1823/2000, Training Loss (NLML): -123.9820, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1824/2000, Training Loss (NLML): -127.8664, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1825/2000, Training Loss (NLML): -136.9640, (RMSE): 0.1223\n",
      "regionc dfNGP Run 1/1, Epoch 1826/2000, Training Loss (NLML): -134.3581, (RMSE): 0.1221\n",
      "regionc dfNGP Run 1/1, Epoch 1827/2000, Training Loss (NLML): -140.8363, (RMSE): 0.1219\n",
      "regionc dfNGP Run 1/1, Epoch 1828/2000, Training Loss (NLML): -133.9506, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1829/2000, Training Loss (NLML): -122.4085, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1830/2000, Training Loss (NLML): -126.4251, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1831/2000, Training Loss (NLML): -123.7070, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1832/2000, Training Loss (NLML): -127.0777, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1833/2000, Training Loss (NLML): -130.2690, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1834/2000, Training Loss (NLML): -127.9697, (RMSE): 0.1233\n",
      "regionc dfNGP Run 1/1, Epoch 1835/2000, Training Loss (NLML): -131.0226, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1836/2000, Training Loss (NLML): -123.8000, (RMSE): 0.1230\n",
      "regionc dfNGP Run 1/1, Epoch 1837/2000, Training Loss (NLML): -129.4328, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1838/2000, Training Loss (NLML): -130.4735, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1839/2000, Training Loss (NLML): -129.8491, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1840/2000, Training Loss (NLML): -127.1433, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1841/2000, Training Loss (NLML): -129.4652, (RMSE): 0.1232\n",
      "regionc dfNGP Run 1/1, Epoch 1842/2000, Training Loss (NLML): -125.9486, (RMSE): 0.1227\n",
      "regionc dfNGP Run 1/1, Epoch 1843/2000, Training Loss (NLML): -131.0280, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1844/2000, Training Loss (NLML): -134.7051, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1845/2000, Training Loss (NLML): -131.9687, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1846/2000, Training Loss (NLML): -131.8855, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1847/2000, Training Loss (NLML): -124.3896, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1848/2000, Training Loss (NLML): -121.5230, (RMSE): 0.1236\n",
      "regionc dfNGP Run 1/1, Epoch 1849/2000, Training Loss (NLML): -129.2422, (RMSE): 0.1228\n",
      "regionc dfNGP Run 1/1, Epoch 1850/2000, Training Loss (NLML): -127.1651, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1851/2000, Training Loss (NLML): -130.3896, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1852/2000, Training Loss (NLML): -128.0321, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1853/2000, Training Loss (NLML): -131.0918, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1854/2000, Training Loss (NLML): -133.1928, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1855/2000, Training Loss (NLML): -124.8464, (RMSE): 0.1231\n",
      "regionc dfNGP Run 1/1, Epoch 1856/2000, Training Loss (NLML): -122.0150, (RMSE): 0.1229\n",
      "regionc dfNGP Run 1/1, Epoch 1857/2000, Training Loss (NLML): -130.5537, (RMSE): 0.1226\n",
      "regionc dfNGP Run 1/1, Epoch 1858/2000, Training Loss (NLML): -133.4625, (RMSE): 0.1225\n",
      "regionc dfNGP Run 1/1, Epoch 1859/2000, Training Loss (NLML): -133.7696, (RMSE): 0.1224\n",
      "regionc dfNGP Run 1/1, Epoch 1860/2000, Training Loss (NLML): 6575.5029, (RMSE): 0.5922\n",
      "regionc dfNGP Run 1/1, Epoch 1861/2000, Training Loss (NLML): -63.3679, (RMSE): 0.1101\n",
      "regionc dfNGP Run 1/1, Epoch 1862/2000, Training Loss (NLML): 65.8881, (RMSE): 0.0911\n",
      "regionc dfNGP Run 1/1, Epoch 1863/2000, Training Loss (NLML): 408.3617, (RMSE): 0.0774\n",
      "regionc dfNGP Run 1/1, Epoch 1864/2000, Training Loss (NLML): 949.0031, (RMSE): 0.0556\n",
      "regionc dfNGP Run 1/1, Epoch 1865/2000, Training Loss (NLML): 1841.5370, (RMSE): 0.0289\n",
      "regionc dfNGP Run 1/1, Epoch 1866/2000, Training Loss (NLML): 3056.3013, (RMSE): 0.0130\n",
      "regionc dfNGP Run 1/1, Epoch 1867/2000, Training Loss (NLML): 4121.8081, (RMSE): 0.0001\n",
      "regionc dfNGP Run 1/1, Epoch 1868/2000, Training Loss (NLML): 5231.8442, (RMSE): 0.0000\n",
      "regionc dfNGP Run 1/1, Epoch 1869/2000, Training Loss (NLML): 3051.4653, (RMSE): 0.0108\n",
      "regionc dfNGP Run 1/1, Epoch 1870/2000, Training Loss (NLML): 1831.2090, (RMSE): 0.0312\n",
      "regionc dfNGP Run 1/1, Epoch 1871/2000, Training Loss (NLML): 1120.1238, (RMSE): 0.0450\n",
      "regionc dfNGP Run 1/1, Epoch 1872/2000, Training Loss (NLML): 689.9058, (RMSE): 0.0530\n",
      "regionc dfNGP Run 1/1, Epoch 1873/2000, Training Loss (NLML): 430.1494, (RMSE): 0.0598\n",
      "regionc dfNGP Run 1/1, Epoch 1874/2000, Training Loss (NLML): 306.5528, (RMSE): 0.0731\n",
      "regionc dfNGP Run 1/1, Epoch 1875/2000, Training Loss (NLML): 217.4620, (RMSE): 0.0795\n",
      "regionc dfNGP Run 1/1, Epoch 1876/2000, Training Loss (NLML): 179.6836, (RMSE): 0.0881\n",
      "regionc dfNGP Run 1/1, Epoch 1877/2000, Training Loss (NLML): 138.6463, (RMSE): 0.0936\n",
      "regionc dfNGP Run 1/1, Epoch 1878/2000, Training Loss (NLML): 2532.6853, (RMSE): 0.0904\n",
      "regionc dfNGP Run 1/1, Epoch 1879/2000, Training Loss (NLML): 2810.5012, (RMSE): 0.0928\n",
      "regionc dfNGP Run 1/1, Epoch 1880/2000, Training Loss (NLML): 3186.1445, (RMSE): 0.0958\n",
      "regionc dfNGP Run 1/1, Epoch 1881/2000, Training Loss (NLML): 3166.2976, (RMSE): 0.0969\n",
      "regionc dfNGP Run 1/1, Epoch 1882/2000, Training Loss (NLML): 2952.0525, (RMSE): 0.0951\n",
      "regionc dfNGP Run 1/1, Epoch 1883/2000, Training Loss (NLML): 2959.3513, (RMSE): 0.0936\n",
      "regionc dfNGP Run 1/1, Epoch 1884/2000, Training Loss (NLML): 2765.8684, (RMSE): 0.0935\n",
      "regionc dfNGP Run 1/1, Epoch 1885/2000, Training Loss (NLML): 2782.0540, (RMSE): 0.0909\n",
      "regionc dfNGP Run 1/1, Epoch 1886/2000, Training Loss (NLML): 2952.7554, (RMSE): 0.0920\n",
      "regionc dfNGP Run 1/1, Epoch 1887/2000, Training Loss (NLML): 2914.7539, (RMSE): 0.0932\n",
      "regionc dfNGP Run 1/1, Epoch 1888/2000, Training Loss (NLML): 2709.0510, (RMSE): 0.0905\n",
      "regionc dfNGP Run 1/1, Epoch 1889/2000, Training Loss (NLML): 2684.7627, (RMSE): 0.0883\n",
      "regionc dfNGP Run 1/1, Epoch 1890/2000, Training Loss (NLML): 2713.8225, (RMSE): 0.0879\n",
      "regionc dfNGP Run 1/1, Epoch 1891/2000, Training Loss (NLML): 2593.5481, (RMSE): 0.0854\n",
      "regionc dfNGP Run 1/1, Epoch 1892/2000, Training Loss (NLML): 2584.2915, (RMSE): 0.0841\n",
      "regionc dfNGP Run 1/1, Epoch 1893/2000, Training Loss (NLML): 2341.7825, (RMSE): 0.0835\n",
      "regionc dfNGP Run 1/1, Epoch 1894/2000, Training Loss (NLML): 2432.7815, (RMSE): 0.0821\n",
      "regionc dfNGP Run 1/1, Epoch 1895/2000, Training Loss (NLML): 2692.9353, (RMSE): 0.0867\n",
      "regionc dfNGP Run 1/1, Epoch 1896/2000, Training Loss (NLML): 599.9609, (RMSE): 0.0819\n",
      "regionc dfNGP Run 1/1, Epoch 1897/2000, Training Loss (NLML): 664.1977, (RMSE): 0.0805\n",
      "regionc dfNGP Run 1/1, Epoch 1898/2000, Training Loss (NLML): 708.1228, (RMSE): 0.0790\n",
      "regionc dfNGP Run 1/1, Epoch 1899/2000, Training Loss (NLML): 734.8401, (RMSE): 0.0781\n",
      "regionc dfNGP Run 1/1, Epoch 1900/2000, Training Loss (NLML): 736.8152, (RMSE): 0.0780\n",
      "regionc dfNGP Run 1/1, Epoch 1901/2000, Training Loss (NLML): 716.7533, (RMSE): 0.0777\n",
      "regionc dfNGP Run 1/1, Epoch 1902/2000, Training Loss (NLML): 2348.2715, (RMSE): 0.0852\n",
      "regionc dfNGP Run 1/1, Epoch 1903/2000, Training Loss (NLML): 658.9453, (RMSE): 0.0784\n",
      "regionc dfNGP Run 1/1, Epoch 1904/2000, Training Loss (NLML): 626.5283, (RMSE): 0.0790\n",
      "regionc dfNGP Run 1/1, Epoch 1905/2000, Training Loss (NLML): 2542.9968, (RMSE): 0.0777\n",
      "regionc dfNGP Run 1/1, Epoch 1906/2000, Training Loss (NLML): 2696.3022, (RMSE): 0.0851\n",
      "regionc dfNGP Run 1/1, Epoch 1907/2000, Training Loss (NLML): 2761.6631, (RMSE): 0.0811\n",
      "regionc dfNGP Run 1/1, Epoch 1908/2000, Training Loss (NLML): 2361.1592, (RMSE): 0.0784\n",
      "regionc dfNGP Run 1/1, Epoch 1909/2000, Training Loss (NLML): 2699.3899, (RMSE): 0.1317\n",
      "regionc dfNGP Run 1/1, Epoch 1910/2000, Training Loss (NLML): 2193.5613, (RMSE): 0.0775\n",
      "regionc dfNGP Run 1/1, Epoch 1911/2000, Training Loss (NLML): 2049.5103, (RMSE): 0.0749\n",
      "regionc dfNGP Run 1/1, Epoch 1912/2000, Training Loss (NLML): 2223.3982, (RMSE): 0.0762\n",
      "regionc dfNGP Run 1/1, Epoch 1913/2000, Training Loss (NLML): 2310.1221, (RMSE): 0.0744\n",
      "regionc dfNGP Run 1/1, Epoch 1914/2000, Training Loss (NLML): 2061.1731, (RMSE): 0.0714\n",
      "regionc dfNGP Run 1/1, Epoch 1915/2000, Training Loss (NLML): 1975.0977, (RMSE): 0.0678\n",
      "regionc dfNGP Run 1/1, Epoch 1916/2000, Training Loss (NLML): 2004.6553, (RMSE): 0.0687\n",
      "regionc dfNGP Run 1/1, Epoch 1917/2000, Training Loss (NLML): 1835.0688, (RMSE): 0.0653\n",
      "regionc dfNGP Run 1/1, Epoch 1918/2000, Training Loss (NLML): 1598.7249, (RMSE): 0.0609\n",
      "regionc dfNGP Run 1/1, Epoch 1919/2000, Training Loss (NLML): 1462.7041, (RMSE): 0.0591\n",
      "regionc dfNGP Run 1/1, Epoch 1920/2000, Training Loss (NLML): 693.9161, (RMSE): 0.0618\n",
      "regionc dfNGP Run 1/1, Epoch 1921/2000, Training Loss (NLML): 1425.9138, (RMSE): 0.0563\n",
      "regionc dfNGP Run 1/1, Epoch 1922/2000, Training Loss (NLML): 732.4943, (RMSE): 0.0560\n",
      "regionc dfNGP Run 1/1, Epoch 1923/2000, Training Loss (NLML): 743.5261, (RMSE): 0.0543\n",
      "regionc dfNGP Run 1/1, Epoch 1924/2000, Training Loss (NLML): 749.1812, (RMSE): 0.0534\n",
      "regionc dfNGP Run 1/1, Epoch 1925/2000, Training Loss (NLML): 741.5596, (RMSE): 0.0523\n",
      "regionc dfNGP Run 1/1, Epoch 1926/2000, Training Loss (NLML): 727.2676, (RMSE): 0.0520\n",
      "regionc dfNGP Run 1/1, Epoch 1927/2000, Training Loss (NLML): 707.8783, (RMSE): 0.0526\n",
      "regionc dfNGP Run 1/1, Epoch 1928/2000, Training Loss (NLML): 1201.4319, (RMSE): 0.0622\n",
      "regionc dfNGP Run 1/1, Epoch 1929/2000, Training Loss (NLML): 686.6577, (RMSE): 0.0524\n",
      "regionc dfNGP Run 1/1, Epoch 1930/2000, Training Loss (NLML): 681.6958, (RMSE): 0.0523\n",
      "regionc dfNGP Run 1/1, Epoch 1931/2000, Training Loss (NLML): 667.7794, (RMSE): 0.0524\n",
      "regionc dfNGP Run 1/1, Epoch 1932/2000, Training Loss (NLML): 651.1560, (RMSE): 0.0528\n",
      "regionc dfNGP Run 1/1, Epoch 1933/2000, Training Loss (NLML): 627.1794, (RMSE): 0.0537\n",
      "regionc dfNGP Run 1/1, Epoch 1934/2000, Training Loss (NLML): 600.2617, (RMSE): 0.0548\n",
      "regionc dfNGP Run 1/1, Epoch 1935/2000, Training Loss (NLML): 567.5720, (RMSE): 0.0564\n",
      "regionc dfNGP Run 1/1, Epoch 1936/2000, Training Loss (NLML): 535.4340, (RMSE): 0.0577\n",
      "regionc dfNGP Run 1/1, Epoch 1937/2000, Training Loss (NLML): 502.3434, (RMSE): 0.0591\n",
      "regionc dfNGP Run 1/1, Epoch 1938/2000, Training Loss (NLML): 467.9044, (RMSE): 0.0610\n",
      "regionc dfNGP Run 1/1, Epoch 1939/2000, Training Loss (NLML): 1431.6464, (RMSE): 0.0790\n",
      "regionc dfNGP Run 1/1, Epoch 1940/2000, Training Loss (NLML): 411.4525, (RMSE): 0.0641\n",
      "regionc dfNGP Run 1/1, Epoch 1941/2000, Training Loss (NLML): 390.5476, (RMSE): 0.0654\n",
      "regionc dfNGP Run 1/1, Epoch 1942/2000, Training Loss (NLML): 364.7899, (RMSE): 0.0667\n",
      "regionc dfNGP Run 1/1, Epoch 1943/2000, Training Loss (NLML): 1496.5260, (RMSE): 0.0963\n",
      "regionc dfNGP Run 1/1, Epoch 1944/2000, Training Loss (NLML): 338.4232, (RMSE): 0.0685\n",
      "regionc dfNGP Run 1/1, Epoch 1945/2000, Training Loss (NLML): 328.6470, (RMSE): 0.0686\n",
      "regionc dfNGP Run 1/1, Epoch 1946/2000, Training Loss (NLML): 1580.4595, (RMSE): 0.0697\n",
      "regionc dfNGP Run 1/1, Epoch 1947/2000, Training Loss (NLML): 317.4193, (RMSE): 0.0690\n",
      "regionc dfNGP Run 1/1, Epoch 1948/2000, Training Loss (NLML): 314.6500, (RMSE): 0.0688\n",
      "regionc dfNGP Run 1/1, Epoch 1949/2000, Training Loss (NLML): 310.7626, (RMSE): 0.0690\n",
      "regionc dfNGP Run 1/1, Epoch 1950/2000, Training Loss (NLML): 301.5913, (RMSE): 0.0693\n",
      "regionc dfNGP Run 1/1, Epoch 1951/2000, Training Loss (NLML): 293.9426, (RMSE): 0.0699\n",
      "regionc dfNGP Run 1/1, Epoch 1952/2000, Training Loss (NLML): 282.8987, (RMSE): 0.0703\n",
      "regionc dfNGP Run 1/1, Epoch 1953/2000, Training Loss (NLML): 270.2655, (RMSE): 0.0710\n",
      "regionc dfNGP Run 1/1, Epoch 1954/2000, Training Loss (NLML): 1452.6912, (RMSE): 0.0724\n",
      "regionc dfNGP Run 1/1, Epoch 1955/2000, Training Loss (NLML): 250.9178, (RMSE): 0.0721\n",
      "regionc dfNGP Run 1/1, Epoch 1956/2000, Training Loss (NLML): 245.3579, (RMSE): 0.0723\n",
      "regionc dfNGP Run 1/1, Epoch 1957/2000, Training Loss (NLML): 237.1158, (RMSE): 0.0727\n",
      "regionc dfNGP Run 1/1, Epoch 1958/2000, Training Loss (NLML): 226.7277, (RMSE): 0.0734\n",
      "regionc dfNGP Run 1/1, Epoch 1959/2000, Training Loss (NLML): 216.1014, (RMSE): 0.0742\n",
      "regionc dfNGP Run 1/1, Epoch 1960/2000, Training Loss (NLML): 207.3166, (RMSE): 0.0748\n",
      "regionc dfNGP Run 1/1, Epoch 1961/2000, Training Loss (NLML): 196.8639, (RMSE): 0.0755\n",
      "regionc dfNGP Run 1/1, Epoch 1962/2000, Training Loss (NLML): 1490.5231, (RMSE): 0.0709\n",
      "regionc dfNGP Run 1/1, Epoch 1963/2000, Training Loss (NLML): 1509.6423, (RMSE): 0.0706\n",
      "regionc dfNGP Run 1/1, Epoch 1964/2000, Training Loss (NLML): 178.4657, (RMSE): 0.0769\n",
      "regionc dfNGP Run 1/1, Epoch 1965/2000, Training Loss (NLML): 178.2572, (RMSE): 0.0768\n",
      "regionc dfNGP Run 1/1, Epoch 1966/2000, Training Loss (NLML): 1551.8717, (RMSE): 0.0736\n",
      "regionc dfNGP Run 1/1, Epoch 1967/2000, Training Loss (NLML): 184.3109, (RMSE): 0.0772\n",
      "regionc dfNGP Run 1/1, Epoch 1968/2000, Training Loss (NLML): 183.8637, (RMSE): 0.0766\n",
      "regionc dfNGP Run 1/1, Epoch 1969/2000, Training Loss (NLML): 188.4787, (RMSE): 0.0772\n",
      "regionc dfNGP Run 1/1, Epoch 1970/2000, Training Loss (NLML): 185.9117, (RMSE): 0.0767\n",
      "regionc dfNGP Run 1/1, Epoch 1971/2000, Training Loss (NLML): 179.6894, (RMSE): 0.0768\n",
      "regionc dfNGP Run 1/1, Epoch 1972/2000, Training Loss (NLML): 1676.3182, (RMSE): 0.0694\n",
      "regionc dfNGP Run 1/1, Epoch 1973/2000, Training Loss (NLML): 173.9453, (RMSE): 0.0763\n",
      "regionc dfNGP Run 1/1, Epoch 1974/2000, Training Loss (NLML): 1915.5015, (RMSE): 0.0918\n",
      "regionc dfNGP Run 1/1, Epoch 1975/2000, Training Loss (NLML): 186.1319, (RMSE): 0.0752\n",
      "regionc dfNGP Run 1/1, Epoch 1976/2000, Training Loss (NLML): 195.1607, (RMSE): 0.0743\n",
      "regionc dfNGP Run 1/1, Epoch 1977/2000, Training Loss (NLML): 198.7819, (RMSE): 0.0738\n",
      "regionc dfNGP Run 1/1, Epoch 1978/2000, Training Loss (NLML): 201.5098, (RMSE): 0.0734\n",
      "regionc dfNGP Run 1/1, Epoch 1979/2000, Training Loss (NLML): 1595.9597, (RMSE): 0.0802\n",
      "regionc dfNGP Run 1/1, Epoch 1980/2000, Training Loss (NLML): 209.4034, (RMSE): 0.0723\n",
      "regionc dfNGP Run 1/1, Epoch 1981/2000, Training Loss (NLML): 214.7885, (RMSE): 0.0720\n",
      "regionc dfNGP Run 1/1, Epoch 1982/2000, Training Loss (NLML): 219.3630, (RMSE): 0.0716\n",
      "regionc dfNGP Run 1/1, Epoch 1983/2000, Training Loss (NLML): 218.5081, (RMSE): 0.0715\n",
      "regionc dfNGP Run 1/1, Epoch 1984/2000, Training Loss (NLML): 1352.9583, (RMSE): 0.0657\n",
      "regionc dfNGP Run 1/1, Epoch 1985/2000, Training Loss (NLML): 220.6298, (RMSE): 0.0711\n",
      "regionc dfNGP Run 1/1, Epoch 1986/2000, Training Loss (NLML): 4453.7041, (RMSE): 0.2960\n",
      "regionc dfNGP Run 1/1, Epoch 1987/2000, Training Loss (NLML): 466.8674, (RMSE): 0.0557\n",
      "regionc dfNGP Run 1/1, Epoch 1988/2000, Training Loss (NLML): 822.6872, (RMSE): 0.0445\n",
      "regionc dfNGP Run 1/1, Epoch 1989/2000, Training Loss (NLML): 1262.7578, (RMSE): 0.0338\n",
      "regionc dfNGP Run 1/1, Epoch 1990/2000, Training Loss (NLML): 1772.1145, (RMSE): 0.0265\n",
      "regionc dfNGP Run 1/1, Epoch 1991/2000, Training Loss (NLML): 2290.0581, (RMSE): 0.0176\n",
      "regionc dfNGP Run 1/1, Epoch 1992/2000, Training Loss (NLML): 2765.5771, (RMSE): 0.0563\n",
      "regionc dfNGP Run 1/1, Epoch 1993/2000, Training Loss (NLML): 3121.2102, (RMSE): 0.0169\n",
      "regionc dfNGP Run 1/1, Epoch 1994/2000, Training Loss (NLML): 3390.2161, (RMSE): 0.0013\n",
      "regionc dfNGP Run 1/1, Epoch 1995/2000, Training Loss (NLML): 3533.5979, (RMSE): 0.0004\n",
      "regionc dfNGP Run 1/1, Epoch 1996/2000, Training Loss (NLML): 3554.3181, (RMSE): 0.0003\n",
      "regionc dfNGP Run 1/1, Epoch 1997/2000, Training Loss (NLML): 3466.5803, (RMSE): 0.0004\n",
      "regionc dfNGP Run 1/1, Epoch 1998/2000, Training Loss (NLML): 3289.7847, (RMSE): 0.0012\n",
      "regionc dfNGP Run 1/1, Epoch 1999/2000, Training Loss (NLML): 3045.5376, (RMSE): 0.0026\n",
      "regionc dfNGP Run 1/1, Epoch 2000/2000, Training Loss (NLML): 2757.5710, (RMSE): 0.0113\n",
      "\n",
      "Results per run saved to results_byrd/dfNGP/regionc_dfNGP_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results_byrd/dfNGP/regionc_dfNGP_metrics_summary.csv\n",
      "Elapsed wall time: 132.4935 seconds\n",
      "Wall time saved to results_byrd/dfNGP/dfNGP_run_wall_time.txt.\n"
     ]
    }
   ],
   "source": [
    "# REAL DATA EXPERIMENTS\n",
    "#               _                 _   _      \n",
    "#              | |               | | (_)     \n",
    "#    __ _ _ __ | |_ __ _ _ __ ___| |_ _  ___ \n",
    "#   / _` | '_ \\| __/ _` | '__/ __| __| |/ __|\n",
    "#  | (_| | | | | || (_| | | | (__| |_| | (__ \n",
    "#   \\__,_|_| |_|\\__\\__,_|_|  \\___|\\__|_|\\___|\n",
    "# \n",
    "model_name = \"dfNGP\"\n",
    "\n",
    "# import configs to we can access the hypers with getattr\n",
    "import configs\n",
    "from configs import PATIENCE, MAX_NUM_EPOCHS, NUM_RUNS, WEIGHT_DECAY\n",
    "\n",
    "# Reiterating import for visibility\n",
    "MAX_NUM_EPOCHS = MAX_NUM_EPOCHS\n",
    "NUM_RUNS = NUM_RUNS\n",
    "WEIGHT_DECAY = WEIGHT_DECAY\n",
    "PATIENCE = PATIENCE\n",
    "\n",
    "# TODO: Delete overwrite, run full\n",
    "NUM_RUNS = 1\n",
    "\n",
    "# assign model-specific variable\n",
    "MODEL_LEARNING_RATE = getattr(configs, f\"{model_name}_REAL_LEARNING_RATE\")\n",
    "MODEL_LEARNING_RATE = 0.005\n",
    "MODEL_REAL_RESULTS_DIR = getattr(configs, f\"{model_name}_REAL_RESULTS_DIR\")\n",
    "import os\n",
    "os.makedirs(MODEL_REAL_RESULTS_DIR, exist_ok = True)\n",
    "\n",
    "# imports for probabilistic models\n",
    "if model_name in [\"GP\", \"dfGP\", \"dfNGP\"]:\n",
    "    from GP_models import GP_predict\n",
    "    from metrics import compute_NLL_sparse, compute_NLL_full\n",
    "    from configs import L_RANGE\n",
    "    if model_name in [\"dfGP\", \"dfNGP\"]:\n",
    "        from configs import SIGMA_F_RANGE\n",
    "    if model_name == \"GP\":\n",
    "        from configs import B_DIAGONAL_RANGE, B_OFFDIAGONAL_RANGE\n",
    "\n",
    "# for all models with NN components train on batches\n",
    "if model_name in [\"dfNGP\", \"dfNN\", \"PINN\"]:\n",
    "    from configs import BATCH_SIZE\n",
    "\n",
    "if model_name in [\"dfNGP\", \"dfNN\"]:\n",
    "    from NN_models import dfNN\n",
    "\n",
    "# universals \n",
    "from metrics import compute_RMSE, compute_MAE, compute_divergence_field\n",
    "\n",
    "# basics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# utilitarian\n",
    "from utils import set_seed\n",
    "# reproducibility\n",
    "set_seed(42)\n",
    "import gc\n",
    "\n",
    "# setting device to GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# overwrite if needed: # device = 'cpu'\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "### START TIMING ###\n",
    "import time\n",
    "start_time = time.time()  # Start timing after imports\n",
    "\n",
    "#############################\n",
    "### LOOP 1 - over REGIONS ###\n",
    "#############################\n",
    "\n",
    "# For region_name in [\"regiona\", \"regionb\", \"regionc\"]:\n",
    "for region_name in [\"regionc\"]:\n",
    "\n",
    "    print(f\"\\nTraining for {region_name.upper()}...\")\n",
    "\n",
    "    # Store metrics for the current region (used for metrics_summary report)\n",
    "    region_results = []\n",
    "\n",
    "    ##########################################\n",
    "    ### x_train & y_train, x_test & x_test ###\n",
    "    ##########################################\n",
    "\n",
    "    # define paths based on region_name\n",
    "    path_to_training_tensor = \"data/real_data/\" + region_name + \"_train_tensor.pt\"\n",
    "    path_to_test_tensor = \"data/real_data/\" + region_name + \"_test_tensor.pt\"\n",
    "\n",
    "    # load and tranpose to have rows as points\n",
    "    train = torch.load(path_to_training_tensor, weights_only = False).T \n",
    "    test = torch.load(path_to_test_tensor, weights_only = False).T\n",
    "\n",
    "    # The train and test tensors have the following columns:\n",
    "    # [:, 0] = x\n",
    "    # [:, 1] = y\n",
    "    # [:, 2] = surface elevation (s)\n",
    "    # [:, 3] = ice flux in x direction (u)\n",
    "    # [:, 4] = ice flux in y direction (v)\n",
    "    # [:, 5] = ice flux error in x direction (u_err)\n",
    "    # [:, 6] = ice flux error in y direction (v_err)\n",
    "\n",
    "    # train\n",
    "    x_train = train[:, [0, 1]].to(device)\n",
    "    y_train = train[:, [3, 4]].to(device)\n",
    "\n",
    "    # test\n",
    "    x_test = test[:, [0, 1]].to(device)\n",
    "    y_test = test[:, [3, 4]].to(device)\n",
    "\n",
    "    # local measurment errors as noise\n",
    "    train_noise_diag = torch.concat((train[:, 5], train[:, 6]), dim = 0).to(device)\n",
    "\n",
    "    # Print train details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Training inputs shape: {x_train.shape}\")\n",
    "    print(f\"Training observations shape: {y_train.shape}\")\n",
    "    print(f\"Training inputs dtype: {x_train.dtype}\")\n",
    "    print()\n",
    "\n",
    "    # Print test details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Test inputs shape: {x_test.shape}\")\n",
    "    print(f\"Test observations shape: {y_test.shape}\")\n",
    "    print(f\"Test inputs dtype: {x_test.dtype}\")\n",
    "    print()\n",
    "\n",
    "    ##################################\n",
    "    ### LOOP 2 - over training run ###\n",
    "    ##################################\n",
    "\n",
    "    # NOTE: GPs don't train on batches, use full data, even for dfNGP\n",
    "\n",
    "    for run in range(NUM_RUNS):\n",
    "\n",
    "        print(f\"\\n--- Training Run {run + 1}/{NUM_RUNS} ---\")\n",
    "\n",
    "        # NOTE: The dfNN mean function uses autograd and thus required x_train to be set to .requires_grad\n",
    "        x_train = x_train.to(device).requires_grad_(True)\n",
    "        # same for x_test for eval round\n",
    "        x_test = x_test.to(device).requires_grad_(True)\n",
    "\n",
    "        ### Initialise dfNGP hyperparameters ###\n",
    "        # 3 learnable HPs, same as dfGP\n",
    "        # NOTE: at every run this initialisation changes, introducing some randomness\n",
    "        # HACK: we need to use nn.Parameter for trainable hypers to avoid leaf variable error\n",
    "\n",
    "        # initialising (trainable) output scalar from a uniform distribution over a predefined range\n",
    "        sigma_f = nn.Parameter(torch.empty(1, device = device).uniform_( * SIGMA_F_RANGE))\n",
    "\n",
    "        # initialising (trainable) lengthscales from a uniform distribution over a predefined range\n",
    "        # each dimension has its own lengthscale\n",
    "        l = nn.Parameter(torch.empty(2, device = device).uniform_( * L_RANGE))\n",
    "\n",
    "        # For every run initialise a (new) mean model\n",
    "        dfNN_mean_model = dfNN().to(device)\n",
    "\n",
    "        # NOTE: We don't need a criterion either\n",
    "\n",
    "        # AdamW as optimizer for some regularisation/weight decay\n",
    "        optimizer = optim.AdamW(list(dfNN_mean_model.parameters()) + [sigma_f, l], lr = MODEL_LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "\n",
    "        # _________________\n",
    "        # BEFORE EPOCH LOOP\n",
    "        \n",
    "        # Export the convergence just for first run only\n",
    "        if run == 0:\n",
    "            # initialise tensors to store losses over epochs (for convergence plot)\n",
    "            train_losses_NLML_over_epochs = torch.zeros(MAX_NUM_EPOCHS) # objective\n",
    "            train_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS) # by-product\n",
    "            # monitor performance transfer to test (only RMSE easy to calc without covar)\n",
    "            test_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "\n",
    "            sigma_f_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "            l1_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "            l2_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "\n",
    "        # Early stopping variables\n",
    "        best_loss = float('inf')\n",
    "        # counter starts at 0\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        ############################\n",
    "        ### LOOP 3 - over EPOCHS ###\n",
    "        ############################\n",
    "        print(\"\\nStart Training\")\n",
    "\n",
    "        for epoch in range(MAX_NUM_EPOCHS):\n",
    "\n",
    "            # Assure model is in training mode\n",
    "            dfNN_mean_model.train()\n",
    "\n",
    "            # For Run 1 we save a bunch of metrics and update, while for the rest we only update\n",
    "            if run == 0:\n",
    "                mean_pred_train, _, lml_train = GP_predict(\n",
    "                        x_train,\n",
    "                        y_train,\n",
    "                        x_train, # predict training data\n",
    "                        [train_noise_diag, sigma_f, l], # list of (initial) hypers\n",
    "                        mean_func = dfNN_mean_model, # dfNN as mean function\n",
    "                        divergence_free_bool = True) # ensures we use a df kernel\n",
    "\n",
    "                # Compute test loss for loss convergence plot\n",
    "                mean_pred_test, _, _ = GP_predict(\n",
    "                        x_train,\n",
    "                        y_train,\n",
    "                        x_test.to(device), # have predictions for training data again\n",
    "                        # HACK: This is rather an eval, so we use detached hypers to avoid the computational tree\n",
    "                        [train_noise_diag, sigma_f.detach().clone(), l.detach().clone()], # list of (initial) hypers\n",
    "                        mean_func = dfNN_mean_model, # dfNN as mean function\n",
    "                        divergence_free_bool = True) # ensures we use a df kernel\n",
    "                \n",
    "                # UPDATE HYPERS (after test loss is computed to use same model)\n",
    "                optimizer.zero_grad() # don't accumulate gradients\n",
    "                # negative for NLML. loss is always on train\n",
    "                loss = - lml_train\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # NOTE: it is important to detach here \n",
    "                train_RMSE = compute_RMSE(y_train.detach(), mean_pred_train.detach())\n",
    "                test_RMSE = compute_RMSE(y_test.detach(), mean_pred_test.detach())\n",
    "\n",
    "                # Save losses for convergence plot\n",
    "                train_losses_NLML_over_epochs[epoch] = - lml_train\n",
    "                train_losses_RMSE_over_epochs[epoch] = train_RMSE\n",
    "                # NOTE: lml is always just given training data. There is no TEST NLML\n",
    "                test_losses_RMSE_over_epochs[epoch] = test_RMSE\n",
    "\n",
    "                # Save evolution of hyprs for convergence plot\n",
    "                sigma_f_over_epochs[epoch] = sigma_f[0]\n",
    "                l1_over_epochs[epoch] = l[0]\n",
    "                l2_over_epochs[epoch] = l[1]\n",
    "\n",
    "                print(f\"{region_name} {model_name} Run {run + 1}/{NUM_RUNS}, Epoch {epoch + 1}/{MAX_NUM_EPOCHS}, Training Loss (NLML): {loss:.4f}, (RMSE): {train_RMSE:.4f}\")\n",
    "\n",
    "                # delete after printing and saving\n",
    "                # NOTE: keep loss for early stopping check\n",
    "                del mean_pred_train, mean_pred_test, lml_train, train_RMSE, test_RMSE\n",
    "                \n",
    "                # Free up memory every 20 epochs\n",
    "                if epoch % 20 == 0:\n",
    "                    gc.collect() and torch.cuda.empty_cache()\n",
    "            \n",
    "             # For all runs after the first we run a minimal version using only lml_train\n",
    "            else:\n",
    "\n",
    "                # NOTE: We can use x_train[0:2] since the predictions doesn;t matter and we only care about lml_train\n",
    "                _, _, lml_train = GP_predict(\n",
    "                        x_train,\n",
    "                        y_train,\n",
    "                        x_train[0:2], # predictions don't matter and we output lml_train already\n",
    "                        [train_noise_diag, sigma_f, l], # list of (initial) hypers\n",
    "                        mean_func = dfNN_mean_model, # dfNN as mean function\n",
    "                        divergence_free_bool = True) # ensures we use a df kernel\n",
    "                \n",
    "                # UPDATE HYPERS (after test loss is computed to use same model)\n",
    "                optimizer.zero_grad() # don't accumulate gradients\n",
    "                # negative for NLML\n",
    "                loss = - lml_train\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # After run 1 we only print lml, nothing else\n",
    "                print(f\"{region_name} {model_name} Run {run + 1}/{NUM_RUNS}, Epoch {epoch + 1}/{MAX_NUM_EPOCHS}, Training Loss (NLML): {loss:.4f}\")\n",
    "\n",
    "                # NOTE: keep loss for early stopping check, del lml_train\n",
    "                del lml_train\n",
    "                \n",
    "                # Free up memory every 20 epochs\n",
    "                if epoch % 20 == 0:\n",
    "                    gc.collect() and torch.cuda.empty_cache()\n",
    "\n",
    "            # EVERY EPOCH: Early stopping check\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                # reset counter if loss improves\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                # exit epoch loop\n",
    "                break\n",
    "\n",
    "        ##############################\n",
    "        ### END LOOP 3 over EPOCHS ###\n",
    "        ##############################\n",
    "\n",
    "        # for every run...\n",
    "        #######################################################\n",
    "        ### EVALUATE after all training for RUN is finished ###\n",
    "        #######################################################\n",
    "\n",
    "        # Evaluate the trained model after all epochs are finished or early stopping was triggered\n",
    "        # NOTE: Detach tuned hyperparameters from the computational graph\n",
    "        best_sigma_f = sigma_f.detach().clone()\n",
    "        best_l = l.detach().clone()\n",
    "\n",
    "        # Need gradients for autograd divergence: We clone and detach\n",
    "        x_test_grad = x_test.to(device).clone().requires_grad_(True)\n",
    "\n",
    "        mean_pred_test, covar_pred_test, _ = GP_predict(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            x_test_grad,\n",
    "            [train_noise_diag, best_sigma_f, best_l], # list of (initial) hypers\n",
    "            mean_func = dfNN_mean_model, # dfNN as mean function\n",
    "            divergence_free_bool = True) # ensures we use a df kernel\n",
    "        \n",
    "        # Compute divergence field\n",
    "        dfGP_test_div_field = compute_divergence_field(mean_pred_test, x_test_grad)\n",
    "\n",
    "        # Only save mean_pred, covar_pred and divergence fields for the first run\n",
    "        if run == 0:\n",
    "\n",
    "            # (1) Save predictions from first run so we can visualise them later\n",
    "            torch.save(mean_pred_test, f\"{MODEL_REAL_RESULTS_DIR}/{region_name}_{model_name}_test_mean_predictions.pt\")\n",
    "            torch.save(covar_pred_test, f\"{MODEL_REAL_RESULTS_DIR}/{region_name}_{model_name}_test_covar_predictions.pt\")\n",
    "\n",
    "            # (2) Save best hyperparameters\n",
    "            # Stack tensors into a single tensor\n",
    "            best_hypers_tensor = torch.cat([\n",
    "                best_sigma_f,\n",
    "                best_l\n",
    "            ])\n",
    "\n",
    "            torch.save(best_hypers_tensor, f\"{MODEL_REAL_RESULTS_DIR}/{region_name}_{model_name}_best_hypers.pt\")\n",
    "\n",
    "            # (3) Since all epoch training is finished, we can save the losses over epochs\n",
    "            df_losses = pd.DataFrame({\n",
    "                'Epoch': list(range(train_losses_NLML_over_epochs.shape[0])), # pythonic indexing\n",
    "                'Train Loss NLML': train_losses_NLML_over_epochs.tolist(),\n",
    "                'Train Loss RMSE': train_losses_RMSE_over_epochs.tolist(),\n",
    "                'Test Loss RMSE': test_losses_RMSE_over_epochs.tolist(),\n",
    "                'Sigma_f': sigma_f_over_epochs.tolist(),\n",
    "                'l1': l1_over_epochs.tolist(),\n",
    "                'l2': l2_over_epochs.tolist()\n",
    "                })\n",
    "            \n",
    "            df_losses.to_csv(f\"{MODEL_REAL_RESULTS_DIR}/{region_name}_{model_name}_losses_over_epochs.csv\", index = False, float_format = \"%.5f\") # reduce to 5 decimals for readability\n",
    "\n",
    "            # (4) Save divergence field (computed above for all runs)\n",
    "            torch.save(dfGP_test_div_field, f\"{MODEL_REAL_RESULTS_DIR}/{region_name}_{model_name}_test_prediction_divergence_field.pt\")\n",
    "\n",
    "        x_train_grad = x_train.to(device).clone().requires_grad_(True)\n",
    "\n",
    "        mean_pred_train, covar_pred_train, _ = GP_predict(\n",
    "                     x_train,\n",
    "                     y_train,\n",
    "                     x_train_grad,\n",
    "                     [train_noise_diag, best_sigma_f, best_l], # list of (initial) hypers\n",
    "                     mean_func = dfNN_mean_model, # dfNN as mean function\n",
    "                     divergence_free_bool = True) # ensures we use a df kernel\n",
    "        \n",
    "        dfGP_train_div_field = compute_divergence_field(mean_pred_train, x_train_grad)\n",
    "\n",
    "        # Divergence: Convert field to metric: mean absolute divergence\n",
    "        # NOTE: It is important to use the absolute value of the divergence field, since positive and negative deviations are violations and shouldn't cancel each other out \n",
    "        dfGP_train_div = dfGP_train_div_field.abs().mean().item()\n",
    "        dfGP_test_div = dfGP_test_div_field.abs().mean().item()\n",
    "\n",
    "        # Compute metrics (convert tensors to float) for every run's tuned model\n",
    "        dfGP_train_RMSE = compute_RMSE(y_train, mean_pred_train).item()\n",
    "        dfGP_train_MAE = compute_MAE(y_train, mean_pred_train).item()\n",
    "        dfGP_train_NLL = compute_NLL_full(y_train, mean_pred_train, covar_pred_train).item()\n",
    "\n",
    "        dfGP_test_RMSE = compute_RMSE(y_test, mean_pred_test).item()\n",
    "        dfGP_test_MAE = compute_MAE(y_test, mean_pred_test).item()\n",
    "        # TODO: full NLL\n",
    "        dfGP_test_NLL = compute_NLL_full(y_test, mean_pred_test, covar_pred_test).item()\n",
    "\n",
    "        region_results.append([\n",
    "            run + 1,\n",
    "            dfGP_train_RMSE, dfGP_train_MAE, dfGP_train_NLL, dfGP_train_div,\n",
    "            dfGP_test_RMSE, dfGP_test_MAE, dfGP_test_NLL, dfGP_test_div\n",
    "        ])\n",
    "\n",
    "        # clean up\n",
    "        del mean_pred_train, mean_pred_test, covar_pred_train, covar_pred_test\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    ############################\n",
    "    ### END LOOP 2 over RUNS ###\n",
    "    ############################\n",
    "\n",
    "    # Convert results to a Pandas DataFrame\n",
    "    results_per_run = pd.DataFrame(\n",
    "        region_results, \n",
    "        columns = [\"Run\", \n",
    "                   \"Train RMSE\", \"Train MAE\", \"Train NLL\", \"Train MAD\",\n",
    "                   \"Test RMSE\", \"Test MAE\", \"Test NLL\", \"Test MAD\"])\n",
    "\n",
    "    # Compute mean and standard deviation for each metric\n",
    "    mean_std_df = results_per_run.iloc[:, 1:].agg([\"mean\", \"std\"]) # Exclude \"Run\" column\n",
    "\n",
    "    # Add region_name and model_name as columns in the DataFrame _metrics_summary to be able to copy df\n",
    "    mean_std_df[\"region name\"] = region_name\n",
    "    mean_std_df[\"model name\"] = model_name\n",
    "\n",
    "    # Save \"_metrics_per_run.csv\" to CSV\n",
    "    path_to_metrics_per_run = os.path.join(MODEL_REAL_RESULTS_DIR, f\"{region_name}_{model_name}_metrics_per_run.csv\")\n",
    "    results_per_run.to_csv(path_to_metrics_per_run, index = False, float_format = \"%.5f\") # reduce to 5 decimals\n",
    "    print(f\"\\nResults per run saved to {path_to_metrics_per_run}\")\n",
    "\n",
    "    # Save \"_metrics_summary.csv\" to CSV\n",
    "    path_to_metrics_summary = os.path.join(MODEL_REAL_RESULTS_DIR, f\"{region_name}_{model_name}_metrics_summary.csv\")\n",
    "    mean_std_df.to_csv(path_to_metrics_summary, float_format = \"%.5f\") # reduce to 5 decimals\n",
    "    print(f\"\\nMean & Std saved to {path_to_metrics_summary}\")\n",
    "\n",
    "###############################\n",
    "### END LOOP 1 over REGIONS ###\n",
    "###############################\n",
    "\n",
    "#############################\n",
    "### WALL time & GPU model ###\n",
    "#############################\n",
    "\n",
    "end_time = time.time()\n",
    "# compute elapsed time\n",
    "elapsed_time = end_time - start_time \n",
    "# convert elapsed time to minutes\n",
    "elapsed_time_minutes = elapsed_time / 60\n",
    "\n",
    "if device == \"cuda\":\n",
    "    # get name of GPU model\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "else:\n",
    "    gpu_name = \"N/A\"\n",
    "\n",
    "print(f\"Elapsed wall time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "# Define full path for the file\n",
    "wall_time_and_gpu_path = os.path.join(MODEL_REAL_RESULTS_DIR, model_name + \"_run_\" \"wall_time.txt\")\n",
    "\n",
    "# Save to the correct folder with both seconds and minutes\n",
    "with open(wall_time_and_gpu_path, \"w\") as f:\n",
    "    f.write(f\"Elapsed wall time: {elapsed_time:.4f} seconds\\n\")\n",
    "    f.write(f\"Elapsed wall time: {elapsed_time_minutes:.2f} minutes\\n\")\n",
    "    f.write(f\"Device used: {device}\\n\")\n",
    "    f.write(f\"GPU model: {gpu_name}\\n\")\n",
    "\n",
    "print(f\"Wall time saved to {wall_time_and_gpu_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def41f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NLL_full(y_true, y_mean_pred, y_covar_pred, jitter = 0.5 * 1e-2):\n",
    "    \"\"\"Computes Negative Log-Likelihood (NLL) using the full covariance matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): True observations of shape (N, 2).\n",
    "        y_mean_pred (torch.Tensor): Mean predictions of shape (N, 2).\n",
    "        y_covar_pred (torch.Tensor): Full predicted covariance matrix of shape (N*2, N*2).(BLOCK FORMAT) [u1, u2, u3, ..., v1, v2, v3, ...]\n",
    "        jitter (float, optional): Small value added to the diagonal for numerical stability. Defaults to 0.5 * 1e-2 - quite high but we need to keep it consistent across all models.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor(): Negative Log-Likelihood (NLL) scalar.\n",
    "    \"\"\"\n",
    "    # Extract number of points\n",
    "    N = y_true.shape[0]\n",
    "    \n",
    "    # STEP 1: Compute Mahalanobis distance efficiently\n",
    "\n",
    "    # NOTE: Flatten y_true and y_mean_pred & match covariance matrix shape (BLOCK structure)\n",
    "    y_true_flat = torch.concat([y_true[:, 0], y_true[:, 1]], dim = 0).unsqueeze(-1)  # Shape: (2 * N, 1)\n",
    "    y_mean_pred_flat = torch.concat([y_mean_pred[:, 0], y_mean_pred[:, 1]], dim = 0).unsqueeze(-1)  # Shape: (2 * N, 1)\n",
    "\n",
    "    # Compute the difference between the true and predicted values (y - μ)\n",
    "    # NOTE: order is (true - pred) to match the Mahalanobis distance formula\n",
    "    diff = y_true_flat - y_mean_pred_flat   # Shape: (2 * N, 1)\n",
    "\n",
    "    # STEP 2: Stabilize covariance matrix with fixed jitter to ensure torch.linalg.cholesky() works\n",
    "    # NOTE: as this is our key metric it is better to add the same jitter to all elements. Thus rather than a loop, we add a fixed small value to the diagonal\n",
    "    y_covar_pred_stable = y_covar_pred + torch.eye(y_covar_pred.shape[0], device = y_covar_pred.device) * jitter\n",
    "    \n",
    "    # Solve Σ⁻¹ using Cholesky decomposition to get lower-triangular matrix L for LL^T = Σ\n",
    "    chol = torch.linalg.cholesky(y_covar_pred_stable) # Shape: (2 * N, 2 * N)\n",
    "\n",
    "    # Solve (y - μ)T Σ⁻¹ (y - μ) using Cholesky decomposition for better stability\n",
    "    mahalanobis_dist = (torch.cholesky_solve(diff, chol).T @ diff).squeeze() # Shape: (1,)\n",
    "\n",
    "    # STEP 3: Compute log-determinant robustly\n",
    "    # HACK: avoids underflow/overflow\n",
    "    sign, log_det_Sigma = torch.linalg.slogdet(y_covar_pred_stable) # sign = 1 or -1, log_det_Sigma = log determinant (scalar)\n",
    "    \n",
    "    # If the determinant is non-positive, return a large NLL to indicate instability\n",
    "    if sign <= 0:\n",
    "        print(\"Warning: Non-positive determinant encountered. Returning large NLL.\")\n",
    "        return torch.tensor(float(\"inf\"), device = y_true.device)\n",
    "    \n",
    "    # STEP 4: Compute normalisation term\n",
    "    d = N * 2  # Dimensionality (since we have two outputs per point)\n",
    "    normalisation_term = d * torch.log(torch.tensor(2 * torch.pi, device = y_true.device))\n",
    "\n",
    "    # Step 5: Combine 3 scalar terms into negative log-likelihood (NLL)\n",
    "    log_likelihood = - 0.5 * (mahalanobis_dist + log_det_Sigma + normalisation_term)\n",
    "\n",
    "    return - log_likelihood  # Negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c98358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NLL_sparse(y_true, y_mean_pred, y_covar_pred):\n",
    "    \"\"\" Computes a sparse version of the Negative Log-Likelihood (NLL) for a 2D Gaussian distribution. This sparse version neglects cross-covariance terms and is more efficient for large datasets.\n",
    "    \n",
    "    NLL: The NLL quantifies how well the predicted Gaussian distribution fits the observed data.\n",
    "    Sparse format: each of the N points has its own 2×2 covariance matrix. (This is more than just the diagonal of the covariance matrix, but not the full covar.)\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): True observations of shape (N, 2).\n",
    "        y_mean_pred (torch.Tensor): Mean predictions of shape (N, 2).\n",
    "        y_covar_pred (torch.Tensor): Full predicted covariance matrix of shape (N * 2, N * 2).(BLOCK FORMAT) [u1, u2, u3, ..., v1, v2, v3, ...]\n",
    "            If N = 400, then y_covar_pred is torch.Size([800, 800]) so 640000 elements N x 2 x 2 = only 1600 elements.\n",
    "        jitter (float, optional): Small value added to the diagonal for numerical stability. Defaults to 0.5 * 1e-2 - quite high but we need to keep it consistent across all models.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor(): Negative Log-Likelihood (NLL) scalar.\n",
    "    \"\"\"\n",
    "    # Extract number of points\n",
    "    N = y_true.shape[0]\n",
    "\n",
    "    # Step 1: Sparsify the covariance matrix\n",
    "    # Change format of y_covar_pred from (N x 2, N x 2) to (N, 2, 2) so N (2, 2) matrices.\n",
    "    # NOTE: This is a sparse version of the covariance matrix, neglecting cross-covariance terms.\n",
    "\n",
    "    # extract diagonal of upper left quadrant: variance of the first output (y1) at each point.\n",
    "    var_y1_y1 = torch.diag(y_covar_pred[:N, :N])\n",
    "    # extract diagonal of ulower right quadrant: variance of the second output (y2) at each point\n",
    "    var_y2_y2 = torch.diag(y_covar_pred[N:, N:])\n",
    "\n",
    "    # extract diagonal of upper right quadrant: How much do y1 and y2 covary at this point\n",
    "    covar_y1_y2 = torch.diag(y_covar_pred[:N, N:])\n",
    "    # extract diagonal of lower left quadrant\n",
    "    covar_y2_y1 = torch.diag(y_covar_pred[N:, :N])\n",
    "\n",
    "    col1 = torch.cat([var_y1_y1.unsqueeze(-1), covar_y1_y2.unsqueeze(-1)], dim = -1)\n",
    "    col2 = torch.cat([covar_y2_y1.unsqueeze(-1), var_y2_y2.unsqueeze(-1)], dim = -1)\n",
    "\n",
    "    # At each point N, what is the predicted variance of y1 and y2 and \n",
    "    # what is the predicted covariance between y1 and y2? (symmetric)\n",
    "    covar_N22 = torch.cat([col1.unsqueeze(-1), col2.unsqueeze(-1)], dim = -1) # shape: torch.Size([N, 2, 2])\n",
    "\n",
    "\n",
    "    # STEP 2: Compute Mahalanobis distance efficiently\n",
    "    # Compute the difference between the true and predicted values (y - μ)\n",
    "    # NOTE: order is (true - pred) to match the Mahalanobis distance formula\n",
    "    # NOTE: we can also keep this shape\n",
    "    diff = y_true - y_mean_pred   # Shape: (N, 2)\n",
    "    \n",
    "    # Reshape diff to (N, 2, 1) to do matrix multiplication with (N, 2, 2)\n",
    "    diff = diff.unsqueeze(-1)  # shape: (N, 2, 1)\n",
    "\n",
    "    sigma_inverse = torch.inverse(covar_N22) # shape: torch.Size([N, 2, 2])\n",
    "\n",
    "    # Compute (Σ⁻¹ @ diff) → shape: (N, 2, 1)\n",
    "    maha_component = torch.matmul(sigma_inverse, diff)\n",
    "\n",
    "    # Compute (diff^T @ Σ⁻¹ @ diff) for each point → shape: (N, 1, 1)\n",
    "    # transpose diff to (N, 1, 2) for matrix multiplication\n",
    "    mahalanobis_distances = torch.matmul(diff.transpose(1, 2), maha_component)\n",
    "\n",
    "    # Sum (N, ) distances to get a single value\n",
    "    mahalanobis_distances = mahalanobis_distances.squeeze().sum()\n",
    "\n",
    "\n",
    "    # STEP 3: Log determinant of the covariance matrix\n",
    "\n",
    "    # element-wise determinant of all 2x2 matrices: sum\n",
    "    sign, log_absdet = torch.slogdet(covar_N22)\n",
    "    if not torch.all(sign > 0):\n",
    "        print(\"Warning: Non-positive definite matrix encountered.\")\n",
    "        return torch.tensor(float(\"inf\"), device = covar_N22.device)\n",
    "    log_det_Sigma = log_absdet.sum()\n",
    "\n",
    "\n",
    "    # STEP 4: Compute normalisation term\n",
    "    d = N * 2  # Dimensionality (since we have two outputs per point)\n",
    "    normalisation_term = d * torch.log(torch.tensor(2 * torch.pi, device = y_true.device))\n",
    "\n",
    "    # Step 5: Combine 3 scalars into negative log-likelihood (NLL)\n",
    "    # Gaussian log-likelihood formula: 2D\n",
    "    # NOTE: Gaussian log-likelihood 2D formula\n",
    "    log_likelihood =  - 0.5 * (mahalanobis_distances + log_det_Sigma + normalisation_term)\n",
    "\n",
    "    # return the negative log-likelihood\n",
    "    return - log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_NLL_full(y_train, mean_pred_train, covar_pred_train).item())\n",
    "print(compute_NLL_sparse(y_train, mean_pred_train, covar_pred_train).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_NLL_full(y_test, mean_pred_test, covar_pred_test).item())\n",
    "print(compute_NLL_sparse(y_test, mean_pred_test, covar_pred_test).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
