{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e82309",
   "metadata": {},
   "source": [
    "# Debug on curve simulated\n",
    "\n",
    "- 2 output dimensions (full matrix model)\n",
    "- would probably profit from a val set, but for GPs we don't use this\n",
    "\n",
    "Tried & didn't work:\n",
    "- Larger network did not help\n",
    "- H no sum() is invalid\n",
    "- dropout at 0.1 or 0.3\n",
    "- gelu\n",
    "- higher batch size\n",
    "\n",
    "Worked:\n",
    "- silu! is also better than geLU\n",
    "- Larger learning rate! Otherwise it gets stuck!\n",
    "- lower patience and larger weight decay help too\n",
    "- Model can \"fit\" test data so works\n",
    "- In 2D every divergence free vector field is symplectic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch\n",
    "\n",
    "class dfNN(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = 1  # Scalar potential\n",
    "\n",
    "        # HACK: SiLu() worked much better than ReLU() for this model\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Turn x1, x2 locations into vector fields\n",
    "        x: [batch_size, input_dim]\n",
    "        Returns: [batch_size, input_dim]  # Symplectic gradient\n",
    "        \"\"\"\n",
    "        # Retrieve scalar potential\n",
    "        H = self.net(x)\n",
    "\n",
    "        partials = torch.autograd.grad(\n",
    "                outputs = H.sum(), # we can sum here because every H row only depend on every x row\n",
    "                inputs = x,\n",
    "                create_graph = True\n",
    "            )[0]\n",
    "        \n",
    "        # Symplectic gradient\n",
    "        # flip columns (last dim) for x2, x1 order. Multiply x2 by -1\n",
    "        symp = partials.flip(-1) * torch.tensor([1, -1], dtype = torch.float32, device = x.device)\n",
    "\n",
    "        # return symp, H # NOTE: return H as well if we want to see what is going on\n",
    "        return symp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "105a486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dfNN_matrix(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # NOTE: different\n",
    "        # for 2D input the NN output dim is now 4 (2x2) in the full matrix case\n",
    "        self.output_dim = int((input_dim * input_dim))\n",
    "\n",
    "        # HACK: SiLu() worked much better than ReLU() for this model\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # put deterministic transformations here with torch functional\n",
    "        # more computation but performs better!?\n",
    "\n",
    "        def A(x):\n",
    "\n",
    "            # RUN THROUGH NET\n",
    "            M = self.net(x)\n",
    "\n",
    "            # make square\n",
    "            M = M.view(self.input_dim, self.input_dim)\n",
    "\n",
    "            # construct an Anti-symmetric matrix from the output of the NN\n",
    "            # the diagonal of the matrix M is irrelevant technically\n",
    "            A = M - M.mT\n",
    "\n",
    "            return A\n",
    "        \n",
    "        # torch.diagonal(jacfwd(A)(x), dim1 = 1, dim2 = 2).sum(-1)\n",
    "\n",
    "        return jacfwd(A)(x), torch.diagonal(jacfwd(A)(x), dim1 = 1, dim2 = 2), torch.diagonal(jacfwd(A)(x), dim1 = 1, dim2 = 2).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a0b8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class dfNN_matrix(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = input_dim * input_dim  # flattened 2x2 matrix\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x.requires_grad_(True)\n",
    "\n",
    "        M = self.net(x).view(-1, 2, 2)\n",
    "        # Make antisymmetric matrix\n",
    "        A = M - M.transpose(1, 2)\n",
    "\n",
    "        # picks u\n",
    "        u = A[:, 0, 1]  # since A = [[0, u], [-u, 0]]\n",
    "\n",
    "        du_dx = torch.autograd.grad(u.sum(), x, create_graph = True)[0]  # [B, 2]\n",
    "        print(du_dx)\n",
    "\n",
    "        symplectic = du_dx.flip(-1) * torch.tensor([1.0, -1.0], device = x.device)\n",
    "\n",
    "        return symplectic  # or return du_dx.sum(dim=1) for divergence-style scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3594e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class dfNN_matrix(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = input_dim * input_dim  # flattened 2x2 matrix\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [batch_size, input_dim]\n",
    "        Returns: batch of scalar values representing trace of Jacobian of anti-symmetric A(x)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        x.requires_grad_(True)\n",
    "\n",
    "        # Pass input through network and reshape output to matrix\n",
    "        M = self.net(x)  # [batch_size, output_dim]\n",
    "        M = M.view(batch_size, self.input_dim, self.input_dim)  # [B, 2, 2]\n",
    "\n",
    "        # Construct anti-symmetric matrix A = M - M^T\n",
    "        A = M - M.transpose(1, 2)  # [B, 2, 2]\n",
    "        # NOTE: A's first row is [0, U] and second row is [U, 0]\n",
    "\n",
    "        print(A)\n",
    "\n",
    "        # Compute Jacobian of A with respect to input x\n",
    "        # Result: [B, input_dim, input_dim, input_dim]\n",
    "        J = []\n",
    "        for i in range(self.input_dim):\n",
    "\n",
    "            grad_outputs = torch.zeros_like(A)\n",
    "            # Select row (has only one non-zero element)\n",
    "            grad_outputs[:, i, :] = 1.0  # dA[i, :] / dx\n",
    "\n",
    "            grad = torch.autograd.grad(\n",
    "                outputs = A,\n",
    "                inputs = x,\n",
    "                grad_outputs = grad_outputs,\n",
    "                create_graph = True,\n",
    "            )[0]\n",
    "            print(grad)\n",
    "            J.append(grad)\n",
    "\n",
    "        # Append row-wise\n",
    "        # Stack to get full Jacobian: shape [B, output_dim (rows*cols), input_dim]\n",
    "        J = torch.stack(J, dim = 1)  # [B, input_dim, input_dim]\n",
    "\n",
    "        print(J)\n",
    "        \n",
    "        # Return trace of the diagonal Jacobian blocks: sum of dA_ii/dx_i\n",
    "        trace = torch.diagonal(J, dim1 = 1, dim2 = 2)  # [B]\n",
    "        print(trace)\n",
    "\n",
    "        return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0163740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed, make_grid\n",
    "from configs import N_SIDE\n",
    "_, x_test = make_grid(N_SIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "154d41fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dfNN_matrix_model = dfNN_matrix()\n",
    "dfNN_matrix_model.train()\n",
    "\n",
    "x_test = x_test.requires_grad_()\n",
    "# A, B, C = dfNN_matrix_model(x_test[0])\n",
    "C = dfNN_matrix_model(x_test[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b2b6d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -0.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cee2d3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jacfwd\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mdiagonal(\u001b[43mjacfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m, dim1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, dim2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1310\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     _, jvp_out \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[0;32m-> 1310\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpush_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1312\u001b[0m     results, aux \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/apis.py:203\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:331\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[1;32m    321\u001b[0m         func,\n\u001b[1;32m    322\u001b[0m         flat_in_dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:479\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    476\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    477\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[1;32m    478\u001b[0m     )\n\u001b[0;32m--> 479\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1299\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn.<locals>.push_jvp\u001b[0;34m(basis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush_jvp\u001b[39m(basis):\n\u001b[0;32m-> 1299\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;66;03m# output[0] is the output of `func(*args)`\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;241m0\u001b[39m], is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1139\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m   1138\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m-> 1139\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "from torch.func import jacfwd\n",
    "\n",
    "torch.diagonal(jacfwd(A)(x_test), dim1 = 1, dim2 = 2).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e19435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== CURVE ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "Training inputs device: cuda:0\n",
      "Training observations device: cuda:0\n",
      "\n",
      "=== CURVE ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "Test inputs device: cuda:0\n",
      "Test observations device: cuda:0\n",
      "\n",
      "\n",
      "--- Training Run 1/1 ---\n",
      "\n",
      "Start Training\n",
      "curve dfNN Run 1/1, Epoch 1/4000, Training Loss (RMSE): 0.7634\n",
      "curve dfNN Run 1/1, Epoch 2/4000, Training Loss (RMSE): 0.4332\n",
      "curve dfNN Run 1/1, Epoch 3/4000, Training Loss (RMSE): 0.3683\n",
      "curve dfNN Run 1/1, Epoch 4/4000, Training Loss (RMSE): 0.3086\n",
      "curve dfNN Run 1/1, Epoch 5/4000, Training Loss (RMSE): 0.2671\n",
      "curve dfNN Run 1/1, Epoch 6/4000, Training Loss (RMSE): 0.2995\n",
      "curve dfNN Run 1/1, Epoch 7/4000, Training Loss (RMSE): 0.2747\n",
      "curve dfNN Run 1/1, Epoch 8/4000, Training Loss (RMSE): 0.2826\n",
      "curve dfNN Run 1/1, Epoch 9/4000, Training Loss (RMSE): 0.2655\n",
      "curve dfNN Run 1/1, Epoch 10/4000, Training Loss (RMSE): 0.2679\n",
      "curve dfNN Run 1/1, Epoch 11/4000, Training Loss (RMSE): 0.2768\n",
      "curve dfNN Run 1/1, Epoch 12/4000, Training Loss (RMSE): 0.2520\n",
      "curve dfNN Run 1/1, Epoch 13/4000, Training Loss (RMSE): 0.2443\n",
      "curve dfNN Run 1/1, Epoch 14/4000, Training Loss (RMSE): 0.2497\n",
      "curve dfNN Run 1/1, Epoch 15/4000, Training Loss (RMSE): 0.2591\n",
      "curve dfNN Run 1/1, Epoch 16/4000, Training Loss (RMSE): 0.2688\n",
      "curve dfNN Run 1/1, Epoch 17/4000, Training Loss (RMSE): 0.2629\n",
      "curve dfNN Run 1/1, Epoch 18/4000, Training Loss (RMSE): 0.2452\n",
      "curve dfNN Run 1/1, Epoch 19/4000, Training Loss (RMSE): 0.2475\n",
      "curve dfNN Run 1/1, Epoch 20/4000, Training Loss (RMSE): 0.2490\n",
      "curve dfNN Run 1/1, Epoch 21/4000, Training Loss (RMSE): 0.2401\n",
      "curve dfNN Run 1/1, Epoch 22/4000, Training Loss (RMSE): 0.2472\n",
      "curve dfNN Run 1/1, Epoch 23/4000, Training Loss (RMSE): 0.2441\n",
      "curve dfNN Run 1/1, Epoch 24/4000, Training Loss (RMSE): 0.2439\n",
      "curve dfNN Run 1/1, Epoch 25/4000, Training Loss (RMSE): 0.2461\n",
      "curve dfNN Run 1/1, Epoch 26/4000, Training Loss (RMSE): 0.2520\n",
      "curve dfNN Run 1/1, Epoch 27/4000, Training Loss (RMSE): 0.2530\n",
      "curve dfNN Run 1/1, Epoch 28/4000, Training Loss (RMSE): 0.2387\n",
      "curve dfNN Run 1/1, Epoch 29/4000, Training Loss (RMSE): 0.2329\n",
      "curve dfNN Run 1/1, Epoch 30/4000, Training Loss (RMSE): 0.2382\n",
      "curve dfNN Run 1/1, Epoch 31/4000, Training Loss (RMSE): 0.2337\n",
      "curve dfNN Run 1/1, Epoch 32/4000, Training Loss (RMSE): 0.2565\n",
      "curve dfNN Run 1/1, Epoch 33/4000, Training Loss (RMSE): 0.2469\n",
      "curve dfNN Run 1/1, Epoch 34/4000, Training Loss (RMSE): 0.2207\n",
      "curve dfNN Run 1/1, Epoch 35/4000, Training Loss (RMSE): 0.2258\n",
      "curve dfNN Run 1/1, Epoch 36/4000, Training Loss (RMSE): 0.2346\n",
      "curve dfNN Run 1/1, Epoch 37/4000, Training Loss (RMSE): 0.2378\n",
      "curve dfNN Run 1/1, Epoch 38/4000, Training Loss (RMSE): 0.2229\n",
      "curve dfNN Run 1/1, Epoch 39/4000, Training Loss (RMSE): 0.2391\n",
      "curve dfNN Run 1/1, Epoch 40/4000, Training Loss (RMSE): 0.2425\n",
      "curve dfNN Run 1/1, Epoch 41/4000, Training Loss (RMSE): 0.2385\n",
      "curve dfNN Run 1/1, Epoch 42/4000, Training Loss (RMSE): 0.2460\n",
      "curve dfNN Run 1/1, Epoch 43/4000, Training Loss (RMSE): 0.2430\n",
      "curve dfNN Run 1/1, Epoch 44/4000, Training Loss (RMSE): 0.2343\n",
      "curve dfNN Run 1/1, Epoch 45/4000, Training Loss (RMSE): 0.2415\n",
      "curve dfNN Run 1/1, Epoch 46/4000, Training Loss (RMSE): 0.2297\n",
      "curve dfNN Run 1/1, Epoch 47/4000, Training Loss (RMSE): 0.2507\n",
      "curve dfNN Run 1/1, Epoch 48/4000, Training Loss (RMSE): 0.2267\n",
      "curve dfNN Run 1/1, Epoch 49/4000, Training Loss (RMSE): 0.2365\n",
      "curve dfNN Run 1/1, Epoch 50/4000, Training Loss (RMSE): 0.2198\n",
      "curve dfNN Run 1/1, Epoch 51/4000, Training Loss (RMSE): 0.2327\n",
      "curve dfNN Run 1/1, Epoch 52/4000, Training Loss (RMSE): 0.2338\n",
      "curve dfNN Run 1/1, Epoch 53/4000, Training Loss (RMSE): 0.2254\n",
      "curve dfNN Run 1/1, Epoch 54/4000, Training Loss (RMSE): 0.2185\n",
      "curve dfNN Run 1/1, Epoch 55/4000, Training Loss (RMSE): 0.2338\n",
      "curve dfNN Run 1/1, Epoch 56/4000, Training Loss (RMSE): 0.2357\n",
      "curve dfNN Run 1/1, Epoch 57/4000, Training Loss (RMSE): 0.2438\n",
      "curve dfNN Run 1/1, Epoch 58/4000, Training Loss (RMSE): 0.2219\n",
      "curve dfNN Run 1/1, Epoch 59/4000, Training Loss (RMSE): 0.2267\n",
      "curve dfNN Run 1/1, Epoch 60/4000, Training Loss (RMSE): 0.2157\n",
      "curve dfNN Run 1/1, Epoch 61/4000, Training Loss (RMSE): 0.2240\n",
      "curve dfNN Run 1/1, Epoch 62/4000, Training Loss (RMSE): 0.2333\n",
      "curve dfNN Run 1/1, Epoch 63/4000, Training Loss (RMSE): 0.2144\n",
      "curve dfNN Run 1/1, Epoch 64/4000, Training Loss (RMSE): 0.2195\n",
      "curve dfNN Run 1/1, Epoch 65/4000, Training Loss (RMSE): 0.2197\n",
      "curve dfNN Run 1/1, Epoch 66/4000, Training Loss (RMSE): 0.2205\n",
      "curve dfNN Run 1/1, Epoch 67/4000, Training Loss (RMSE): 0.2212\n",
      "curve dfNN Run 1/1, Epoch 68/4000, Training Loss (RMSE): 0.2207\n",
      "curve dfNN Run 1/1, Epoch 69/4000, Training Loss (RMSE): 0.2269\n",
      "curve dfNN Run 1/1, Epoch 70/4000, Training Loss (RMSE): 0.2266\n",
      "curve dfNN Run 1/1, Epoch 71/4000, Training Loss (RMSE): 0.2171\n",
      "curve dfNN Run 1/1, Epoch 72/4000, Training Loss (RMSE): 0.2068\n",
      "curve dfNN Run 1/1, Epoch 73/4000, Training Loss (RMSE): 0.2086\n",
      "curve dfNN Run 1/1, Epoch 74/4000, Training Loss (RMSE): 0.2214\n",
      "curve dfNN Run 1/1, Epoch 75/4000, Training Loss (RMSE): 0.2093\n",
      "curve dfNN Run 1/1, Epoch 76/4000, Training Loss (RMSE): 0.2225\n",
      "curve dfNN Run 1/1, Epoch 77/4000, Training Loss (RMSE): 0.2265\n",
      "curve dfNN Run 1/1, Epoch 78/4000, Training Loss (RMSE): 0.2333\n",
      "curve dfNN Run 1/1, Epoch 79/4000, Training Loss (RMSE): 0.2199\n",
      "curve dfNN Run 1/1, Epoch 80/4000, Training Loss (RMSE): 0.2221\n",
      "curve dfNN Run 1/1, Epoch 81/4000, Training Loss (RMSE): 0.2364\n",
      "curve dfNN Run 1/1, Epoch 82/4000, Training Loss (RMSE): 0.2113\n",
      "curve dfNN Run 1/1, Epoch 83/4000, Training Loss (RMSE): 0.2092\n",
      "curve dfNN Run 1/1, Epoch 84/4000, Training Loss (RMSE): 0.2174\n",
      "curve dfNN Run 1/1, Epoch 85/4000, Training Loss (RMSE): 0.2078\n",
      "curve dfNN Run 1/1, Epoch 86/4000, Training Loss (RMSE): 0.2032\n",
      "curve dfNN Run 1/1, Epoch 87/4000, Training Loss (RMSE): 0.2059\n",
      "curve dfNN Run 1/1, Epoch 88/4000, Training Loss (RMSE): 0.2111\n",
      "curve dfNN Run 1/1, Epoch 89/4000, Training Loss (RMSE): 0.2124\n",
      "curve dfNN Run 1/1, Epoch 90/4000, Training Loss (RMSE): 0.2204\n",
      "curve dfNN Run 1/1, Epoch 91/4000, Training Loss (RMSE): 0.2134\n",
      "curve dfNN Run 1/1, Epoch 92/4000, Training Loss (RMSE): 0.2051\n",
      "curve dfNN Run 1/1, Epoch 93/4000, Training Loss (RMSE): 0.2185\n",
      "curve dfNN Run 1/1, Epoch 94/4000, Training Loss (RMSE): 0.1990\n",
      "curve dfNN Run 1/1, Epoch 95/4000, Training Loss (RMSE): 0.2086\n",
      "curve dfNN Run 1/1, Epoch 96/4000, Training Loss (RMSE): 0.2079\n",
      "curve dfNN Run 1/1, Epoch 97/4000, Training Loss (RMSE): 0.2154\n",
      "curve dfNN Run 1/1, Epoch 98/4000, Training Loss (RMSE): 0.2278\n",
      "curve dfNN Run 1/1, Epoch 99/4000, Training Loss (RMSE): 0.2063\n",
      "curve dfNN Run 1/1, Epoch 100/4000, Training Loss (RMSE): 0.2085\n",
      "curve dfNN Run 1/1, Epoch 101/4000, Training Loss (RMSE): 0.2052\n",
      "curve dfNN Run 1/1, Epoch 102/4000, Training Loss (RMSE): 0.2063\n",
      "curve dfNN Run 1/1, Epoch 103/4000, Training Loss (RMSE): 0.2194\n",
      "curve dfNN Run 1/1, Epoch 104/4000, Training Loss (RMSE): 0.2141\n",
      "curve dfNN Run 1/1, Epoch 105/4000, Training Loss (RMSE): 0.2119\n",
      "curve dfNN Run 1/1, Epoch 106/4000, Training Loss (RMSE): 0.2246\n",
      "curve dfNN Run 1/1, Epoch 107/4000, Training Loss (RMSE): 0.2170\n",
      "curve dfNN Run 1/1, Epoch 108/4000, Training Loss (RMSE): 0.2139\n",
      "curve dfNN Run 1/1, Epoch 109/4000, Training Loss (RMSE): 0.2094\n",
      "curve dfNN Run 1/1, Epoch 110/4000, Training Loss (RMSE): 0.2250\n",
      "curve dfNN Run 1/1, Epoch 111/4000, Training Loss (RMSE): 0.2089\n",
      "curve dfNN Run 1/1, Epoch 112/4000, Training Loss (RMSE): 0.1963\n",
      "curve dfNN Run 1/1, Epoch 113/4000, Training Loss (RMSE): 0.2051\n",
      "curve dfNN Run 1/1, Epoch 114/4000, Training Loss (RMSE): 0.2031\n",
      "curve dfNN Run 1/1, Epoch 115/4000, Training Loss (RMSE): 0.2059\n",
      "curve dfNN Run 1/1, Epoch 116/4000, Training Loss (RMSE): 0.2032\n",
      "curve dfNN Run 1/1, Epoch 117/4000, Training Loss (RMSE): 0.2106\n",
      "curve dfNN Run 1/1, Epoch 118/4000, Training Loss (RMSE): 0.2084\n",
      "curve dfNN Run 1/1, Epoch 119/4000, Training Loss (RMSE): 0.2255\n",
      "curve dfNN Run 1/1, Epoch 120/4000, Training Loss (RMSE): 0.2146\n",
      "curve dfNN Run 1/1, Epoch 121/4000, Training Loss (RMSE): 0.2144\n",
      "curve dfNN Run 1/1, Epoch 122/4000, Training Loss (RMSE): 0.2194\n",
      "curve dfNN Run 1/1, Epoch 123/4000, Training Loss (RMSE): 0.2234\n",
      "curve dfNN Run 1/1, Epoch 124/4000, Training Loss (RMSE): 0.2054\n",
      "curve dfNN Run 1/1, Epoch 125/4000, Training Loss (RMSE): 0.1985\n",
      "curve dfNN Run 1/1, Epoch 126/4000, Training Loss (RMSE): 0.1955\n",
      "curve dfNN Run 1/1, Epoch 127/4000, Training Loss (RMSE): 0.1868\n",
      "curve dfNN Run 1/1, Epoch 128/4000, Training Loss (RMSE): 0.1984\n",
      "curve dfNN Run 1/1, Epoch 129/4000, Training Loss (RMSE): 0.1982\n",
      "curve dfNN Run 1/1, Epoch 130/4000, Training Loss (RMSE): 0.1782\n",
      "curve dfNN Run 1/1, Epoch 131/4000, Training Loss (RMSE): 0.1951\n",
      "curve dfNN Run 1/1, Epoch 132/4000, Training Loss (RMSE): 0.1788\n",
      "curve dfNN Run 1/1, Epoch 133/4000, Training Loss (RMSE): 0.1973\n",
      "curve dfNN Run 1/1, Epoch 134/4000, Training Loss (RMSE): 0.1948\n",
      "curve dfNN Run 1/1, Epoch 135/4000, Training Loss (RMSE): 0.1915\n",
      "curve dfNN Run 1/1, Epoch 136/4000, Training Loss (RMSE): 0.1871\n",
      "curve dfNN Run 1/1, Epoch 137/4000, Training Loss (RMSE): 0.1830\n",
      "curve dfNN Run 1/1, Epoch 138/4000, Training Loss (RMSE): 0.1956\n",
      "curve dfNN Run 1/1, Epoch 139/4000, Training Loss (RMSE): 0.1834\n",
      "curve dfNN Run 1/1, Epoch 140/4000, Training Loss (RMSE): 0.1927\n",
      "curve dfNN Run 1/1, Epoch 141/4000, Training Loss (RMSE): 0.1804\n",
      "curve dfNN Run 1/1, Epoch 142/4000, Training Loss (RMSE): 0.1942\n",
      "curve dfNN Run 1/1, Epoch 143/4000, Training Loss (RMSE): 0.1779\n",
      "curve dfNN Run 1/1, Epoch 144/4000, Training Loss (RMSE): 0.1706\n",
      "curve dfNN Run 1/1, Epoch 145/4000, Training Loss (RMSE): 0.1786\n",
      "curve dfNN Run 1/1, Epoch 146/4000, Training Loss (RMSE): 0.1869\n",
      "curve dfNN Run 1/1, Epoch 147/4000, Training Loss (RMSE): 0.2042\n",
      "curve dfNN Run 1/1, Epoch 148/4000, Training Loss (RMSE): 0.1860\n",
      "curve dfNN Run 1/1, Epoch 149/4000, Training Loss (RMSE): 0.1732\n",
      "curve dfNN Run 1/1, Epoch 150/4000, Training Loss (RMSE): 0.1864\n",
      "curve dfNN Run 1/1, Epoch 151/4000, Training Loss (RMSE): 0.1861\n",
      "curve dfNN Run 1/1, Epoch 152/4000, Training Loss (RMSE): 0.1841\n",
      "curve dfNN Run 1/1, Epoch 153/4000, Training Loss (RMSE): 0.1858\n",
      "curve dfNN Run 1/1, Epoch 154/4000, Training Loss (RMSE): 0.1871\n",
      "curve dfNN Run 1/1, Epoch 155/4000, Training Loss (RMSE): 0.2005\n",
      "curve dfNN Run 1/1, Epoch 156/4000, Training Loss (RMSE): 0.2103\n",
      "curve dfNN Run 1/1, Epoch 157/4000, Training Loss (RMSE): 0.2042\n",
      "curve dfNN Run 1/1, Epoch 158/4000, Training Loss (RMSE): 0.1892\n",
      "curve dfNN Run 1/1, Epoch 159/4000, Training Loss (RMSE): 0.1875\n",
      "curve dfNN Run 1/1, Epoch 160/4000, Training Loss (RMSE): 0.1859\n",
      "curve dfNN Run 1/1, Epoch 161/4000, Training Loss (RMSE): 0.1666\n",
      "curve dfNN Run 1/1, Epoch 162/4000, Training Loss (RMSE): 0.1765\n",
      "curve dfNN Run 1/1, Epoch 163/4000, Training Loss (RMSE): 0.1916\n",
      "curve dfNN Run 1/1, Epoch 164/4000, Training Loss (RMSE): 0.1777\n",
      "curve dfNN Run 1/1, Epoch 165/4000, Training Loss (RMSE): 0.1841\n",
      "curve dfNN Run 1/1, Epoch 166/4000, Training Loss (RMSE): 0.2112\n",
      "curve dfNN Run 1/1, Epoch 167/4000, Training Loss (RMSE): 0.1879\n",
      "curve dfNN Run 1/1, Epoch 168/4000, Training Loss (RMSE): 0.1879\n",
      "curve dfNN Run 1/1, Epoch 169/4000, Training Loss (RMSE): 0.1981\n",
      "curve dfNN Run 1/1, Epoch 170/4000, Training Loss (RMSE): 0.1863\n",
      "curve dfNN Run 1/1, Epoch 171/4000, Training Loss (RMSE): 0.1871\n",
      "curve dfNN Run 1/1, Epoch 172/4000, Training Loss (RMSE): 0.1877\n",
      "curve dfNN Run 1/1, Epoch 173/4000, Training Loss (RMSE): 0.1901\n",
      "curve dfNN Run 1/1, Epoch 174/4000, Training Loss (RMSE): 0.1918\n",
      "curve dfNN Run 1/1, Epoch 175/4000, Training Loss (RMSE): 0.1808\n",
      "curve dfNN Run 1/1, Epoch 176/4000, Training Loss (RMSE): 0.1935\n",
      "curve dfNN Run 1/1, Epoch 177/4000, Training Loss (RMSE): 0.2072\n",
      "curve dfNN Run 1/1, Epoch 178/4000, Training Loss (RMSE): 0.1969\n",
      "curve dfNN Run 1/1, Epoch 179/4000, Training Loss (RMSE): 0.1808\n",
      "curve dfNN Run 1/1, Epoch 180/4000, Training Loss (RMSE): 0.1971\n",
      "curve dfNN Run 1/1, Epoch 181/4000, Training Loss (RMSE): 0.1941\n",
      "curve dfNN Run 1/1, Epoch 182/4000, Training Loss (RMSE): 0.1753\n",
      "curve dfNN Run 1/1, Epoch 183/4000, Training Loss (RMSE): 0.1763\n",
      "curve dfNN Run 1/1, Epoch 184/4000, Training Loss (RMSE): 0.1784\n",
      "curve dfNN Run 1/1, Epoch 185/4000, Training Loss (RMSE): 0.1851\n",
      "curve dfNN Run 1/1, Epoch 186/4000, Training Loss (RMSE): 0.1854\n",
      "curve dfNN Run 1/1, Epoch 187/4000, Training Loss (RMSE): 0.1833\n",
      "curve dfNN Run 1/1, Epoch 188/4000, Training Loss (RMSE): 0.1947\n",
      "curve dfNN Run 1/1, Epoch 189/4000, Training Loss (RMSE): 0.1851\n",
      "curve dfNN Run 1/1, Epoch 190/4000, Training Loss (RMSE): 0.1758\n",
      "curve dfNN Run 1/1, Epoch 191/4000, Training Loss (RMSE): 0.1858\n",
      "curve dfNN Run 1/1, Epoch 192/4000, Training Loss (RMSE): 0.1950\n",
      "curve dfNN Run 1/1, Epoch 193/4000, Training Loss (RMSE): 0.1786\n",
      "curve dfNN Run 1/1, Epoch 194/4000, Training Loss (RMSE): 0.1861\n",
      "curve dfNN Run 1/1, Epoch 195/4000, Training Loss (RMSE): 0.1744\n",
      "curve dfNN Run 1/1, Epoch 196/4000, Training Loss (RMSE): 0.1905\n",
      "curve dfNN Run 1/1, Epoch 197/4000, Training Loss (RMSE): 0.1883\n",
      "curve dfNN Run 1/1, Epoch 198/4000, Training Loss (RMSE): 0.1699\n",
      "curve dfNN Run 1/1, Epoch 199/4000, Training Loss (RMSE): 0.1845\n",
      "curve dfNN Run 1/1, Epoch 200/4000, Training Loss (RMSE): 0.1912\n",
      "curve dfNN Run 1/1, Epoch 201/4000, Training Loss (RMSE): 0.1838\n",
      "curve dfNN Run 1/1, Epoch 202/4000, Training Loss (RMSE): 0.1889\n",
      "curve dfNN Run 1/1, Epoch 203/4000, Training Loss (RMSE): 0.1694\n",
      "curve dfNN Run 1/1, Epoch 204/4000, Training Loss (RMSE): 0.1790\n",
      "curve dfNN Run 1/1, Epoch 205/4000, Training Loss (RMSE): 0.1692\n",
      "curve dfNN Run 1/1, Epoch 206/4000, Training Loss (RMSE): 0.1729\n",
      "curve dfNN Run 1/1, Epoch 207/4000, Training Loss (RMSE): 0.1822\n",
      "curve dfNN Run 1/1, Epoch 208/4000, Training Loss (RMSE): 0.1831\n",
      "curve dfNN Run 1/1, Epoch 209/4000, Training Loss (RMSE): 0.1656\n",
      "curve dfNN Run 1/1, Epoch 210/4000, Training Loss (RMSE): 0.1736\n",
      "curve dfNN Run 1/1, Epoch 211/4000, Training Loss (RMSE): 0.1839\n",
      "curve dfNN Run 1/1, Epoch 212/4000, Training Loss (RMSE): 0.1921\n",
      "curve dfNN Run 1/1, Epoch 213/4000, Training Loss (RMSE): 0.1857\n",
      "curve dfNN Run 1/1, Epoch 214/4000, Training Loss (RMSE): 0.1912\n",
      "curve dfNN Run 1/1, Epoch 215/4000, Training Loss (RMSE): 0.1806\n",
      "curve dfNN Run 1/1, Epoch 216/4000, Training Loss (RMSE): 0.1728\n",
      "curve dfNN Run 1/1, Epoch 217/4000, Training Loss (RMSE): 0.1874\n",
      "curve dfNN Run 1/1, Epoch 218/4000, Training Loss (RMSE): 0.1923\n",
      "curve dfNN Run 1/1, Epoch 219/4000, Training Loss (RMSE): 0.2017\n",
      "curve dfNN Run 1/1, Epoch 220/4000, Training Loss (RMSE): 0.1881\n",
      "curve dfNN Run 1/1, Epoch 221/4000, Training Loss (RMSE): 0.1800\n",
      "curve dfNN Run 1/1, Epoch 222/4000, Training Loss (RMSE): 0.1725\n",
      "curve dfNN Run 1/1, Epoch 223/4000, Training Loss (RMSE): 0.1953\n",
      "curve dfNN Run 1/1, Epoch 224/4000, Training Loss (RMSE): 0.1658\n",
      "curve dfNN Run 1/1, Epoch 225/4000, Training Loss (RMSE): 0.1941\n",
      "curve dfNN Run 1/1, Epoch 226/4000, Training Loss (RMSE): 0.1684\n",
      "curve dfNN Run 1/1, Epoch 227/4000, Training Loss (RMSE): 0.1793\n",
      "curve dfNN Run 1/1, Epoch 228/4000, Training Loss (RMSE): 0.1658\n",
      "curve dfNN Run 1/1, Epoch 229/4000, Training Loss (RMSE): 0.1876\n",
      "curve dfNN Run 1/1, Epoch 230/4000, Training Loss (RMSE): 0.1883\n",
      "curve dfNN Run 1/1, Epoch 231/4000, Training Loss (RMSE): 0.1868\n",
      "curve dfNN Run 1/1, Epoch 232/4000, Training Loss (RMSE): 0.1969\n",
      "curve dfNN Run 1/1, Epoch 233/4000, Training Loss (RMSE): 0.1896\n",
      "curve dfNN Run 1/1, Epoch 234/4000, Training Loss (RMSE): 0.1780\n",
      "curve dfNN Run 1/1, Epoch 235/4000, Training Loss (RMSE): 0.1744\n",
      "curve dfNN Run 1/1, Epoch 236/4000, Training Loss (RMSE): 0.1855\n",
      "curve dfNN Run 1/1, Epoch 237/4000, Training Loss (RMSE): 0.1694\n",
      "curve dfNN Run 1/1, Epoch 238/4000, Training Loss (RMSE): 0.1880\n",
      "curve dfNN Run 1/1, Epoch 239/4000, Training Loss (RMSE): 0.1638\n",
      "curve dfNN Run 1/1, Epoch 240/4000, Training Loss (RMSE): 0.1830\n",
      "curve dfNN Run 1/1, Epoch 241/4000, Training Loss (RMSE): 0.1777\n",
      "curve dfNN Run 1/1, Epoch 242/4000, Training Loss (RMSE): 0.1774\n",
      "curve dfNN Run 1/1, Epoch 243/4000, Training Loss (RMSE): 0.1711\n",
      "curve dfNN Run 1/1, Epoch 244/4000, Training Loss (RMSE): 0.1739\n",
      "curve dfNN Run 1/1, Epoch 245/4000, Training Loss (RMSE): 0.1827\n",
      "curve dfNN Run 1/1, Epoch 246/4000, Training Loss (RMSE): 0.1601\n",
      "curve dfNN Run 1/1, Epoch 247/4000, Training Loss (RMSE): 0.1633\n",
      "curve dfNN Run 1/1, Epoch 248/4000, Training Loss (RMSE): 0.1725\n",
      "curve dfNN Run 1/1, Epoch 249/4000, Training Loss (RMSE): 0.1980\n",
      "curve dfNN Run 1/1, Epoch 250/4000, Training Loss (RMSE): 0.1660\n",
      "curve dfNN Run 1/1, Epoch 251/4000, Training Loss (RMSE): 0.1679\n",
      "curve dfNN Run 1/1, Epoch 252/4000, Training Loss (RMSE): 0.1549\n",
      "curve dfNN Run 1/1, Epoch 253/4000, Training Loss (RMSE): 0.1647\n",
      "curve dfNN Run 1/1, Epoch 254/4000, Training Loss (RMSE): 0.1692\n",
      "curve dfNN Run 1/1, Epoch 255/4000, Training Loss (RMSE): 0.1804\n",
      "curve dfNN Run 1/1, Epoch 256/4000, Training Loss (RMSE): 0.1900\n",
      "curve dfNN Run 1/1, Epoch 257/4000, Training Loss (RMSE): 0.1672\n",
      "curve dfNN Run 1/1, Epoch 258/4000, Training Loss (RMSE): 0.1658\n",
      "curve dfNN Run 1/1, Epoch 259/4000, Training Loss (RMSE): 0.1599\n",
      "curve dfNN Run 1/1, Epoch 260/4000, Training Loss (RMSE): 0.1634\n",
      "curve dfNN Run 1/1, Epoch 261/4000, Training Loss (RMSE): 0.1607\n",
      "curve dfNN Run 1/1, Epoch 262/4000, Training Loss (RMSE): 0.1837\n",
      "curve dfNN Run 1/1, Epoch 263/4000, Training Loss (RMSE): 0.1744\n",
      "curve dfNN Run 1/1, Epoch 264/4000, Training Loss (RMSE): 0.1581\n",
      "curve dfNN Run 1/1, Epoch 265/4000, Training Loss (RMSE): 0.1652\n",
      "curve dfNN Run 1/1, Epoch 266/4000, Training Loss (RMSE): 0.1551\n",
      "curve dfNN Run 1/1, Epoch 267/4000, Training Loss (RMSE): 0.1795\n",
      "curve dfNN Run 1/1, Epoch 268/4000, Training Loss (RMSE): 0.1559\n",
      "curve dfNN Run 1/1, Epoch 269/4000, Training Loss (RMSE): 0.1564\n",
      "curve dfNN Run 1/1, Epoch 270/4000, Training Loss (RMSE): 0.1621\n",
      "curve dfNN Run 1/1, Epoch 271/4000, Training Loss (RMSE): 0.1643\n",
      "curve dfNN Run 1/1, Epoch 272/4000, Training Loss (RMSE): 0.1646\n",
      "curve dfNN Run 1/1, Epoch 273/4000, Training Loss (RMSE): 0.1593\n",
      "curve dfNN Run 1/1, Epoch 274/4000, Training Loss (RMSE): 0.1561\n",
      "curve dfNN Run 1/1, Epoch 275/4000, Training Loss (RMSE): 0.1593\n",
      "curve dfNN Run 1/1, Epoch 276/4000, Training Loss (RMSE): 0.1605\n",
      "curve dfNN Run 1/1, Epoch 277/4000, Training Loss (RMSE): 0.1645\n",
      "curve dfNN Run 1/1, Epoch 278/4000, Training Loss (RMSE): 0.1539\n",
      "curve dfNN Run 1/1, Epoch 279/4000, Training Loss (RMSE): 0.1496\n",
      "curve dfNN Run 1/1, Epoch 280/4000, Training Loss (RMSE): 0.1511\n",
      "curve dfNN Run 1/1, Epoch 281/4000, Training Loss (RMSE): 0.1478\n",
      "curve dfNN Run 1/1, Epoch 282/4000, Training Loss (RMSE): 0.1580\n",
      "curve dfNN Run 1/1, Epoch 283/4000, Training Loss (RMSE): 0.1674\n",
      "curve dfNN Run 1/1, Epoch 284/4000, Training Loss (RMSE): 0.1630\n",
      "curve dfNN Run 1/1, Epoch 285/4000, Training Loss (RMSE): 0.1578\n",
      "curve dfNN Run 1/1, Epoch 286/4000, Training Loss (RMSE): 0.1615\n",
      "curve dfNN Run 1/1, Epoch 287/4000, Training Loss (RMSE): 0.1608\n",
      "curve dfNN Run 1/1, Epoch 288/4000, Training Loss (RMSE): 0.1359\n",
      "curve dfNN Run 1/1, Epoch 289/4000, Training Loss (RMSE): 0.1575\n",
      "curve dfNN Run 1/1, Epoch 290/4000, Training Loss (RMSE): 0.1651\n",
      "curve dfNN Run 1/1, Epoch 291/4000, Training Loss (RMSE): 0.1418\n",
      "curve dfNN Run 1/1, Epoch 292/4000, Training Loss (RMSE): 0.1667\n",
      "curve dfNN Run 1/1, Epoch 293/4000, Training Loss (RMSE): 0.1467\n",
      "curve dfNN Run 1/1, Epoch 294/4000, Training Loss (RMSE): 0.1547\n",
      "curve dfNN Run 1/1, Epoch 295/4000, Training Loss (RMSE): 0.1511\n",
      "curve dfNN Run 1/1, Epoch 296/4000, Training Loss (RMSE): 0.1397\n",
      "curve dfNN Run 1/1, Epoch 297/4000, Training Loss (RMSE): 0.1612\n",
      "curve dfNN Run 1/1, Epoch 298/4000, Training Loss (RMSE): 0.1850\n",
      "curve dfNN Run 1/1, Epoch 299/4000, Training Loss (RMSE): 0.1566\n",
      "curve dfNN Run 1/1, Epoch 300/4000, Training Loss (RMSE): 0.1588\n",
      "curve dfNN Run 1/1, Epoch 301/4000, Training Loss (RMSE): 0.1512\n",
      "curve dfNN Run 1/1, Epoch 302/4000, Training Loss (RMSE): 0.1445\n",
      "curve dfNN Run 1/1, Epoch 303/4000, Training Loss (RMSE): 0.1587\n",
      "curve dfNN Run 1/1, Epoch 304/4000, Training Loss (RMSE): 0.1465\n",
      "curve dfNN Run 1/1, Epoch 305/4000, Training Loss (RMSE): 0.1354\n",
      "curve dfNN Run 1/1, Epoch 306/4000, Training Loss (RMSE): 0.1416\n",
      "curve dfNN Run 1/1, Epoch 307/4000, Training Loss (RMSE): 0.1462\n",
      "curve dfNN Run 1/1, Epoch 308/4000, Training Loss (RMSE): 0.1416\n",
      "curve dfNN Run 1/1, Epoch 309/4000, Training Loss (RMSE): 0.1512\n",
      "curve dfNN Run 1/1, Epoch 310/4000, Training Loss (RMSE): 0.1455\n",
      "curve dfNN Run 1/1, Epoch 311/4000, Training Loss (RMSE): 0.1667\n",
      "curve dfNN Run 1/1, Epoch 312/4000, Training Loss (RMSE): 0.1333\n",
      "curve dfNN Run 1/1, Epoch 313/4000, Training Loss (RMSE): 0.1335\n",
      "curve dfNN Run 1/1, Epoch 314/4000, Training Loss (RMSE): 0.1523\n",
      "curve dfNN Run 1/1, Epoch 315/4000, Training Loss (RMSE): 0.1457\n",
      "curve dfNN Run 1/1, Epoch 316/4000, Training Loss (RMSE): 0.1334\n",
      "curve dfNN Run 1/1, Epoch 317/4000, Training Loss (RMSE): 0.1603\n",
      "curve dfNN Run 1/1, Epoch 318/4000, Training Loss (RMSE): 0.1346\n",
      "curve dfNN Run 1/1, Epoch 319/4000, Training Loss (RMSE): 0.1400\n",
      "curve dfNN Run 1/1, Epoch 320/4000, Training Loss (RMSE): 0.1379\n",
      "curve dfNN Run 1/1, Epoch 321/4000, Training Loss (RMSE): 0.1483\n",
      "curve dfNN Run 1/1, Epoch 322/4000, Training Loss (RMSE): 0.1322\n",
      "curve dfNN Run 1/1, Epoch 323/4000, Training Loss (RMSE): 0.1490\n",
      "curve dfNN Run 1/1, Epoch 324/4000, Training Loss (RMSE): 0.1435\n",
      "curve dfNN Run 1/1, Epoch 325/4000, Training Loss (RMSE): 0.1298\n",
      "curve dfNN Run 1/1, Epoch 326/4000, Training Loss (RMSE): 0.1387\n",
      "curve dfNN Run 1/1, Epoch 327/4000, Training Loss (RMSE): 0.1490\n",
      "curve dfNN Run 1/1, Epoch 328/4000, Training Loss (RMSE): 0.1647\n",
      "curve dfNN Run 1/1, Epoch 329/4000, Training Loss (RMSE): 0.1461\n",
      "curve dfNN Run 1/1, Epoch 330/4000, Training Loss (RMSE): 0.1406\n",
      "curve dfNN Run 1/1, Epoch 331/4000, Training Loss (RMSE): 0.1487\n",
      "curve dfNN Run 1/1, Epoch 332/4000, Training Loss (RMSE): 0.1435\n",
      "curve dfNN Run 1/1, Epoch 333/4000, Training Loss (RMSE): 0.1343\n",
      "curve dfNN Run 1/1, Epoch 334/4000, Training Loss (RMSE): 0.1262\n",
      "curve dfNN Run 1/1, Epoch 335/4000, Training Loss (RMSE): 0.1480\n",
      "curve dfNN Run 1/1, Epoch 336/4000, Training Loss (RMSE): 0.1545\n",
      "curve dfNN Run 1/1, Epoch 337/4000, Training Loss (RMSE): 0.1524\n",
      "curve dfNN Run 1/1, Epoch 338/4000, Training Loss (RMSE): 0.1483\n",
      "curve dfNN Run 1/1, Epoch 339/4000, Training Loss (RMSE): 0.1402\n",
      "curve dfNN Run 1/1, Epoch 340/4000, Training Loss (RMSE): 0.1272\n",
      "curve dfNN Run 1/1, Epoch 341/4000, Training Loss (RMSE): 0.1445\n",
      "curve dfNN Run 1/1, Epoch 342/4000, Training Loss (RMSE): 0.1311\n",
      "curve dfNN Run 1/1, Epoch 343/4000, Training Loss (RMSE): 0.1543\n",
      "curve dfNN Run 1/1, Epoch 344/4000, Training Loss (RMSE): 0.1436\n",
      "curve dfNN Run 1/1, Epoch 345/4000, Training Loss (RMSE): 0.1309\n",
      "curve dfNN Run 1/1, Epoch 346/4000, Training Loss (RMSE): 0.1373\n",
      "curve dfNN Run 1/1, Epoch 347/4000, Training Loss (RMSE): 0.1275\n",
      "curve dfNN Run 1/1, Epoch 348/4000, Training Loss (RMSE): 0.1498\n",
      "curve dfNN Run 1/1, Epoch 349/4000, Training Loss (RMSE): 0.1341\n",
      "curve dfNN Run 1/1, Epoch 350/4000, Training Loss (RMSE): 0.1458\n",
      "curve dfNN Run 1/1, Epoch 351/4000, Training Loss (RMSE): 0.1381\n",
      "curve dfNN Run 1/1, Epoch 352/4000, Training Loss (RMSE): 0.1333\n",
      "curve dfNN Run 1/1, Epoch 353/4000, Training Loss (RMSE): 0.1372\n",
      "curve dfNN Run 1/1, Epoch 354/4000, Training Loss (RMSE): 0.1414\n",
      "curve dfNN Run 1/1, Epoch 355/4000, Training Loss (RMSE): 0.1297\n",
      "curve dfNN Run 1/1, Epoch 356/4000, Training Loss (RMSE): 0.1402\n",
      "curve dfNN Run 1/1, Epoch 357/4000, Training Loss (RMSE): 0.1435\n",
      "curve dfNN Run 1/1, Epoch 358/4000, Training Loss (RMSE): 0.1411\n",
      "curve dfNN Run 1/1, Epoch 359/4000, Training Loss (RMSE): 0.1530\n",
      "curve dfNN Run 1/1, Epoch 360/4000, Training Loss (RMSE): 0.1545\n",
      "curve dfNN Run 1/1, Epoch 361/4000, Training Loss (RMSE): 0.1432\n",
      "curve dfNN Run 1/1, Epoch 362/4000, Training Loss (RMSE): 0.1326\n",
      "curve dfNN Run 1/1, Epoch 363/4000, Training Loss (RMSE): 0.1235\n",
      "curve dfNN Run 1/1, Epoch 364/4000, Training Loss (RMSE): 0.1464\n",
      "curve dfNN Run 1/1, Epoch 365/4000, Training Loss (RMSE): 0.1418\n",
      "curve dfNN Run 1/1, Epoch 366/4000, Training Loss (RMSE): 0.1384\n",
      "curve dfNN Run 1/1, Epoch 367/4000, Training Loss (RMSE): 0.1407\n",
      "curve dfNN Run 1/1, Epoch 368/4000, Training Loss (RMSE): 0.1303\n",
      "curve dfNN Run 1/1, Epoch 369/4000, Training Loss (RMSE): 0.1474\n",
      "curve dfNN Run 1/1, Epoch 370/4000, Training Loss (RMSE): 0.1269\n",
      "curve dfNN Run 1/1, Epoch 371/4000, Training Loss (RMSE): 0.1299\n",
      "curve dfNN Run 1/1, Epoch 372/4000, Training Loss (RMSE): 0.1321\n",
      "curve dfNN Run 1/1, Epoch 373/4000, Training Loss (RMSE): 0.1294\n",
      "curve dfNN Run 1/1, Epoch 374/4000, Training Loss (RMSE): 0.1312\n",
      "curve dfNN Run 1/1, Epoch 375/4000, Training Loss (RMSE): 0.1337\n",
      "curve dfNN Run 1/1, Epoch 376/4000, Training Loss (RMSE): 0.1346\n",
      "curve dfNN Run 1/1, Epoch 377/4000, Training Loss (RMSE): 0.1325\n",
      "curve dfNN Run 1/1, Epoch 378/4000, Training Loss (RMSE): 0.1249\n",
      "curve dfNN Run 1/1, Epoch 379/4000, Training Loss (RMSE): 0.1327\n",
      "curve dfNN Run 1/1, Epoch 380/4000, Training Loss (RMSE): 0.1446\n",
      "curve dfNN Run 1/1, Epoch 381/4000, Training Loss (RMSE): 0.1309\n",
      "curve dfNN Run 1/1, Epoch 382/4000, Training Loss (RMSE): 0.1316\n",
      "curve dfNN Run 1/1, Epoch 383/4000, Training Loss (RMSE): 0.1256\n",
      "curve dfNN Run 1/1, Epoch 384/4000, Training Loss (RMSE): 0.1338\n",
      "curve dfNN Run 1/1, Epoch 385/4000, Training Loss (RMSE): 0.1236\n",
      "curve dfNN Run 1/1, Epoch 386/4000, Training Loss (RMSE): 0.1321\n",
      "curve dfNN Run 1/1, Epoch 387/4000, Training Loss (RMSE): 0.1313\n",
      "curve dfNN Run 1/1, Epoch 388/4000, Training Loss (RMSE): 0.1319\n",
      "curve dfNN Run 1/1, Epoch 389/4000, Training Loss (RMSE): 0.1263\n",
      "curve dfNN Run 1/1, Epoch 390/4000, Training Loss (RMSE): 0.1288\n",
      "curve dfNN Run 1/1, Epoch 391/4000, Training Loss (RMSE): 0.1163\n",
      "curve dfNN Run 1/1, Epoch 392/4000, Training Loss (RMSE): 0.1183\n",
      "curve dfNN Run 1/1, Epoch 393/4000, Training Loss (RMSE): 0.1313\n",
      "curve dfNN Run 1/1, Epoch 394/4000, Training Loss (RMSE): 0.1303\n",
      "curve dfNN Run 1/1, Epoch 395/4000, Training Loss (RMSE): 0.1274\n",
      "curve dfNN Run 1/1, Epoch 396/4000, Training Loss (RMSE): 0.1282\n",
      "curve dfNN Run 1/1, Epoch 397/4000, Training Loss (RMSE): 0.1204\n",
      "curve dfNN Run 1/1, Epoch 398/4000, Training Loss (RMSE): 0.1385\n",
      "curve dfNN Run 1/1, Epoch 399/4000, Training Loss (RMSE): 0.1248\n",
      "curve dfNN Run 1/1, Epoch 400/4000, Training Loss (RMSE): 0.1378\n",
      "curve dfNN Run 1/1, Epoch 401/4000, Training Loss (RMSE): 0.1434\n",
      "curve dfNN Run 1/1, Epoch 402/4000, Training Loss (RMSE): 0.1324\n",
      "curve dfNN Run 1/1, Epoch 403/4000, Training Loss (RMSE): 0.1346\n",
      "curve dfNN Run 1/1, Epoch 404/4000, Training Loss (RMSE): 0.1365\n",
      "curve dfNN Run 1/1, Epoch 405/4000, Training Loss (RMSE): 0.1239\n",
      "curve dfNN Run 1/1, Epoch 406/4000, Training Loss (RMSE): 0.1276\n",
      "curve dfNN Run 1/1, Epoch 407/4000, Training Loss (RMSE): 0.1224\n",
      "curve dfNN Run 1/1, Epoch 408/4000, Training Loss (RMSE): 0.1096\n",
      "curve dfNN Run 1/1, Epoch 409/4000, Training Loss (RMSE): 0.1163\n",
      "curve dfNN Run 1/1, Epoch 410/4000, Training Loss (RMSE): 0.1206\n",
      "curve dfNN Run 1/1, Epoch 411/4000, Training Loss (RMSE): 0.1160\n",
      "curve dfNN Run 1/1, Epoch 412/4000, Training Loss (RMSE): 0.1160\n",
      "curve dfNN Run 1/1, Epoch 413/4000, Training Loss (RMSE): 0.1187\n",
      "curve dfNN Run 1/1, Epoch 414/4000, Training Loss (RMSE): 0.1239\n",
      "curve dfNN Run 1/1, Epoch 415/4000, Training Loss (RMSE): 0.1125\n",
      "curve dfNN Run 1/1, Epoch 416/4000, Training Loss (RMSE): 0.1171\n",
      "curve dfNN Run 1/1, Epoch 417/4000, Training Loss (RMSE): 0.1166\n",
      "curve dfNN Run 1/1, Epoch 418/4000, Training Loss (RMSE): 0.1138\n",
      "curve dfNN Run 1/1, Epoch 419/4000, Training Loss (RMSE): 0.1139\n",
      "curve dfNN Run 1/1, Epoch 420/4000, Training Loss (RMSE): 0.1164\n",
      "curve dfNN Run 1/1, Epoch 421/4000, Training Loss (RMSE): 0.1182\n",
      "curve dfNN Run 1/1, Epoch 422/4000, Training Loss (RMSE): 0.1179\n",
      "curve dfNN Run 1/1, Epoch 423/4000, Training Loss (RMSE): 0.1092\n",
      "curve dfNN Run 1/1, Epoch 424/4000, Training Loss (RMSE): 0.1048\n",
      "curve dfNN Run 1/1, Epoch 425/4000, Training Loss (RMSE): 0.1219\n",
      "curve dfNN Run 1/1, Epoch 426/4000, Training Loss (RMSE): 0.1083\n",
      "curve dfNN Run 1/1, Epoch 427/4000, Training Loss (RMSE): 0.1121\n",
      "curve dfNN Run 1/1, Epoch 428/4000, Training Loss (RMSE): 0.1228\n",
      "curve dfNN Run 1/1, Epoch 429/4000, Training Loss (RMSE): 0.1249\n",
      "curve dfNN Run 1/1, Epoch 430/4000, Training Loss (RMSE): 0.1173\n",
      "curve dfNN Run 1/1, Epoch 431/4000, Training Loss (RMSE): 0.1153\n",
      "curve dfNN Run 1/1, Epoch 432/4000, Training Loss (RMSE): 0.1055\n",
      "curve dfNN Run 1/1, Epoch 433/4000, Training Loss (RMSE): 0.1073\n",
      "curve dfNN Run 1/1, Epoch 434/4000, Training Loss (RMSE): 0.1077\n",
      "curve dfNN Run 1/1, Epoch 435/4000, Training Loss (RMSE): 0.1125\n",
      "curve dfNN Run 1/1, Epoch 436/4000, Training Loss (RMSE): 0.1202\n",
      "curve dfNN Run 1/1, Epoch 437/4000, Training Loss (RMSE): 0.1064\n",
      "curve dfNN Run 1/1, Epoch 438/4000, Training Loss (RMSE): 0.1067\n",
      "curve dfNN Run 1/1, Epoch 439/4000, Training Loss (RMSE): 0.1093\n",
      "curve dfNN Run 1/1, Epoch 440/4000, Training Loss (RMSE): 0.1168\n",
      "curve dfNN Run 1/1, Epoch 441/4000, Training Loss (RMSE): 0.1115\n",
      "curve dfNN Run 1/1, Epoch 442/4000, Training Loss (RMSE): 0.1077\n",
      "curve dfNN Run 1/1, Epoch 443/4000, Training Loss (RMSE): 0.1001\n",
      "curve dfNN Run 1/1, Epoch 444/4000, Training Loss (RMSE): 0.1091\n",
      "curve dfNN Run 1/1, Epoch 445/4000, Training Loss (RMSE): 0.1329\n",
      "curve dfNN Run 1/1, Epoch 446/4000, Training Loss (RMSE): 0.1251\n",
      "curve dfNN Run 1/1, Epoch 447/4000, Training Loss (RMSE): 0.1105\n",
      "curve dfNN Run 1/1, Epoch 448/4000, Training Loss (RMSE): 0.1061\n",
      "curve dfNN Run 1/1, Epoch 449/4000, Training Loss (RMSE): 0.1087\n",
      "curve dfNN Run 1/1, Epoch 450/4000, Training Loss (RMSE): 0.1074\n",
      "curve dfNN Run 1/1, Epoch 451/4000, Training Loss (RMSE): 0.1160\n",
      "curve dfNN Run 1/1, Epoch 452/4000, Training Loss (RMSE): 0.1157\n",
      "curve dfNN Run 1/1, Epoch 453/4000, Training Loss (RMSE): 0.1219\n",
      "curve dfNN Run 1/1, Epoch 454/4000, Training Loss (RMSE): 0.1093\n",
      "curve dfNN Run 1/1, Epoch 455/4000, Training Loss (RMSE): 0.1049\n",
      "curve dfNN Run 1/1, Epoch 456/4000, Training Loss (RMSE): 0.0955\n",
      "curve dfNN Run 1/1, Epoch 457/4000, Training Loss (RMSE): 0.1134\n",
      "curve dfNN Run 1/1, Epoch 458/4000, Training Loss (RMSE): 0.1013\n",
      "curve dfNN Run 1/1, Epoch 459/4000, Training Loss (RMSE): 0.1086\n",
      "curve dfNN Run 1/1, Epoch 460/4000, Training Loss (RMSE): 0.0962\n",
      "curve dfNN Run 1/1, Epoch 461/4000, Training Loss (RMSE): 0.1015\n",
      "curve dfNN Run 1/1, Epoch 462/4000, Training Loss (RMSE): 0.1096\n",
      "curve dfNN Run 1/1, Epoch 463/4000, Training Loss (RMSE): 0.0987\n",
      "curve dfNN Run 1/1, Epoch 464/4000, Training Loss (RMSE): 0.1018\n",
      "curve dfNN Run 1/1, Epoch 465/4000, Training Loss (RMSE): 0.1034\n",
      "curve dfNN Run 1/1, Epoch 466/4000, Training Loss (RMSE): 0.1022\n",
      "curve dfNN Run 1/1, Epoch 467/4000, Training Loss (RMSE): 0.0996\n",
      "curve dfNN Run 1/1, Epoch 468/4000, Training Loss (RMSE): 0.0969\n",
      "curve dfNN Run 1/1, Epoch 469/4000, Training Loss (RMSE): 0.0997\n",
      "curve dfNN Run 1/1, Epoch 470/4000, Training Loss (RMSE): 0.1027\n",
      "curve dfNN Run 1/1, Epoch 471/4000, Training Loss (RMSE): 0.0961\n",
      "curve dfNN Run 1/1, Epoch 472/4000, Training Loss (RMSE): 0.0944\n",
      "curve dfNN Run 1/1, Epoch 473/4000, Training Loss (RMSE): 0.1050\n",
      "curve dfNN Run 1/1, Epoch 474/4000, Training Loss (RMSE): 0.0960\n",
      "curve dfNN Run 1/1, Epoch 475/4000, Training Loss (RMSE): 0.1053\n",
      "curve dfNN Run 1/1, Epoch 476/4000, Training Loss (RMSE): 0.1092\n",
      "curve dfNN Run 1/1, Epoch 477/4000, Training Loss (RMSE): 0.1021\n",
      "curve dfNN Run 1/1, Epoch 478/4000, Training Loss (RMSE): 0.0934\n",
      "curve dfNN Run 1/1, Epoch 479/4000, Training Loss (RMSE): 0.0967\n",
      "curve dfNN Run 1/1, Epoch 480/4000, Training Loss (RMSE): 0.1019\n",
      "curve dfNN Run 1/1, Epoch 481/4000, Training Loss (RMSE): 0.0948\n",
      "curve dfNN Run 1/1, Epoch 482/4000, Training Loss (RMSE): 0.1016\n",
      "curve dfNN Run 1/1, Epoch 483/4000, Training Loss (RMSE): 0.0919\n",
      "curve dfNN Run 1/1, Epoch 484/4000, Training Loss (RMSE): 0.1055\n",
      "curve dfNN Run 1/1, Epoch 485/4000, Training Loss (RMSE): 0.0980\n",
      "curve dfNN Run 1/1, Epoch 486/4000, Training Loss (RMSE): 0.1299\n",
      "curve dfNN Run 1/1, Epoch 487/4000, Training Loss (RMSE): 0.1184\n",
      "curve dfNN Run 1/1, Epoch 488/4000, Training Loss (RMSE): 0.1075\n",
      "curve dfNN Run 1/1, Epoch 489/4000, Training Loss (RMSE): 0.1088\n",
      "curve dfNN Run 1/1, Epoch 490/4000, Training Loss (RMSE): 0.0991\n",
      "curve dfNN Run 1/1, Epoch 491/4000, Training Loss (RMSE): 0.0932\n",
      "curve dfNN Run 1/1, Epoch 492/4000, Training Loss (RMSE): 0.0871\n",
      "curve dfNN Run 1/1, Epoch 493/4000, Training Loss (RMSE): 0.0929\n",
      "curve dfNN Run 1/1, Epoch 494/4000, Training Loss (RMSE): 0.0963\n",
      "curve dfNN Run 1/1, Epoch 495/4000, Training Loss (RMSE): 0.0949\n",
      "curve dfNN Run 1/1, Epoch 496/4000, Training Loss (RMSE): 0.0974\n",
      "curve dfNN Run 1/1, Epoch 497/4000, Training Loss (RMSE): 0.1248\n",
      "curve dfNN Run 1/1, Epoch 498/4000, Training Loss (RMSE): 0.1092\n",
      "curve dfNN Run 1/1, Epoch 499/4000, Training Loss (RMSE): 0.0936\n",
      "curve dfNN Run 1/1, Epoch 500/4000, Training Loss (RMSE): 0.0975\n",
      "curve dfNN Run 1/1, Epoch 501/4000, Training Loss (RMSE): 0.0951\n",
      "curve dfNN Run 1/1, Epoch 502/4000, Training Loss (RMSE): 0.1007\n",
      "curve dfNN Run 1/1, Epoch 503/4000, Training Loss (RMSE): 0.1058\n",
      "curve dfNN Run 1/1, Epoch 504/4000, Training Loss (RMSE): 0.0946\n",
      "curve dfNN Run 1/1, Epoch 505/4000, Training Loss (RMSE): 0.0946\n",
      "curve dfNN Run 1/1, Epoch 506/4000, Training Loss (RMSE): 0.0889\n",
      "curve dfNN Run 1/1, Epoch 507/4000, Training Loss (RMSE): 0.0922\n",
      "curve dfNN Run 1/1, Epoch 508/4000, Training Loss (RMSE): 0.0944\n",
      "curve dfNN Run 1/1, Epoch 509/4000, Training Loss (RMSE): 0.0878\n",
      "curve dfNN Run 1/1, Epoch 510/4000, Training Loss (RMSE): 0.0933\n",
      "curve dfNN Run 1/1, Epoch 511/4000, Training Loss (RMSE): 0.0905\n",
      "curve dfNN Run 1/1, Epoch 512/4000, Training Loss (RMSE): 0.0845\n",
      "curve dfNN Run 1/1, Epoch 513/4000, Training Loss (RMSE): 0.0854\n",
      "curve dfNN Run 1/1, Epoch 514/4000, Training Loss (RMSE): 0.0890\n",
      "curve dfNN Run 1/1, Epoch 515/4000, Training Loss (RMSE): 0.0935\n",
      "curve dfNN Run 1/1, Epoch 516/4000, Training Loss (RMSE): 0.0940\n",
      "curve dfNN Run 1/1, Epoch 517/4000, Training Loss (RMSE): 0.0902\n",
      "curve dfNN Run 1/1, Epoch 518/4000, Training Loss (RMSE): 0.0898\n",
      "curve dfNN Run 1/1, Epoch 519/4000, Training Loss (RMSE): 0.0862\n",
      "curve dfNN Run 1/1, Epoch 520/4000, Training Loss (RMSE): 0.0970\n",
      "curve dfNN Run 1/1, Epoch 521/4000, Training Loss (RMSE): 0.0994\n",
      "curve dfNN Run 1/1, Epoch 522/4000, Training Loss (RMSE): 0.0892\n",
      "curve dfNN Run 1/1, Epoch 523/4000, Training Loss (RMSE): 0.0860\n",
      "curve dfNN Run 1/1, Epoch 524/4000, Training Loss (RMSE): 0.0853\n",
      "curve dfNN Run 1/1, Epoch 525/4000, Training Loss (RMSE): 0.0905\n",
      "curve dfNN Run 1/1, Epoch 526/4000, Training Loss (RMSE): 0.0966\n",
      "curve dfNN Run 1/1, Epoch 527/4000, Training Loss (RMSE): 0.0998\n",
      "curve dfNN Run 1/1, Epoch 528/4000, Training Loss (RMSE): 0.0939\n",
      "curve dfNN Run 1/1, Epoch 529/4000, Training Loss (RMSE): 0.0983\n",
      "curve dfNN Run 1/1, Epoch 530/4000, Training Loss (RMSE): 0.1056\n",
      "curve dfNN Run 1/1, Epoch 531/4000, Training Loss (RMSE): 0.0962\n",
      "curve dfNN Run 1/1, Epoch 532/4000, Training Loss (RMSE): 0.0916\n",
      "curve dfNN Run 1/1, Epoch 533/4000, Training Loss (RMSE): 0.0834\n",
      "curve dfNN Run 1/1, Epoch 534/4000, Training Loss (RMSE): 0.0926\n",
      "curve dfNN Run 1/1, Epoch 535/4000, Training Loss (RMSE): 0.0952\n",
      "curve dfNN Run 1/1, Epoch 536/4000, Training Loss (RMSE): 0.0938\n",
      "curve dfNN Run 1/1, Epoch 537/4000, Training Loss (RMSE): 0.0826\n",
      "curve dfNN Run 1/1, Epoch 538/4000, Training Loss (RMSE): 0.1004\n",
      "curve dfNN Run 1/1, Epoch 539/4000, Training Loss (RMSE): 0.0961\n",
      "curve dfNN Run 1/1, Epoch 540/4000, Training Loss (RMSE): 0.0872\n",
      "curve dfNN Run 1/1, Epoch 541/4000, Training Loss (RMSE): 0.0945\n",
      "curve dfNN Run 1/1, Epoch 542/4000, Training Loss (RMSE): 0.0821\n",
      "curve dfNN Run 1/1, Epoch 543/4000, Training Loss (RMSE): 0.0848\n",
      "curve dfNN Run 1/1, Epoch 544/4000, Training Loss (RMSE): 0.0896\n",
      "curve dfNN Run 1/1, Epoch 545/4000, Training Loss (RMSE): 0.0839\n",
      "curve dfNN Run 1/1, Epoch 546/4000, Training Loss (RMSE): 0.0816\n",
      "curve dfNN Run 1/1, Epoch 547/4000, Training Loss (RMSE): 0.1031\n",
      "curve dfNN Run 1/1, Epoch 548/4000, Training Loss (RMSE): 0.0921\n",
      "curve dfNN Run 1/1, Epoch 549/4000, Training Loss (RMSE): 0.1019\n",
      "curve dfNN Run 1/1, Epoch 550/4000, Training Loss (RMSE): 0.0902\n",
      "curve dfNN Run 1/1, Epoch 551/4000, Training Loss (RMSE): 0.0868\n",
      "curve dfNN Run 1/1, Epoch 552/4000, Training Loss (RMSE): 0.0905\n",
      "curve dfNN Run 1/1, Epoch 553/4000, Training Loss (RMSE): 0.0948\n",
      "curve dfNN Run 1/1, Epoch 554/4000, Training Loss (RMSE): 0.0933\n",
      "curve dfNN Run 1/1, Epoch 555/4000, Training Loss (RMSE): 0.0907\n",
      "curve dfNN Run 1/1, Epoch 556/4000, Training Loss (RMSE): 0.0921\n",
      "curve dfNN Run 1/1, Epoch 557/4000, Training Loss (RMSE): 0.0898\n",
      "curve dfNN Run 1/1, Epoch 558/4000, Training Loss (RMSE): 0.0936\n",
      "curve dfNN Run 1/1, Epoch 559/4000, Training Loss (RMSE): 0.0838\n",
      "curve dfNN Run 1/1, Epoch 560/4000, Training Loss (RMSE): 0.0938\n",
      "curve dfNN Run 1/1, Epoch 561/4000, Training Loss (RMSE): 0.0886\n",
      "curve dfNN Run 1/1, Epoch 562/4000, Training Loss (RMSE): 0.0778\n",
      "curve dfNN Run 1/1, Epoch 563/4000, Training Loss (RMSE): 0.0820\n",
      "curve dfNN Run 1/1, Epoch 564/4000, Training Loss (RMSE): 0.0886\n",
      "curve dfNN Run 1/1, Epoch 565/4000, Training Loss (RMSE): 0.0792\n",
      "curve dfNN Run 1/1, Epoch 566/4000, Training Loss (RMSE): 0.0901\n",
      "curve dfNN Run 1/1, Epoch 567/4000, Training Loss (RMSE): 0.0940\n",
      "curve dfNN Run 1/1, Epoch 568/4000, Training Loss (RMSE): 0.0874\n",
      "curve dfNN Run 1/1, Epoch 569/4000, Training Loss (RMSE): 0.0860\n",
      "curve dfNN Run 1/1, Epoch 570/4000, Training Loss (RMSE): 0.0878\n",
      "curve dfNN Run 1/1, Epoch 571/4000, Training Loss (RMSE): 0.0802\n",
      "curve dfNN Run 1/1, Epoch 572/4000, Training Loss (RMSE): 0.0787\n",
      "curve dfNN Run 1/1, Epoch 573/4000, Training Loss (RMSE): 0.0885\n",
      "curve dfNN Run 1/1, Epoch 574/4000, Training Loss (RMSE): 0.0808\n",
      "curve dfNN Run 1/1, Epoch 575/4000, Training Loss (RMSE): 0.0806\n",
      "curve dfNN Run 1/1, Epoch 576/4000, Training Loss (RMSE): 0.0843\n",
      "curve dfNN Run 1/1, Epoch 577/4000, Training Loss (RMSE): 0.0841\n",
      "curve dfNN Run 1/1, Epoch 578/4000, Training Loss (RMSE): 0.0809\n",
      "curve dfNN Run 1/1, Epoch 579/4000, Training Loss (RMSE): 0.0824\n",
      "curve dfNN Run 1/1, Epoch 580/4000, Training Loss (RMSE): 0.0817\n",
      "curve dfNN Run 1/1, Epoch 581/4000, Training Loss (RMSE): 0.0854\n",
      "curve dfNN Run 1/1, Epoch 582/4000, Training Loss (RMSE): 0.0780\n",
      "curve dfNN Run 1/1, Epoch 583/4000, Training Loss (RMSE): 0.0948\n",
      "curve dfNN Run 1/1, Epoch 584/4000, Training Loss (RMSE): 0.0898\n",
      "curve dfNN Run 1/1, Epoch 585/4000, Training Loss (RMSE): 0.0866\n",
      "curve dfNN Run 1/1, Epoch 586/4000, Training Loss (RMSE): 0.0792\n",
      "curve dfNN Run 1/1, Epoch 587/4000, Training Loss (RMSE): 0.0855\n",
      "curve dfNN Run 1/1, Epoch 588/4000, Training Loss (RMSE): 0.0936\n",
      "curve dfNN Run 1/1, Epoch 589/4000, Training Loss (RMSE): 0.0822\n",
      "curve dfNN Run 1/1, Epoch 590/4000, Training Loss (RMSE): 0.0780\n",
      "curve dfNN Run 1/1, Epoch 591/4000, Training Loss (RMSE): 0.0727\n",
      "curve dfNN Run 1/1, Epoch 592/4000, Training Loss (RMSE): 0.0826\n",
      "curve dfNN Run 1/1, Epoch 593/4000, Training Loss (RMSE): 0.0879\n",
      "curve dfNN Run 1/1, Epoch 594/4000, Training Loss (RMSE): 0.0828\n",
      "curve dfNN Run 1/1, Epoch 595/4000, Training Loss (RMSE): 0.0775\n",
      "curve dfNN Run 1/1, Epoch 596/4000, Training Loss (RMSE): 0.0794\n",
      "curve dfNN Run 1/1, Epoch 597/4000, Training Loss (RMSE): 0.0750\n",
      "curve dfNN Run 1/1, Epoch 598/4000, Training Loss (RMSE): 0.0858\n",
      "curve dfNN Run 1/1, Epoch 599/4000, Training Loss (RMSE): 0.0887\n",
      "curve dfNN Run 1/1, Epoch 600/4000, Training Loss (RMSE): 0.0992\n",
      "curve dfNN Run 1/1, Epoch 601/4000, Training Loss (RMSE): 0.0894\n",
      "curve dfNN Run 1/1, Epoch 602/4000, Training Loss (RMSE): 0.0865\n",
      "curve dfNN Run 1/1, Epoch 603/4000, Training Loss (RMSE): 0.0835\n",
      "curve dfNN Run 1/1, Epoch 604/4000, Training Loss (RMSE): 0.0849\n",
      "curve dfNN Run 1/1, Epoch 605/4000, Training Loss (RMSE): 0.0861\n",
      "curve dfNN Run 1/1, Epoch 606/4000, Training Loss (RMSE): 0.0836\n",
      "curve dfNN Run 1/1, Epoch 607/4000, Training Loss (RMSE): 0.0766\n",
      "curve dfNN Run 1/1, Epoch 608/4000, Training Loss (RMSE): 0.0798\n",
      "curve dfNN Run 1/1, Epoch 609/4000, Training Loss (RMSE): 0.0897\n",
      "curve dfNN Run 1/1, Epoch 610/4000, Training Loss (RMSE): 0.0973\n",
      "curve dfNN Run 1/1, Epoch 611/4000, Training Loss (RMSE): 0.0751\n",
      "curve dfNN Run 1/1, Epoch 612/4000, Training Loss (RMSE): 0.0725\n",
      "curve dfNN Run 1/1, Epoch 613/4000, Training Loss (RMSE): 0.0838\n",
      "curve dfNN Run 1/1, Epoch 614/4000, Training Loss (RMSE): 0.0695\n",
      "curve dfNN Run 1/1, Epoch 615/4000, Training Loss (RMSE): 0.0774\n",
      "curve dfNN Run 1/1, Epoch 616/4000, Training Loss (RMSE): 0.0777\n",
      "curve dfNN Run 1/1, Epoch 617/4000, Training Loss (RMSE): 0.0735\n",
      "curve dfNN Run 1/1, Epoch 618/4000, Training Loss (RMSE): 0.0752\n",
      "curve dfNN Run 1/1, Epoch 619/4000, Training Loss (RMSE): 0.0757\n",
      "curve dfNN Run 1/1, Epoch 620/4000, Training Loss (RMSE): 0.0743\n",
      "curve dfNN Run 1/1, Epoch 621/4000, Training Loss (RMSE): 0.0705\n",
      "curve dfNN Run 1/1, Epoch 622/4000, Training Loss (RMSE): 0.0779\n",
      "curve dfNN Run 1/1, Epoch 623/4000, Training Loss (RMSE): 0.0669\n",
      "curve dfNN Run 1/1, Epoch 624/4000, Training Loss (RMSE): 0.0735\n",
      "curve dfNN Run 1/1, Epoch 625/4000, Training Loss (RMSE): 0.0649\n",
      "curve dfNN Run 1/1, Epoch 626/4000, Training Loss (RMSE): 0.0828\n",
      "curve dfNN Run 1/1, Epoch 627/4000, Training Loss (RMSE): 0.0727\n",
      "curve dfNN Run 1/1, Epoch 628/4000, Training Loss (RMSE): 0.0722\n",
      "curve dfNN Run 1/1, Epoch 629/4000, Training Loss (RMSE): 0.0717\n",
      "curve dfNN Run 1/1, Epoch 630/4000, Training Loss (RMSE): 0.0725\n",
      "curve dfNN Run 1/1, Epoch 631/4000, Training Loss (RMSE): 0.0736\n",
      "curve dfNN Run 1/1, Epoch 632/4000, Training Loss (RMSE): 0.0773\n",
      "curve dfNN Run 1/1, Epoch 633/4000, Training Loss (RMSE): 0.0925\n",
      "curve dfNN Run 1/1, Epoch 634/4000, Training Loss (RMSE): 0.0853\n",
      "curve dfNN Run 1/1, Epoch 635/4000, Training Loss (RMSE): 0.0785\n",
      "curve dfNN Run 1/1, Epoch 636/4000, Training Loss (RMSE): 0.0835\n",
      "curve dfNN Run 1/1, Epoch 637/4000, Training Loss (RMSE): 0.0792\n",
      "curve dfNN Run 1/1, Epoch 638/4000, Training Loss (RMSE): 0.0690\n",
      "curve dfNN Run 1/1, Epoch 639/4000, Training Loss (RMSE): 0.0719\n",
      "curve dfNN Run 1/1, Epoch 640/4000, Training Loss (RMSE): 0.0804\n",
      "curve dfNN Run 1/1, Epoch 641/4000, Training Loss (RMSE): 0.0695\n",
      "curve dfNN Run 1/1, Epoch 642/4000, Training Loss (RMSE): 0.0662\n",
      "curve dfNN Run 1/1, Epoch 643/4000, Training Loss (RMSE): 0.0670\n",
      "curve dfNN Run 1/1, Epoch 644/4000, Training Loss (RMSE): 0.0657\n",
      "curve dfNN Run 1/1, Epoch 645/4000, Training Loss (RMSE): 0.0667\n",
      "curve dfNN Run 1/1, Epoch 646/4000, Training Loss (RMSE): 0.0648\n",
      "curve dfNN Run 1/1, Epoch 647/4000, Training Loss (RMSE): 0.0658\n",
      "curve dfNN Run 1/1, Epoch 648/4000, Training Loss (RMSE): 0.0667\n",
      "curve dfNN Run 1/1, Epoch 649/4000, Training Loss (RMSE): 0.0724\n",
      "curve dfNN Run 1/1, Epoch 650/4000, Training Loss (RMSE): 0.0788\n",
      "curve dfNN Run 1/1, Epoch 651/4000, Training Loss (RMSE): 0.0741\n",
      "curve dfNN Run 1/1, Epoch 652/4000, Training Loss (RMSE): 0.0651\n",
      "curve dfNN Run 1/1, Epoch 653/4000, Training Loss (RMSE): 0.0710\n",
      "curve dfNN Run 1/1, Epoch 654/4000, Training Loss (RMSE): 0.0671\n",
      "curve dfNN Run 1/1, Epoch 655/4000, Training Loss (RMSE): 0.0657\n",
      "curve dfNN Run 1/1, Epoch 656/4000, Training Loss (RMSE): 0.0669\n",
      "curve dfNN Run 1/1, Epoch 657/4000, Training Loss (RMSE): 0.0653\n",
      "curve dfNN Run 1/1, Epoch 658/4000, Training Loss (RMSE): 0.0765\n",
      "curve dfNN Run 1/1, Epoch 659/4000, Training Loss (RMSE): 0.0728\n",
      "curve dfNN Run 1/1, Epoch 660/4000, Training Loss (RMSE): 0.0680\n",
      "curve dfNN Run 1/1, Epoch 661/4000, Training Loss (RMSE): 0.0618\n",
      "curve dfNN Run 1/1, Epoch 662/4000, Training Loss (RMSE): 0.0725\n",
      "curve dfNN Run 1/1, Epoch 663/4000, Training Loss (RMSE): 0.0668\n",
      "curve dfNN Run 1/1, Epoch 664/4000, Training Loss (RMSE): 0.0687\n",
      "curve dfNN Run 1/1, Epoch 665/4000, Training Loss (RMSE): 0.0640\n",
      "curve dfNN Run 1/1, Epoch 666/4000, Training Loss (RMSE): 0.0703\n",
      "curve dfNN Run 1/1, Epoch 667/4000, Training Loss (RMSE): 0.0743\n",
      "curve dfNN Run 1/1, Epoch 668/4000, Training Loss (RMSE): 0.0716\n",
      "curve dfNN Run 1/1, Epoch 669/4000, Training Loss (RMSE): 0.0671\n",
      "curve dfNN Run 1/1, Epoch 670/4000, Training Loss (RMSE): 0.0678\n",
      "curve dfNN Run 1/1, Epoch 671/4000, Training Loss (RMSE): 0.0617\n",
      "curve dfNN Run 1/1, Epoch 672/4000, Training Loss (RMSE): 0.0606\n",
      "curve dfNN Run 1/1, Epoch 673/4000, Training Loss (RMSE): 0.0766\n",
      "curve dfNN Run 1/1, Epoch 674/4000, Training Loss (RMSE): 0.0646\n",
      "curve dfNN Run 1/1, Epoch 675/4000, Training Loss (RMSE): 0.0662\n",
      "curve dfNN Run 1/1, Epoch 676/4000, Training Loss (RMSE): 0.0590\n",
      "curve dfNN Run 1/1, Epoch 677/4000, Training Loss (RMSE): 0.0760\n",
      "curve dfNN Run 1/1, Epoch 678/4000, Training Loss (RMSE): 0.0684\n",
      "curve dfNN Run 1/1, Epoch 679/4000, Training Loss (RMSE): 0.0619\n",
      "curve dfNN Run 1/1, Epoch 680/4000, Training Loss (RMSE): 0.0571\n",
      "curve dfNN Run 1/1, Epoch 681/4000, Training Loss (RMSE): 0.0663\n",
      "curve dfNN Run 1/1, Epoch 682/4000, Training Loss (RMSE): 0.0626\n",
      "curve dfNN Run 1/1, Epoch 683/4000, Training Loss (RMSE): 0.0649\n",
      "curve dfNN Run 1/1, Epoch 684/4000, Training Loss (RMSE): 0.0613\n",
      "curve dfNN Run 1/1, Epoch 685/4000, Training Loss (RMSE): 0.0599\n",
      "curve dfNN Run 1/1, Epoch 686/4000, Training Loss (RMSE): 0.0582\n",
      "curve dfNN Run 1/1, Epoch 687/4000, Training Loss (RMSE): 0.0607\n",
      "curve dfNN Run 1/1, Epoch 688/4000, Training Loss (RMSE): 0.0531\n",
      "curve dfNN Run 1/1, Epoch 689/4000, Training Loss (RMSE): 0.0569\n",
      "curve dfNN Run 1/1, Epoch 690/4000, Training Loss (RMSE): 0.0636\n",
      "curve dfNN Run 1/1, Epoch 691/4000, Training Loss (RMSE): 0.0603\n",
      "curve dfNN Run 1/1, Epoch 692/4000, Training Loss (RMSE): 0.0604\n",
      "curve dfNN Run 1/1, Epoch 693/4000, Training Loss (RMSE): 0.0616\n",
      "curve dfNN Run 1/1, Epoch 694/4000, Training Loss (RMSE): 0.0657\n",
      "curve dfNN Run 1/1, Epoch 695/4000, Training Loss (RMSE): 0.0624\n",
      "curve dfNN Run 1/1, Epoch 696/4000, Training Loss (RMSE): 0.0626\n",
      "curve dfNN Run 1/1, Epoch 697/4000, Training Loss (RMSE): 0.0574\n",
      "curve dfNN Run 1/1, Epoch 698/4000, Training Loss (RMSE): 0.0586\n",
      "curve dfNN Run 1/1, Epoch 699/4000, Training Loss (RMSE): 0.0597\n",
      "curve dfNN Run 1/1, Epoch 700/4000, Training Loss (RMSE): 0.0548\n",
      "curve dfNN Run 1/1, Epoch 701/4000, Training Loss (RMSE): 0.0626\n",
      "curve dfNN Run 1/1, Epoch 702/4000, Training Loss (RMSE): 0.0578\n",
      "curve dfNN Run 1/1, Epoch 703/4000, Training Loss (RMSE): 0.0646\n",
      "curve dfNN Run 1/1, Epoch 704/4000, Training Loss (RMSE): 0.0645\n",
      "curve dfNN Run 1/1, Epoch 705/4000, Training Loss (RMSE): 0.0730\n",
      "curve dfNN Run 1/1, Epoch 706/4000, Training Loss (RMSE): 0.0690\n",
      "curve dfNN Run 1/1, Epoch 707/4000, Training Loss (RMSE): 0.0722\n",
      "curve dfNN Run 1/1, Epoch 708/4000, Training Loss (RMSE): 0.0582\n",
      "curve dfNN Run 1/1, Epoch 709/4000, Training Loss (RMSE): 0.0576\n",
      "curve dfNN Run 1/1, Epoch 710/4000, Training Loss (RMSE): 0.0592\n",
      "curve dfNN Run 1/1, Epoch 711/4000, Training Loss (RMSE): 0.0655\n",
      "curve dfNN Run 1/1, Epoch 712/4000, Training Loss (RMSE): 0.0684\n",
      "curve dfNN Run 1/1, Epoch 713/4000, Training Loss (RMSE): 0.0647\n",
      "curve dfNN Run 1/1, Epoch 714/4000, Training Loss (RMSE): 0.0587\n",
      "curve dfNN Run 1/1, Epoch 715/4000, Training Loss (RMSE): 0.0677\n",
      "curve dfNN Run 1/1, Epoch 716/4000, Training Loss (RMSE): 0.0666\n",
      "curve dfNN Run 1/1, Epoch 717/4000, Training Loss (RMSE): 0.0656\n",
      "curve dfNN Run 1/1, Epoch 718/4000, Training Loss (RMSE): 0.0617\n",
      "curve dfNN Run 1/1, Epoch 719/4000, Training Loss (RMSE): 0.0617\n",
      "curve dfNN Run 1/1, Epoch 720/4000, Training Loss (RMSE): 0.0561\n",
      "curve dfNN Run 1/1, Epoch 721/4000, Training Loss (RMSE): 0.0566\n",
      "curve dfNN Run 1/1, Epoch 722/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 723/4000, Training Loss (RMSE): 0.0571\n",
      "curve dfNN Run 1/1, Epoch 724/4000, Training Loss (RMSE): 0.0589\n",
      "curve dfNN Run 1/1, Epoch 725/4000, Training Loss (RMSE): 0.0749\n",
      "curve dfNN Run 1/1, Epoch 726/4000, Training Loss (RMSE): 0.0576\n",
      "curve dfNN Run 1/1, Epoch 727/4000, Training Loss (RMSE): 0.0697\n",
      "curve dfNN Run 1/1, Epoch 728/4000, Training Loss (RMSE): 0.0620\n",
      "curve dfNN Run 1/1, Epoch 729/4000, Training Loss (RMSE): 0.0557\n",
      "curve dfNN Run 1/1, Epoch 730/4000, Training Loss (RMSE): 0.0580\n",
      "curve dfNN Run 1/1, Epoch 731/4000, Training Loss (RMSE): 0.0538\n",
      "curve dfNN Run 1/1, Epoch 732/4000, Training Loss (RMSE): 0.0594\n",
      "curve dfNN Run 1/1, Epoch 733/4000, Training Loss (RMSE): 0.0574\n",
      "curve dfNN Run 1/1, Epoch 734/4000, Training Loss (RMSE): 0.0557\n",
      "curve dfNN Run 1/1, Epoch 735/4000, Training Loss (RMSE): 0.0591\n",
      "curve dfNN Run 1/1, Epoch 736/4000, Training Loss (RMSE): 0.0576\n",
      "curve dfNN Run 1/1, Epoch 737/4000, Training Loss (RMSE): 0.0578\n",
      "curve dfNN Run 1/1, Epoch 738/4000, Training Loss (RMSE): 0.0613\n",
      "curve dfNN Run 1/1, Epoch 739/4000, Training Loss (RMSE): 0.0635\n",
      "curve dfNN Run 1/1, Epoch 740/4000, Training Loss (RMSE): 0.0620\n",
      "curve dfNN Run 1/1, Epoch 741/4000, Training Loss (RMSE): 0.0536\n",
      "curve dfNN Run 1/1, Epoch 742/4000, Training Loss (RMSE): 0.0539\n",
      "curve dfNN Run 1/1, Epoch 743/4000, Training Loss (RMSE): 0.0598\n",
      "curve dfNN Run 1/1, Epoch 744/4000, Training Loss (RMSE): 0.0614\n",
      "curve dfNN Run 1/1, Epoch 745/4000, Training Loss (RMSE): 0.0530\n",
      "curve dfNN Run 1/1, Epoch 746/4000, Training Loss (RMSE): 0.0736\n",
      "curve dfNN Run 1/1, Epoch 747/4000, Training Loss (RMSE): 0.0541\n",
      "curve dfNN Run 1/1, Epoch 748/4000, Training Loss (RMSE): 0.0532\n",
      "curve dfNN Run 1/1, Epoch 749/4000, Training Loss (RMSE): 0.0541\n",
      "curve dfNN Run 1/1, Epoch 750/4000, Training Loss (RMSE): 0.0570\n",
      "curve dfNN Run 1/1, Epoch 751/4000, Training Loss (RMSE): 0.0581\n",
      "curve dfNN Run 1/1, Epoch 752/4000, Training Loss (RMSE): 0.0529\n",
      "curve dfNN Run 1/1, Epoch 753/4000, Training Loss (RMSE): 0.0605\n",
      "curve dfNN Run 1/1, Epoch 754/4000, Training Loss (RMSE): 0.0535\n",
      "curve dfNN Run 1/1, Epoch 755/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 756/4000, Training Loss (RMSE): 0.0506\n",
      "curve dfNN Run 1/1, Epoch 757/4000, Training Loss (RMSE): 0.0528\n",
      "curve dfNN Run 1/1, Epoch 758/4000, Training Loss (RMSE): 0.0564\n",
      "curve dfNN Run 1/1, Epoch 759/4000, Training Loss (RMSE): 0.0643\n",
      "curve dfNN Run 1/1, Epoch 760/4000, Training Loss (RMSE): 0.0594\n",
      "curve dfNN Run 1/1, Epoch 761/4000, Training Loss (RMSE): 0.0591\n",
      "curve dfNN Run 1/1, Epoch 762/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 763/4000, Training Loss (RMSE): 0.0617\n",
      "curve dfNN Run 1/1, Epoch 764/4000, Training Loss (RMSE): 0.0517\n",
      "curve dfNN Run 1/1, Epoch 765/4000, Training Loss (RMSE): 0.0615\n",
      "curve dfNN Run 1/1, Epoch 766/4000, Training Loss (RMSE): 0.0555\n",
      "curve dfNN Run 1/1, Epoch 767/4000, Training Loss (RMSE): 0.0508\n",
      "curve dfNN Run 1/1, Epoch 768/4000, Training Loss (RMSE): 0.0517\n",
      "curve dfNN Run 1/1, Epoch 769/4000, Training Loss (RMSE): 0.0587\n",
      "curve dfNN Run 1/1, Epoch 770/4000, Training Loss (RMSE): 0.0561\n",
      "curve dfNN Run 1/1, Epoch 771/4000, Training Loss (RMSE): 0.0688\n",
      "curve dfNN Run 1/1, Epoch 772/4000, Training Loss (RMSE): 0.0608\n",
      "curve dfNN Run 1/1, Epoch 773/4000, Training Loss (RMSE): 0.0562\n",
      "curve dfNN Run 1/1, Epoch 774/4000, Training Loss (RMSE): 0.0545\n",
      "curve dfNN Run 1/1, Epoch 775/4000, Training Loss (RMSE): 0.0498\n",
      "curve dfNN Run 1/1, Epoch 776/4000, Training Loss (RMSE): 0.0540\n",
      "curve dfNN Run 1/1, Epoch 777/4000, Training Loss (RMSE): 0.0569\n",
      "curve dfNN Run 1/1, Epoch 778/4000, Training Loss (RMSE): 0.0516\n",
      "curve dfNN Run 1/1, Epoch 779/4000, Training Loss (RMSE): 0.0508\n",
      "curve dfNN Run 1/1, Epoch 780/4000, Training Loss (RMSE): 0.0533\n",
      "curve dfNN Run 1/1, Epoch 781/4000, Training Loss (RMSE): 0.0559\n",
      "curve dfNN Run 1/1, Epoch 782/4000, Training Loss (RMSE): 0.0569\n",
      "curve dfNN Run 1/1, Epoch 783/4000, Training Loss (RMSE): 0.0559\n",
      "curve dfNN Run 1/1, Epoch 784/4000, Training Loss (RMSE): 0.0612\n",
      "curve dfNN Run 1/1, Epoch 785/4000, Training Loss (RMSE): 0.0534\n",
      "curve dfNN Run 1/1, Epoch 786/4000, Training Loss (RMSE): 0.0505\n",
      "curve dfNN Run 1/1, Epoch 787/4000, Training Loss (RMSE): 0.0561\n",
      "curve dfNN Run 1/1, Epoch 788/4000, Training Loss (RMSE): 0.0484\n",
      "curve dfNN Run 1/1, Epoch 789/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 790/4000, Training Loss (RMSE): 0.0551\n",
      "curve dfNN Run 1/1, Epoch 791/4000, Training Loss (RMSE): 0.0525\n",
      "curve dfNN Run 1/1, Epoch 792/4000, Training Loss (RMSE): 0.0502\n",
      "curve dfNN Run 1/1, Epoch 793/4000, Training Loss (RMSE): 0.0514\n",
      "curve dfNN Run 1/1, Epoch 794/4000, Training Loss (RMSE): 0.0481\n",
      "curve dfNN Run 1/1, Epoch 795/4000, Training Loss (RMSE): 0.0524\n",
      "curve dfNN Run 1/1, Epoch 796/4000, Training Loss (RMSE): 0.0521\n",
      "curve dfNN Run 1/1, Epoch 797/4000, Training Loss (RMSE): 0.0506\n",
      "curve dfNN Run 1/1, Epoch 798/4000, Training Loss (RMSE): 0.0513\n",
      "curve dfNN Run 1/1, Epoch 799/4000, Training Loss (RMSE): 0.0521\n",
      "curve dfNN Run 1/1, Epoch 800/4000, Training Loss (RMSE): 0.0624\n",
      "curve dfNN Run 1/1, Epoch 801/4000, Training Loss (RMSE): 0.0491\n",
      "curve dfNN Run 1/1, Epoch 802/4000, Training Loss (RMSE): 0.0530\n",
      "curve dfNN Run 1/1, Epoch 803/4000, Training Loss (RMSE): 0.0493\n",
      "curve dfNN Run 1/1, Epoch 804/4000, Training Loss (RMSE): 0.0686\n",
      "curve dfNN Run 1/1, Epoch 805/4000, Training Loss (RMSE): 0.0601\n",
      "curve dfNN Run 1/1, Epoch 806/4000, Training Loss (RMSE): 0.0557\n",
      "curve dfNN Run 1/1, Epoch 807/4000, Training Loss (RMSE): 0.0565\n",
      "curve dfNN Run 1/1, Epoch 808/4000, Training Loss (RMSE): 0.0532\n",
      "curve dfNN Run 1/1, Epoch 809/4000, Training Loss (RMSE): 0.0505\n",
      "curve dfNN Run 1/1, Epoch 810/4000, Training Loss (RMSE): 0.0568\n",
      "curve dfNN Run 1/1, Epoch 811/4000, Training Loss (RMSE): 0.0536\n",
      "curve dfNN Run 1/1, Epoch 812/4000, Training Loss (RMSE): 0.0590\n",
      "curve dfNN Run 1/1, Epoch 813/4000, Training Loss (RMSE): 0.0592\n",
      "curve dfNN Run 1/1, Epoch 814/4000, Training Loss (RMSE): 0.0519\n",
      "curve dfNN Run 1/1, Epoch 815/4000, Training Loss (RMSE): 0.0529\n",
      "curve dfNN Run 1/1, Epoch 816/4000, Training Loss (RMSE): 0.0608\n",
      "curve dfNN Run 1/1, Epoch 817/4000, Training Loss (RMSE): 0.0510\n",
      "curve dfNN Run 1/1, Epoch 818/4000, Training Loss (RMSE): 0.0559\n",
      "curve dfNN Run 1/1, Epoch 819/4000, Training Loss (RMSE): 0.0549\n",
      "curve dfNN Run 1/1, Epoch 820/4000, Training Loss (RMSE): 0.0544\n",
      "curve dfNN Run 1/1, Epoch 821/4000, Training Loss (RMSE): 0.0506\n",
      "curve dfNN Run 1/1, Epoch 822/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 823/4000, Training Loss (RMSE): 0.0447\n",
      "curve dfNN Run 1/1, Epoch 824/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 825/4000, Training Loss (RMSE): 0.0499\n",
      "curve dfNN Run 1/1, Epoch 826/4000, Training Loss (RMSE): 0.0513\n",
      "curve dfNN Run 1/1, Epoch 827/4000, Training Loss (RMSE): 0.0565\n",
      "curve dfNN Run 1/1, Epoch 828/4000, Training Loss (RMSE): 0.0592\n",
      "curve dfNN Run 1/1, Epoch 829/4000, Training Loss (RMSE): 0.0565\n",
      "curve dfNN Run 1/1, Epoch 830/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 831/4000, Training Loss (RMSE): 0.0475\n",
      "curve dfNN Run 1/1, Epoch 832/4000, Training Loss (RMSE): 0.0478\n",
      "curve dfNN Run 1/1, Epoch 833/4000, Training Loss (RMSE): 0.0495\n",
      "curve dfNN Run 1/1, Epoch 834/4000, Training Loss (RMSE): 0.0569\n",
      "curve dfNN Run 1/1, Epoch 835/4000, Training Loss (RMSE): 0.0455\n",
      "curve dfNN Run 1/1, Epoch 836/4000, Training Loss (RMSE): 0.0512\n",
      "curve dfNN Run 1/1, Epoch 837/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 838/4000, Training Loss (RMSE): 0.0492\n",
      "curve dfNN Run 1/1, Epoch 839/4000, Training Loss (RMSE): 0.0503\n",
      "curve dfNN Run 1/1, Epoch 840/4000, Training Loss (RMSE): 0.0496\n",
      "curve dfNN Run 1/1, Epoch 841/4000, Training Loss (RMSE): 0.0543\n",
      "curve dfNN Run 1/1, Epoch 842/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 843/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 844/4000, Training Loss (RMSE): 0.0483\n",
      "curve dfNN Run 1/1, Epoch 845/4000, Training Loss (RMSE): 0.0545\n",
      "curve dfNN Run 1/1, Epoch 846/4000, Training Loss (RMSE): 0.0603\n",
      "curve dfNN Run 1/1, Epoch 847/4000, Training Loss (RMSE): 0.0509\n",
      "curve dfNN Run 1/1, Epoch 848/4000, Training Loss (RMSE): 0.0520\n",
      "curve dfNN Run 1/1, Epoch 849/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 850/4000, Training Loss (RMSE): 0.0523\n",
      "curve dfNN Run 1/1, Epoch 851/4000, Training Loss (RMSE): 0.0529\n",
      "curve dfNN Run 1/1, Epoch 852/4000, Training Loss (RMSE): 0.0551\n",
      "curve dfNN Run 1/1, Epoch 853/4000, Training Loss (RMSE): 0.0566\n",
      "curve dfNN Run 1/1, Epoch 854/4000, Training Loss (RMSE): 0.0587\n",
      "curve dfNN Run 1/1, Epoch 855/4000, Training Loss (RMSE): 0.0478\n",
      "curve dfNN Run 1/1, Epoch 856/4000, Training Loss (RMSE): 0.0495\n",
      "curve dfNN Run 1/1, Epoch 857/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 858/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 859/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 860/4000, Training Loss (RMSE): 0.0531\n",
      "curve dfNN Run 1/1, Epoch 861/4000, Training Loss (RMSE): 0.0475\n",
      "curve dfNN Run 1/1, Epoch 862/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 863/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 864/4000, Training Loss (RMSE): 0.0459\n",
      "curve dfNN Run 1/1, Epoch 865/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 866/4000, Training Loss (RMSE): 0.0582\n",
      "curve dfNN Run 1/1, Epoch 867/4000, Training Loss (RMSE): 0.0518\n",
      "curve dfNN Run 1/1, Epoch 868/4000, Training Loss (RMSE): 0.0535\n",
      "curve dfNN Run 1/1, Epoch 869/4000, Training Loss (RMSE): 0.0453\n",
      "curve dfNN Run 1/1, Epoch 870/4000, Training Loss (RMSE): 0.0500\n",
      "curve dfNN Run 1/1, Epoch 871/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 872/4000, Training Loss (RMSE): 0.0496\n",
      "curve dfNN Run 1/1, Epoch 873/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 874/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 875/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 876/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 877/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 878/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 879/4000, Training Loss (RMSE): 0.0531\n",
      "curve dfNN Run 1/1, Epoch 880/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 881/4000, Training Loss (RMSE): 0.0483\n",
      "curve dfNN Run 1/1, Epoch 882/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 883/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 884/4000, Training Loss (RMSE): 0.0548\n",
      "curve dfNN Run 1/1, Epoch 885/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 886/4000, Training Loss (RMSE): 0.0531\n",
      "curve dfNN Run 1/1, Epoch 887/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 888/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 889/4000, Training Loss (RMSE): 0.0493\n",
      "curve dfNN Run 1/1, Epoch 890/4000, Training Loss (RMSE): 0.0474\n",
      "curve dfNN Run 1/1, Epoch 891/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 892/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 893/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 894/4000, Training Loss (RMSE): 0.0503\n",
      "curve dfNN Run 1/1, Epoch 895/4000, Training Loss (RMSE): 0.0524\n",
      "curve dfNN Run 1/1, Epoch 896/4000, Training Loss (RMSE): 0.0613\n",
      "curve dfNN Run 1/1, Epoch 897/4000, Training Loss (RMSE): 0.0504\n",
      "curve dfNN Run 1/1, Epoch 898/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 899/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 900/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 901/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 902/4000, Training Loss (RMSE): 0.0453\n",
      "curve dfNN Run 1/1, Epoch 903/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 904/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 905/4000, Training Loss (RMSE): 0.0558\n",
      "curve dfNN Run 1/1, Epoch 906/4000, Training Loss (RMSE): 0.0558\n",
      "curve dfNN Run 1/1, Epoch 907/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 908/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 909/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 910/4000, Training Loss (RMSE): 0.0517\n",
      "curve dfNN Run 1/1, Epoch 911/4000, Training Loss (RMSE): 0.0485\n",
      "curve dfNN Run 1/1, Epoch 912/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 913/4000, Training Loss (RMSE): 0.0518\n",
      "curve dfNN Run 1/1, Epoch 914/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 915/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 916/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 917/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 918/4000, Training Loss (RMSE): 0.0489\n",
      "curve dfNN Run 1/1, Epoch 919/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 920/4000, Training Loss (RMSE): 0.0491\n",
      "curve dfNN Run 1/1, Epoch 921/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 922/4000, Training Loss (RMSE): 0.0483\n",
      "curve dfNN Run 1/1, Epoch 923/4000, Training Loss (RMSE): 0.0554\n",
      "curve dfNN Run 1/1, Epoch 924/4000, Training Loss (RMSE): 0.0533\n",
      "curve dfNN Run 1/1, Epoch 925/4000, Training Loss (RMSE): 0.0439\n",
      "curve dfNN Run 1/1, Epoch 926/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 927/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 928/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 929/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 930/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 931/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 932/4000, Training Loss (RMSE): 0.0454\n",
      "curve dfNN Run 1/1, Epoch 933/4000, Training Loss (RMSE): 0.0446\n",
      "curve dfNN Run 1/1, Epoch 934/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 935/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 936/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 937/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 938/4000, Training Loss (RMSE): 0.0495\n",
      "curve dfNN Run 1/1, Epoch 939/4000, Training Loss (RMSE): 0.0467\n",
      "curve dfNN Run 1/1, Epoch 940/4000, Training Loss (RMSE): 0.0494\n",
      "curve dfNN Run 1/1, Epoch 941/4000, Training Loss (RMSE): 0.0456\n",
      "curve dfNN Run 1/1, Epoch 942/4000, Training Loss (RMSE): 0.0523\n",
      "curve dfNN Run 1/1, Epoch 943/4000, Training Loss (RMSE): 0.0476\n",
      "curve dfNN Run 1/1, Epoch 944/4000, Training Loss (RMSE): 0.0501\n",
      "curve dfNN Run 1/1, Epoch 945/4000, Training Loss (RMSE): 0.0513\n",
      "curve dfNN Run 1/1, Epoch 946/4000, Training Loss (RMSE): 0.0449\n",
      "curve dfNN Run 1/1, Epoch 947/4000, Training Loss (RMSE): 0.0517\n",
      "curve dfNN Run 1/1, Epoch 948/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 949/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 950/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 951/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 952/4000, Training Loss (RMSE): 0.0423\n",
      "curve dfNN Run 1/1, Epoch 953/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 954/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 955/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 956/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 957/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 958/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 959/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 960/4000, Training Loss (RMSE): 0.0514\n",
      "curve dfNN Run 1/1, Epoch 961/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 962/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 963/4000, Training Loss (RMSE): 0.0489\n",
      "curve dfNN Run 1/1, Epoch 964/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 965/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 966/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 967/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 968/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 969/4000, Training Loss (RMSE): 0.0446\n",
      "curve dfNN Run 1/1, Epoch 970/4000, Training Loss (RMSE): 0.0387\n",
      "curve dfNN Run 1/1, Epoch 971/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 972/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 973/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 974/4000, Training Loss (RMSE): 0.0417\n",
      "curve dfNN Run 1/1, Epoch 975/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 976/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 977/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 978/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 979/4000, Training Loss (RMSE): 0.0430\n",
      "curve dfNN Run 1/1, Epoch 980/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 981/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 982/4000, Training Loss (RMSE): 0.0685\n",
      "curve dfNN Run 1/1, Epoch 983/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 984/4000, Training Loss (RMSE): 0.0599\n",
      "curve dfNN Run 1/1, Epoch 985/4000, Training Loss (RMSE): 0.0439\n",
      "curve dfNN Run 1/1, Epoch 986/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 987/4000, Training Loss (RMSE): 0.0417\n",
      "curve dfNN Run 1/1, Epoch 988/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 989/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 990/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 991/4000, Training Loss (RMSE): 0.0456\n",
      "curve dfNN Run 1/1, Epoch 992/4000, Training Loss (RMSE): 0.0487\n",
      "curve dfNN Run 1/1, Epoch 993/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 994/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 995/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 996/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 997/4000, Training Loss (RMSE): 0.0560\n",
      "curve dfNN Run 1/1, Epoch 998/4000, Training Loss (RMSE): 0.0490\n",
      "curve dfNN Run 1/1, Epoch 999/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1000/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 1001/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1002/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1003/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 1004/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1005/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1006/4000, Training Loss (RMSE): 0.0423\n",
      "curve dfNN Run 1/1, Epoch 1007/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 1008/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1009/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1010/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 1011/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1012/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1013/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1014/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1015/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1016/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1017/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1018/4000, Training Loss (RMSE): 0.0572\n",
      "curve dfNN Run 1/1, Epoch 1019/4000, Training Loss (RMSE): 0.0485\n",
      "curve dfNN Run 1/1, Epoch 1020/4000, Training Loss (RMSE): 0.0467\n",
      "curve dfNN Run 1/1, Epoch 1021/4000, Training Loss (RMSE): 0.0489\n",
      "curve dfNN Run 1/1, Epoch 1022/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1023/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 1024/4000, Training Loss (RMSE): 0.0441\n",
      "curve dfNN Run 1/1, Epoch 1025/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1026/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1027/4000, Training Loss (RMSE): 0.0449\n",
      "curve dfNN Run 1/1, Epoch 1028/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1029/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1030/4000, Training Loss (RMSE): 0.0476\n",
      "curve dfNN Run 1/1, Epoch 1031/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1032/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1033/4000, Training Loss (RMSE): 0.0500\n",
      "curve dfNN Run 1/1, Epoch 1034/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 1035/4000, Training Loss (RMSE): 0.0523\n",
      "curve dfNN Run 1/1, Epoch 1036/4000, Training Loss (RMSE): 0.0497\n",
      "curve dfNN Run 1/1, Epoch 1037/4000, Training Loss (RMSE): 0.0447\n",
      "curve dfNN Run 1/1, Epoch 1038/4000, Training Loss (RMSE): 0.0738\n",
      "curve dfNN Run 1/1, Epoch 1039/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 1040/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 1041/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1042/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1043/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 1044/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1045/4000, Training Loss (RMSE): 0.0487\n",
      "curve dfNN Run 1/1, Epoch 1046/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1047/4000, Training Loss (RMSE): 0.0475\n",
      "curve dfNN Run 1/1, Epoch 1048/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1049/4000, Training Loss (RMSE): 0.0507\n",
      "curve dfNN Run 1/1, Epoch 1050/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1051/4000, Training Loss (RMSE): 0.0493\n",
      "curve dfNN Run 1/1, Epoch 1052/4000, Training Loss (RMSE): 0.0500\n",
      "curve dfNN Run 1/1, Epoch 1053/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 1054/4000, Training Loss (RMSE): 0.0499\n",
      "curve dfNN Run 1/1, Epoch 1055/4000, Training Loss (RMSE): 0.0515\n",
      "curve dfNN Run 1/1, Epoch 1056/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 1057/4000, Training Loss (RMSE): 0.0610\n",
      "curve dfNN Run 1/1, Epoch 1058/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 1059/4000, Training Loss (RMSE): 0.0462\n",
      "curve dfNN Run 1/1, Epoch 1060/4000, Training Loss (RMSE): 0.0439\n",
      "curve dfNN Run 1/1, Epoch 1061/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1062/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1063/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1064/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1065/4000, Training Loss (RMSE): 0.0467\n",
      "curve dfNN Run 1/1, Epoch 1066/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1067/4000, Training Loss (RMSE): 0.0478\n",
      "curve dfNN Run 1/1, Epoch 1068/4000, Training Loss (RMSE): 0.0419\n",
      "curve dfNN Run 1/1, Epoch 1069/4000, Training Loss (RMSE): 0.0562\n",
      "curve dfNN Run 1/1, Epoch 1070/4000, Training Loss (RMSE): 0.0450\n",
      "curve dfNN Run 1/1, Epoch 1071/4000, Training Loss (RMSE): 0.0513\n",
      "curve dfNN Run 1/1, Epoch 1072/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1073/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1074/4000, Training Loss (RMSE): 0.0476\n",
      "curve dfNN Run 1/1, Epoch 1075/4000, Training Loss (RMSE): 0.0495\n",
      "curve dfNN Run 1/1, Epoch 1076/4000, Training Loss (RMSE): 0.0491\n",
      "curve dfNN Run 1/1, Epoch 1077/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 1078/4000, Training Loss (RMSE): 0.0504\n",
      "curve dfNN Run 1/1, Epoch 1079/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1080/4000, Training Loss (RMSE): 0.0448\n",
      "curve dfNN Run 1/1, Epoch 1081/4000, Training Loss (RMSE): 0.0501\n",
      "curve dfNN Run 1/1, Epoch 1082/4000, Training Loss (RMSE): 0.0506\n",
      "curve dfNN Run 1/1, Epoch 1083/4000, Training Loss (RMSE): 0.0497\n",
      "curve dfNN Run 1/1, Epoch 1084/4000, Training Loss (RMSE): 0.0592\n",
      "curve dfNN Run 1/1, Epoch 1085/4000, Training Loss (RMSE): 0.0470\n",
      "curve dfNN Run 1/1, Epoch 1086/4000, Training Loss (RMSE): 0.0520\n",
      "curve dfNN Run 1/1, Epoch 1087/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1088/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 1089/4000, Training Loss (RMSE): 0.0490\n",
      "curve dfNN Run 1/1, Epoch 1090/4000, Training Loss (RMSE): 0.0483\n",
      "curve dfNN Run 1/1, Epoch 1091/4000, Training Loss (RMSE): 0.0524\n",
      "curve dfNN Run 1/1, Epoch 1092/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1093/4000, Training Loss (RMSE): 0.0476\n",
      "curve dfNN Run 1/1, Epoch 1094/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1095/4000, Training Loss (RMSE): 0.0448\n",
      "curve dfNN Run 1/1, Epoch 1096/4000, Training Loss (RMSE): 0.0508\n",
      "curve dfNN Run 1/1, Epoch 1097/4000, Training Loss (RMSE): 0.0524\n",
      "curve dfNN Run 1/1, Epoch 1098/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1099/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1100/4000, Training Loss (RMSE): 0.0472\n",
      "curve dfNN Run 1/1, Epoch 1101/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1102/4000, Training Loss (RMSE): 0.0417\n",
      "curve dfNN Run 1/1, Epoch 1103/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1104/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1105/4000, Training Loss (RMSE): 0.0374\n",
      "curve dfNN Run 1/1, Epoch 1106/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1107/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1108/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1109/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1110/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1111/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1112/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1113/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 1114/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1115/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1116/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1117/4000, Training Loss (RMSE): 0.0543\n",
      "curve dfNN Run 1/1, Epoch 1118/4000, Training Loss (RMSE): 0.0478\n",
      "curve dfNN Run 1/1, Epoch 1119/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1120/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1121/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1122/4000, Training Loss (RMSE): 0.0453\n",
      "curve dfNN Run 1/1, Epoch 1123/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1124/4000, Training Loss (RMSE): 0.0518\n",
      "curve dfNN Run 1/1, Epoch 1125/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1126/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1127/4000, Training Loss (RMSE): 0.0432\n",
      "curve dfNN Run 1/1, Epoch 1128/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1129/4000, Training Loss (RMSE): 0.0446\n",
      "curve dfNN Run 1/1, Epoch 1130/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 1131/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 1132/4000, Training Loss (RMSE): 0.0512\n",
      "curve dfNN Run 1/1, Epoch 1133/4000, Training Loss (RMSE): 0.0514\n",
      "curve dfNN Run 1/1, Epoch 1134/4000, Training Loss (RMSE): 0.0551\n",
      "curve dfNN Run 1/1, Epoch 1135/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1136/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 1137/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1138/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1139/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1140/4000, Training Loss (RMSE): 0.0527\n",
      "curve dfNN Run 1/1, Epoch 1141/4000, Training Loss (RMSE): 0.0453\n",
      "curve dfNN Run 1/1, Epoch 1142/4000, Training Loss (RMSE): 0.0427\n",
      "curve dfNN Run 1/1, Epoch 1143/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1144/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1145/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1146/4000, Training Loss (RMSE): 0.0384\n",
      "curve dfNN Run 1/1, Epoch 1147/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1148/4000, Training Loss (RMSE): 0.0392\n",
      "curve dfNN Run 1/1, Epoch 1149/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1150/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1151/4000, Training Loss (RMSE): 0.0403\n",
      "curve dfNN Run 1/1, Epoch 1152/4000, Training Loss (RMSE): 0.0458\n",
      "curve dfNN Run 1/1, Epoch 1153/4000, Training Loss (RMSE): 0.0427\n",
      "curve dfNN Run 1/1, Epoch 1154/4000, Training Loss (RMSE): 0.0373\n",
      "curve dfNN Run 1/1, Epoch 1155/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1156/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1157/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1158/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1159/4000, Training Loss (RMSE): 0.0650\n",
      "curve dfNN Run 1/1, Epoch 1160/4000, Training Loss (RMSE): 0.0560\n",
      "curve dfNN Run 1/1, Epoch 1161/4000, Training Loss (RMSE): 0.0558\n",
      "curve dfNN Run 1/1, Epoch 1162/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 1163/4000, Training Loss (RMSE): 0.0488\n",
      "curve dfNN Run 1/1, Epoch 1164/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1165/4000, Training Loss (RMSE): 0.0447\n",
      "curve dfNN Run 1/1, Epoch 1166/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 1167/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1168/4000, Training Loss (RMSE): 0.0370\n",
      "curve dfNN Run 1/1, Epoch 1169/4000, Training Loss (RMSE): 0.0480\n",
      "curve dfNN Run 1/1, Epoch 1170/4000, Training Loss (RMSE): 0.0447\n",
      "curve dfNN Run 1/1, Epoch 1171/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1172/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1173/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1174/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1175/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1176/4000, Training Loss (RMSE): 0.0398\n",
      "curve dfNN Run 1/1, Epoch 1177/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1178/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1179/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 1180/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1181/4000, Training Loss (RMSE): 0.0507\n",
      "curve dfNN Run 1/1, Epoch 1182/4000, Training Loss (RMSE): 0.0493\n",
      "curve dfNN Run 1/1, Epoch 1183/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1184/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1185/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1186/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1187/4000, Training Loss (RMSE): 0.0475\n",
      "curve dfNN Run 1/1, Epoch 1188/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1189/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1190/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 1191/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 1192/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1193/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1194/4000, Training Loss (RMSE): 0.0391\n",
      "curve dfNN Run 1/1, Epoch 1195/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1196/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1197/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1198/4000, Training Loss (RMSE): 0.0500\n",
      "curve dfNN Run 1/1, Epoch 1199/4000, Training Loss (RMSE): 0.0486\n",
      "curve dfNN Run 1/1, Epoch 1200/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1201/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1202/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 1203/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1204/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 1205/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 1206/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1207/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1208/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1209/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1210/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1211/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1212/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1213/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 1214/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 1215/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1216/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1217/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1218/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 1219/4000, Training Loss (RMSE): 0.0542\n",
      "curve dfNN Run 1/1, Epoch 1220/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1221/4000, Training Loss (RMSE): 0.0377\n",
      "curve dfNN Run 1/1, Epoch 1222/4000, Training Loss (RMSE): 0.0384\n",
      "curve dfNN Run 1/1, Epoch 1223/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1224/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1225/4000, Training Loss (RMSE): 0.0387\n",
      "curve dfNN Run 1/1, Epoch 1226/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1227/4000, Training Loss (RMSE): 0.0445\n",
      "curve dfNN Run 1/1, Epoch 1228/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 1229/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1230/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1231/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1232/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1233/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1234/4000, Training Loss (RMSE): 0.0358\n",
      "curve dfNN Run 1/1, Epoch 1235/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 1236/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1237/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1238/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1239/4000, Training Loss (RMSE): 0.0522\n",
      "curve dfNN Run 1/1, Epoch 1240/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1241/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1242/4000, Training Loss (RMSE): 0.0373\n",
      "curve dfNN Run 1/1, Epoch 1243/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1244/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1245/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1246/4000, Training Loss (RMSE): 0.0492\n",
      "curve dfNN Run 1/1, Epoch 1247/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1248/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1249/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1250/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1251/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1252/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1253/4000, Training Loss (RMSE): 0.0423\n",
      "curve dfNN Run 1/1, Epoch 1254/4000, Training Loss (RMSE): 0.0386\n",
      "curve dfNN Run 1/1, Epoch 1255/4000, Training Loss (RMSE): 0.0458\n",
      "curve dfNN Run 1/1, Epoch 1256/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1257/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1258/4000, Training Loss (RMSE): 0.0480\n",
      "curve dfNN Run 1/1, Epoch 1259/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1260/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 1261/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1262/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 1263/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1264/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1265/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 1266/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1267/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1268/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1269/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1270/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1271/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1272/4000, Training Loss (RMSE): 0.0467\n",
      "curve dfNN Run 1/1, Epoch 1273/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 1274/4000, Training Loss (RMSE): 0.0430\n",
      "curve dfNN Run 1/1, Epoch 1275/4000, Training Loss (RMSE): 0.0430\n",
      "curve dfNN Run 1/1, Epoch 1276/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1277/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1278/4000, Training Loss (RMSE): 0.0419\n",
      "curve dfNN Run 1/1, Epoch 1279/4000, Training Loss (RMSE): 0.0417\n",
      "curve dfNN Run 1/1, Epoch 1280/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1281/4000, Training Loss (RMSE): 0.0480\n",
      "curve dfNN Run 1/1, Epoch 1282/4000, Training Loss (RMSE): 0.0448\n",
      "curve dfNN Run 1/1, Epoch 1283/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 1284/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1285/4000, Training Loss (RMSE): 0.0482\n",
      "curve dfNN Run 1/1, Epoch 1286/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 1287/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1288/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1289/4000, Training Loss (RMSE): 0.0520\n",
      "curve dfNN Run 1/1, Epoch 1290/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1291/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 1292/4000, Training Loss (RMSE): 0.0419\n",
      "curve dfNN Run 1/1, Epoch 1293/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1294/4000, Training Loss (RMSE): 0.0475\n",
      "curve dfNN Run 1/1, Epoch 1295/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1296/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1297/4000, Training Loss (RMSE): 0.0476\n",
      "curve dfNN Run 1/1, Epoch 1298/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 1299/4000, Training Loss (RMSE): 0.0459\n",
      "curve dfNN Run 1/1, Epoch 1300/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 1301/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1302/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1303/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1304/4000, Training Loss (RMSE): 0.0406\n",
      "curve dfNN Run 1/1, Epoch 1305/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1306/4000, Training Loss (RMSE): 0.0394\n",
      "curve dfNN Run 1/1, Epoch 1307/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1308/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1309/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1310/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1311/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1312/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1313/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1314/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1315/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1316/4000, Training Loss (RMSE): 0.0453\n",
      "curve dfNN Run 1/1, Epoch 1317/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1318/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 1319/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1320/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1321/4000, Training Loss (RMSE): 0.0441\n",
      "curve dfNN Run 1/1, Epoch 1322/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1323/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1324/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1325/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 1326/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1327/4000, Training Loss (RMSE): 0.0381\n",
      "curve dfNN Run 1/1, Epoch 1328/4000, Training Loss (RMSE): 0.0523\n",
      "curve dfNN Run 1/1, Epoch 1329/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 1330/4000, Training Loss (RMSE): 0.0506\n",
      "curve dfNN Run 1/1, Epoch 1331/4000, Training Loss (RMSE): 0.0464\n",
      "curve dfNN Run 1/1, Epoch 1332/4000, Training Loss (RMSE): 0.0403\n",
      "curve dfNN Run 1/1, Epoch 1333/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1334/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 1335/4000, Training Loss (RMSE): 0.0474\n",
      "curve dfNN Run 1/1, Epoch 1336/4000, Training Loss (RMSE): 0.0459\n",
      "curve dfNN Run 1/1, Epoch 1337/4000, Training Loss (RMSE): 0.0440\n",
      "curve dfNN Run 1/1, Epoch 1338/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 1339/4000, Training Loss (RMSE): 0.0516\n",
      "curve dfNN Run 1/1, Epoch 1340/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1341/4000, Training Loss (RMSE): 0.0634\n",
      "curve dfNN Run 1/1, Epoch 1342/4000, Training Loss (RMSE): 0.0564\n",
      "curve dfNN Run 1/1, Epoch 1343/4000, Training Loss (RMSE): 0.0456\n",
      "curve dfNN Run 1/1, Epoch 1344/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1345/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 1346/4000, Training Loss (RMSE): 0.0495\n",
      "curve dfNN Run 1/1, Epoch 1347/4000, Training Loss (RMSE): 0.0466\n",
      "curve dfNN Run 1/1, Epoch 1348/4000, Training Loss (RMSE): 0.0465\n",
      "curve dfNN Run 1/1, Epoch 1349/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1350/4000, Training Loss (RMSE): 0.0450\n",
      "curve dfNN Run 1/1, Epoch 1351/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1352/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1353/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1354/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1355/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1356/4000, Training Loss (RMSE): 0.0457\n",
      "curve dfNN Run 1/1, Epoch 1357/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1358/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1359/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1360/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1361/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1362/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 1363/4000, Training Loss (RMSE): 0.0494\n",
      "curve dfNN Run 1/1, Epoch 1364/4000, Training Loss (RMSE): 0.0473\n",
      "curve dfNN Run 1/1, Epoch 1365/4000, Training Loss (RMSE): 0.0423\n",
      "curve dfNN Run 1/1, Epoch 1366/4000, Training Loss (RMSE): 0.0430\n",
      "curve dfNN Run 1/1, Epoch 1367/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1368/4000, Training Loss (RMSE): 0.0389\n",
      "curve dfNN Run 1/1, Epoch 1369/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1370/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1371/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1372/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1373/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1374/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1375/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1376/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1377/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1378/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1379/4000, Training Loss (RMSE): 0.0439\n",
      "curve dfNN Run 1/1, Epoch 1380/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1381/4000, Training Loss (RMSE): 0.0461\n",
      "curve dfNN Run 1/1, Epoch 1382/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1383/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1384/4000, Training Loss (RMSE): 0.0389\n",
      "curve dfNN Run 1/1, Epoch 1385/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1386/4000, Training Loss (RMSE): 0.0460\n",
      "curve dfNN Run 1/1, Epoch 1387/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1388/4000, Training Loss (RMSE): 0.0343\n",
      "curve dfNN Run 1/1, Epoch 1389/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1390/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1391/4000, Training Loss (RMSE): 0.0355\n",
      "curve dfNN Run 1/1, Epoch 1392/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 1393/4000, Training Loss (RMSE): 0.0377\n",
      "curve dfNN Run 1/1, Epoch 1394/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1395/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1396/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 1397/4000, Training Loss (RMSE): 0.0491\n",
      "curve dfNN Run 1/1, Epoch 1398/4000, Training Loss (RMSE): 0.0488\n",
      "curve dfNN Run 1/1, Epoch 1399/4000, Training Loss (RMSE): 0.0405\n",
      "curve dfNN Run 1/1, Epoch 1400/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1401/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 1402/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1403/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1404/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1405/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1406/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1407/4000, Training Loss (RMSE): 0.0392\n",
      "curve dfNN Run 1/1, Epoch 1408/4000, Training Loss (RMSE): 0.0384\n",
      "curve dfNN Run 1/1, Epoch 1409/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1410/4000, Training Loss (RMSE): 0.0384\n",
      "curve dfNN Run 1/1, Epoch 1411/4000, Training Loss (RMSE): 0.0416\n",
      "curve dfNN Run 1/1, Epoch 1412/4000, Training Loss (RMSE): 0.0443\n",
      "curve dfNN Run 1/1, Epoch 1413/4000, Training Loss (RMSE): 0.0508\n",
      "curve dfNN Run 1/1, Epoch 1414/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1415/4000, Training Loss (RMSE): 0.0477\n",
      "curve dfNN Run 1/1, Epoch 1416/4000, Training Loss (RMSE): 0.0456\n",
      "curve dfNN Run 1/1, Epoch 1417/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1418/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 1419/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1420/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1421/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1422/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1423/4000, Training Loss (RMSE): 0.0452\n",
      "curve dfNN Run 1/1, Epoch 1424/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 1425/4000, Training Loss (RMSE): 0.0372\n",
      "curve dfNN Run 1/1, Epoch 1426/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1427/4000, Training Loss (RMSE): 0.0387\n",
      "curve dfNN Run 1/1, Epoch 1428/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1429/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1430/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1431/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1432/4000, Training Loss (RMSE): 0.0427\n",
      "curve dfNN Run 1/1, Epoch 1433/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1434/4000, Training Loss (RMSE): 0.0419\n",
      "curve dfNN Run 1/1, Epoch 1435/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1436/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1437/4000, Training Loss (RMSE): 0.0471\n",
      "curve dfNN Run 1/1, Epoch 1438/4000, Training Loss (RMSE): 0.0501\n",
      "curve dfNN Run 1/1, Epoch 1439/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1440/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 1441/4000, Training Loss (RMSE): 0.0451\n",
      "curve dfNN Run 1/1, Epoch 1442/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1443/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1444/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1445/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1446/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1447/4000, Training Loss (RMSE): 0.0367\n",
      "curve dfNN Run 1/1, Epoch 1448/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1449/4000, Training Loss (RMSE): 0.0447\n",
      "curve dfNN Run 1/1, Epoch 1450/4000, Training Loss (RMSE): 0.0380\n",
      "curve dfNN Run 1/1, Epoch 1451/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1452/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1453/4000, Training Loss (RMSE): 0.0394\n",
      "curve dfNN Run 1/1, Epoch 1454/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1455/4000, Training Loss (RMSE): 0.0610\n",
      "curve dfNN Run 1/1, Epoch 1456/4000, Training Loss (RMSE): 0.0511\n",
      "curve dfNN Run 1/1, Epoch 1457/4000, Training Loss (RMSE): 0.0458\n",
      "curve dfNN Run 1/1, Epoch 1458/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1459/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1460/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 1461/4000, Training Loss (RMSE): 0.0436\n",
      "curve dfNN Run 1/1, Epoch 1462/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1463/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1464/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1465/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1466/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1467/4000, Training Loss (RMSE): 0.0499\n",
      "curve dfNN Run 1/1, Epoch 1468/4000, Training Loss (RMSE): 0.0546\n",
      "curve dfNN Run 1/1, Epoch 1469/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1470/4000, Training Loss (RMSE): 0.0394\n",
      "curve dfNN Run 1/1, Epoch 1471/4000, Training Loss (RMSE): 0.0380\n",
      "curve dfNN Run 1/1, Epoch 1472/4000, Training Loss (RMSE): 0.0377\n",
      "curve dfNN Run 1/1, Epoch 1473/4000, Training Loss (RMSE): 0.0472\n",
      "curve dfNN Run 1/1, Epoch 1474/4000, Training Loss (RMSE): 0.0463\n",
      "curve dfNN Run 1/1, Epoch 1475/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1476/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1477/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1478/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1479/4000, Training Loss (RMSE): 0.0410\n",
      "curve dfNN Run 1/1, Epoch 1480/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1481/4000, Training Loss (RMSE): 0.0419\n",
      "curve dfNN Run 1/1, Epoch 1482/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1483/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1484/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1485/4000, Training Loss (RMSE): 0.0415\n",
      "curve dfNN Run 1/1, Epoch 1486/4000, Training Loss (RMSE): 0.0458\n",
      "curve dfNN Run 1/1, Epoch 1487/4000, Training Loss (RMSE): 0.0507\n",
      "curve dfNN Run 1/1, Epoch 1488/4000, Training Loss (RMSE): 0.0510\n",
      "curve dfNN Run 1/1, Epoch 1489/4000, Training Loss (RMSE): 0.0617\n",
      "curve dfNN Run 1/1, Epoch 1490/4000, Training Loss (RMSE): 0.0504\n",
      "curve dfNN Run 1/1, Epoch 1491/4000, Training Loss (RMSE): 0.0446\n",
      "curve dfNN Run 1/1, Epoch 1492/4000, Training Loss (RMSE): 0.0468\n",
      "curve dfNN Run 1/1, Epoch 1493/4000, Training Loss (RMSE): 0.0507\n",
      "curve dfNN Run 1/1, Epoch 1494/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1495/4000, Training Loss (RMSE): 0.0407\n",
      "curve dfNN Run 1/1, Epoch 1496/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1497/4000, Training Loss (RMSE): 0.0422\n",
      "curve dfNN Run 1/1, Epoch 1498/4000, Training Loss (RMSE): 0.0430\n",
      "curve dfNN Run 1/1, Epoch 1499/4000, Training Loss (RMSE): 0.0455\n",
      "curve dfNN Run 1/1, Epoch 1500/4000, Training Loss (RMSE): 0.0442\n",
      "curve dfNN Run 1/1, Epoch 1501/4000, Training Loss (RMSE): 0.0431\n",
      "curve dfNN Run 1/1, Epoch 1502/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1503/4000, Training Loss (RMSE): 0.0523\n",
      "curve dfNN Run 1/1, Epoch 1504/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1505/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1506/4000, Training Loss (RMSE): 0.0379\n",
      "curve dfNN Run 1/1, Epoch 1507/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1508/4000, Training Loss (RMSE): 0.0450\n",
      "curve dfNN Run 1/1, Epoch 1509/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1510/4000, Training Loss (RMSE): 0.0421\n",
      "curve dfNN Run 1/1, Epoch 1511/4000, Training Loss (RMSE): 0.0392\n",
      "curve dfNN Run 1/1, Epoch 1512/4000, Training Loss (RMSE): 0.0455\n",
      "curve dfNN Run 1/1, Epoch 1513/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1514/4000, Training Loss (RMSE): 0.0449\n",
      "curve dfNN Run 1/1, Epoch 1515/4000, Training Loss (RMSE): 0.0412\n",
      "curve dfNN Run 1/1, Epoch 1516/4000, Training Loss (RMSE): 0.0386\n",
      "curve dfNN Run 1/1, Epoch 1517/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1518/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1519/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1520/4000, Training Loss (RMSE): 0.0387\n",
      "curve dfNN Run 1/1, Epoch 1521/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1522/4000, Training Loss (RMSE): 0.0374\n",
      "curve dfNN Run 1/1, Epoch 1523/4000, Training Loss (RMSE): 0.0357\n",
      "curve dfNN Run 1/1, Epoch 1524/4000, Training Loss (RMSE): 0.0456\n",
      "curve dfNN Run 1/1, Epoch 1525/4000, Training Loss (RMSE): 0.0435\n",
      "curve dfNN Run 1/1, Epoch 1526/4000, Training Loss (RMSE): 0.0483\n",
      "curve dfNN Run 1/1, Epoch 1527/4000, Training Loss (RMSE): 0.0490\n",
      "curve dfNN Run 1/1, Epoch 1528/4000, Training Loss (RMSE): 0.0434\n",
      "curve dfNN Run 1/1, Epoch 1529/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 1530/4000, Training Loss (RMSE): 0.0408\n",
      "curve dfNN Run 1/1, Epoch 1531/4000, Training Loss (RMSE): 0.0414\n",
      "curve dfNN Run 1/1, Epoch 1532/4000, Training Loss (RMSE): 0.0365\n",
      "curve dfNN Run 1/1, Epoch 1533/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1534/4000, Training Loss (RMSE): 0.0397\n",
      "curve dfNN Run 1/1, Epoch 1535/4000, Training Loss (RMSE): 0.0404\n",
      "curve dfNN Run 1/1, Epoch 1536/4000, Training Loss (RMSE): 0.0396\n",
      "curve dfNN Run 1/1, Epoch 1537/4000, Training Loss (RMSE): 0.0376\n",
      "curve dfNN Run 1/1, Epoch 1538/4000, Training Loss (RMSE): 0.0426\n",
      "curve dfNN Run 1/1, Epoch 1539/4000, Training Loss (RMSE): 0.0399\n",
      "curve dfNN Run 1/1, Epoch 1540/4000, Training Loss (RMSE): 0.0394\n",
      "curve dfNN Run 1/1, Epoch 1541/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1542/4000, Training Loss (RMSE): 0.0366\n",
      "curve dfNN Run 1/1, Epoch 1543/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 1544/4000, Training Loss (RMSE): 0.0437\n",
      "curve dfNN Run 1/1, Epoch 1545/4000, Training Loss (RMSE): 0.0429\n",
      "curve dfNN Run 1/1, Epoch 1546/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1547/4000, Training Loss (RMSE): 0.0361\n",
      "curve dfNN Run 1/1, Epoch 1548/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1549/4000, Training Loss (RMSE): 0.0418\n",
      "curve dfNN Run 1/1, Epoch 1550/4000, Training Loss (RMSE): 0.0383\n",
      "curve dfNN Run 1/1, Epoch 1551/4000, Training Loss (RMSE): 0.0409\n",
      "curve dfNN Run 1/1, Epoch 1552/4000, Training Loss (RMSE): 0.0402\n",
      "curve dfNN Run 1/1, Epoch 1553/4000, Training Loss (RMSE): 0.0428\n",
      "curve dfNN Run 1/1, Epoch 1554/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1555/4000, Training Loss (RMSE): 0.0493\n",
      "curve dfNN Run 1/1, Epoch 1556/4000, Training Loss (RMSE): 0.0531\n",
      "curve dfNN Run 1/1, Epoch 1557/4000, Training Loss (RMSE): 0.0417\n",
      "curve dfNN Run 1/1, Epoch 1558/4000, Training Loss (RMSE): 0.0507\n",
      "curve dfNN Run 1/1, Epoch 1559/4000, Training Loss (RMSE): 0.0401\n",
      "curve dfNN Run 1/1, Epoch 1560/4000, Training Loss (RMSE): 0.0458\n",
      "curve dfNN Run 1/1, Epoch 1561/4000, Training Loss (RMSE): 0.0469\n",
      "curve dfNN Run 1/1, Epoch 1562/4000, Training Loss (RMSE): 0.0398\n",
      "curve dfNN Run 1/1, Epoch 1563/4000, Training Loss (RMSE): 0.0424\n",
      "curve dfNN Run 1/1, Epoch 1564/4000, Training Loss (RMSE): 0.0433\n",
      "curve dfNN Run 1/1, Epoch 1565/4000, Training Loss (RMSE): 0.0420\n",
      "curve dfNN Run 1/1, Epoch 1566/4000, Training Loss (RMSE): 0.0472\n",
      "curve dfNN Run 1/1, Epoch 1567/4000, Training Loss (RMSE): 0.0438\n",
      "curve dfNN Run 1/1, Epoch 1568/4000, Training Loss (RMSE): 0.0521\n",
      "curve dfNN Run 1/1, Epoch 1569/4000, Training Loss (RMSE): 0.0467\n",
      "curve dfNN Run 1/1, Epoch 1570/4000, Training Loss (RMSE): 0.0479\n",
      "curve dfNN Run 1/1, Epoch 1571/4000, Training Loss (RMSE): 0.0388\n",
      "curve dfNN Run 1/1, Epoch 1572/4000, Training Loss (RMSE): 0.0370\n",
      "curve dfNN Run 1/1, Epoch 1573/4000, Training Loss (RMSE): 0.0384\n",
      "curve dfNN Run 1/1, Epoch 1574/4000, Training Loss (RMSE): 0.0371\n",
      "curve dfNN Run 1/1, Epoch 1575/4000, Training Loss (RMSE): 0.0390\n",
      "curve dfNN Run 1/1, Epoch 1576/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1577/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1578/4000, Training Loss (RMSE): 0.0375\n",
      "curve dfNN Run 1/1, Epoch 1579/4000, Training Loss (RMSE): 0.0411\n",
      "curve dfNN Run 1/1, Epoch 1580/4000, Training Loss (RMSE): 0.0444\n",
      "curve dfNN Run 1/1, Epoch 1581/4000, Training Loss (RMSE): 0.0400\n",
      "curve dfNN Run 1/1, Epoch 1582/4000, Training Loss (RMSE): 0.0395\n",
      "curve dfNN Run 1/1, Epoch 1583/4000, Training Loss (RMSE): 0.0425\n",
      "curve dfNN Run 1/1, Epoch 1584/4000, Training Loss (RMSE): 0.0393\n",
      "curve dfNN Run 1/1, Epoch 1585/4000, Training Loss (RMSE): 0.0413\n",
      "curve dfNN Run 1/1, Epoch 1586/4000, Training Loss (RMSE): 0.0406\n",
      "curve dfNN Run 1/1, Epoch 1587/4000, Training Loss (RMSE): 0.0382\n",
      "curve dfNN Run 1/1, Epoch 1588/4000, Training Loss (RMSE): 0.0406\n",
      "Early stopping triggered after 1588 epochs.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dfNN\"\n",
    "\n",
    "# import configs to we can access the hypers with getattr\n",
    "import configs\n",
    "from configs import PATIENCE, MAX_NUM_EPOCHS, NUM_RUNS, WEIGHT_DECAY\n",
    "# also import x_test grid size and std noise for training data\n",
    "from configs import N_SIDE, STD_GAUSSIAN_NOISE\n",
    "\n",
    "# Reiterating import for visibility\n",
    "MAX_NUM_EPOCHS = MAX_NUM_EPOCHS\n",
    "MAX_NUM_EPOCHS = 4000\n",
    "NUM_RUNS = NUM_RUNS\n",
    "WEIGHT_DECAY = WEIGHT_DECAY\n",
    "PATIENCE = PATIENCE\n",
    "\n",
    "# TODO: Delete overwrite, run full\n",
    "NUM_RUNS = 1\n",
    "\n",
    "# assign model-specific variable\n",
    "MODEL_LEARNING_RATE = getattr(configs, f\"{model_name}_SIM_LEARNING_RATE\")\n",
    "MODEL_SIM_RESULTS_DIR = getattr(configs, f\"{model_name}_SIM_RESULTS_DIR\")\n",
    "import os\n",
    "os.makedirs(MODEL_SIM_RESULTS_DIR, exist_ok = True)\n",
    "\n",
    "# for all models with NN components train on batches\n",
    "if model_name in [\"dfNGP\", \"dfNN\", \"PINN\"]:\n",
    "    from configs import BATCH_SIZE\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "if model_name in [\"dfNGP\", \"dfNN\"]:\n",
    "    from NN_models import dfNN\n",
    "\n",
    "# universals \n",
    "from metrics import compute_RMSE, compute_MAE, compute_divergence_field\n",
    "\n",
    "# basics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# utilitarian\n",
    "from utils import set_seed, make_grid\n",
    "# reproducibility\n",
    "set_seed(42)\n",
    "import gc\n",
    "\n",
    "# setting device to GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# overwrite if needed: # device = 'cpu'\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "### START TIMING ###\n",
    "import time\n",
    "start_time = time.time()  # Start timing after imports\n",
    "\n",
    "### SIMULATION ###\n",
    "# Import all simulation functions\n",
    "from simulate import (\n",
    "    simulate_detailed_curve,\n",
    ")\n",
    "\n",
    "# Define simulations as a dictionary with names as keys to function objects\n",
    "# alphabectic order here\n",
    "simulations = {\n",
    "    \"curve\": simulate_detailed_curve,\n",
    "}\n",
    "\n",
    "########################\n",
    "### x_train & x_test ###\n",
    "########################\n",
    "\n",
    "# Load training inputs (once for all simulations)\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised_0to1.pt\", weights_only = False).float()\n",
    "\n",
    "# Generate x_test (grid) once for all simulations\n",
    "x_test_grid, x_test = make_grid(N_SIDE)\n",
    "# x_test is long format (N_SIDE ** 2, 2)\n",
    "\n",
    "#################################\n",
    "### LOOP 1 - over SIMULATIONS ###\n",
    "#################################\n",
    "\n",
    "# Make y_train_dict: Iterate over all simulation functions\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    ########################\n",
    "    ### y_train & y_test ###\n",
    "    ########################\n",
    "\n",
    "    # Generate training observations\n",
    "    # NOTE: sim_func() needs to be on CPU, so we move x_train to CPU\n",
    "    y_train = sim_func(x_train.cpu()).to(device)\n",
    "    y_test = sim_func(x_test.cpu()).to(device)\n",
    "    \n",
    "    x_test = x_test.to(device)\n",
    "    x_train = x_train.to(device)\n",
    "    \n",
    "    # Print details\n",
    "    print(f\"=== {sim_name.upper()} ===\")\n",
    "    print(f\"Training inputs shape: {x_train.shape}\")\n",
    "    print(f\"Training observations shape: {y_train.shape}\")\n",
    "    print(f\"Training inputs dtype: {x_train.dtype}\")\n",
    "    print(f\"Training inputs device: {y_train.device}\")\n",
    "    print(f\"Training observations device: {y_train.device}\")\n",
    "    print()\n",
    "\n",
    "    # Print details\n",
    "    print(f\"=== {sim_name.upper()} ===\")\n",
    "    print(f\"Test inputs shape: {x_test.shape}\")\n",
    "    print(f\"Test observations shape: {y_test.shape}\")\n",
    "    print(f\"Test inputs dtype: {x_test.dtype}\")\n",
    "    print(f\"Test inputs device: {x_test.device}\")\n",
    "    print(f\"Test observations device: {y_test.device}\")\n",
    "    print()\n",
    "\n",
    "    # NOTE: This is different to the real data experiments\n",
    "    # calculate the mean magnitude of the test data as we use this to scale the noise\n",
    "    sim_mean_magnitude_for_noise = torch.norm(y_test, dim = -1).mean().to(device)\n",
    "    sim_noise = STD_GAUSSIAN_NOISE * sim_mean_magnitude_for_noise\n",
    "\n",
    "    # Store metrics for the simulation (used for *metrics_summary* report and *metrics_per_run*)\n",
    "    simulation_results = [] \n",
    "\n",
    "    ##################################\n",
    "    ### LOOP 2 - over training run ###\n",
    "    ##################################\n",
    "\n",
    "    for run in range(NUM_RUNS):\n",
    "\n",
    "        print(f\"\\n--- Training Run {run + 1}/{NUM_RUNS} ---\")\n",
    "\n",
    "        # Add Noise before data loader is defined\n",
    "        y_train_noisy = y_train.to(device) + (torch.randn(y_train.shape, device = device) * sim_noise)\n",
    "\n",
    "        # convert to DataLoader for batching\n",
    "        # NOTE: For the simulated experiments we use noisy data\n",
    "        dataset = TensorDataset(x_train, y_train_noisy)\n",
    "        # now giving it all test data to see if it converges then\n",
    "        # dataset = TensorDataset(x_test, y_test)\n",
    "        dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "        # initialise new model for run (seeded so this is reproducible)\n",
    "        dfNN_model = dfNN().to(device)\n",
    "        dfNN_model.train()\n",
    "\n",
    "        # define loss function (MSE for regression)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # AdamW as optimizer for some regularisation/weight decay\n",
    "        optimizer = optim.AdamW(dfNN_model.parameters(), lr = MODEL_LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "\n",
    "        # _________________\n",
    "        # BEFORE EPOCH LOOP\n",
    "        \n",
    "        # Export the convergence just for first run only\n",
    "        if run == 0:\n",
    "            # initialise tensors to store losses over epochs (for convergence plot)\n",
    "            train_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS) # by-product\n",
    "            test_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "\n",
    "        # Early stopping variables\n",
    "        best_loss = float('inf')\n",
    "        # counter starts at 0\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        ############################\n",
    "        ### LOOP 3 - over EPOCHS ###\n",
    "        ############################\n",
    "        print(\"\\nStart Training\")\n",
    "\n",
    "        for epoch in range(MAX_NUM_EPOCHS):\n",
    "\n",
    "            # accumulate losses over batches for each epoch \n",
    "            train_losses_RMSE_over_batches = 0.0\n",
    "\n",
    "            #############################\n",
    "            ### LOOP 4 - over BATCHES ###\n",
    "            #############################\n",
    "\n",
    "            for batch in dataloader:\n",
    "\n",
    "                # set model to training mode\n",
    "                dfNN_model.train()\n",
    "\n",
    "                x_batch, y_batch = batch\n",
    "                # put on GPU if available\n",
    "                # NOTE: requires_grad_() is used to compute gradients for the input\n",
    "                x_batch, y_batch = x_batch.to(device).requires_grad_(), y_batch.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                # NOTE: We used to do this with vmaps, but now we do it with the model directly (not faster)\n",
    "                y_pred_batch, _ = dfNN_model(x_batch)\n",
    "\n",
    "                # Compute loss (RMSE for same units as data) \n",
    "                loss = torch.sqrt(criterion(y_pred_batch, y_batch)) \n",
    "\n",
    "                # Add losses to the epoch loss (over batches)\n",
    "                train_losses_RMSE_over_batches += loss.item()\n",
    "\n",
    "                # backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            ###############################\n",
    "            ### END LOOP 4 over BATCHES ###\n",
    "            ###############################\n",
    "            \n",
    "            # for every epoch...\n",
    "\n",
    "            dfNN_model.eval()\n",
    "\n",
    "            # Compute average loss for the epoch (e.g. 7 batches / epoch)\n",
    "            avg_train_loss_RMSE_for_epoch = train_losses_RMSE_over_batches / len(dataloader)\n",
    "\n",
    "            # Print for epoch\n",
    "            print(f\"{sim_name} {model_name} Run {run + 1}/{NUM_RUNS}, Epoch {epoch + 1}/{MAX_NUM_EPOCHS}, Training Loss (RMSE): {avg_train_loss_RMSE_for_epoch:.4f}\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if avg_train_loss_RMSE_for_epoch < best_loss:\n",
    "                best_loss = avg_train_loss_RMSE_for_epoch\n",
    "                epochs_no_improve = 0  # reset counter\n",
    "                best_model_state = dfNN_model.state_dict()  # save best model\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "            # For Run 1 we save a bunch of metrics, while for the rest we only update (above)\n",
    "            if run == 0:\n",
    "\n",
    "                # Train \n",
    "                # NOTE: We do this again because we want to pass through the full dataset, not just batches\n",
    "                y_train_pred, H_train = dfNN_model(x_train.to(device).requires_grad_())\n",
    "                # Compute train loss for loss convergence plot\n",
    "                train_rmse_loss = torch.sqrt(criterion(y_train_pred, y_train.to(device))).item()\n",
    "                # TODO: Maybe detach here\n",
    "\n",
    "                # Test \n",
    "                # No batches, but full dataset\n",
    "                y_test_pred, H_test = dfNN_model(x_test.to(device).requires_grad_())\n",
    "                test_rmse_loss = torch.sqrt(criterion(y_test_pred, y_test.to(device))).item()\n",
    "\n",
    "                train_losses_RMSE_over_epochs[epoch] = train_rmse_loss\n",
    "                test_losses_RMSE_over_epochs[epoch] = test_rmse_loss\n",
    "\n",
    "        ##############################\n",
    "        ### END LOOP 3 over EPOCHS ###\n",
    "        ##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0dd8a",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "The training loss ceiling is around 0.22\n",
    "On train we do converge to close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate_detailed_curve\n",
    "from utils import make_grid\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6270d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long grid\n",
    "_, x_grid = make_grid(N_SIDE)\n",
    "\n",
    "vector_field, psi, psi_vector_field, simulated_vector_field = simulate_detailed_curve(x_test.cpu(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symplectic_field_of_merge(x):\n",
    "    comp1 = ((x[:, 1] + 0.5)**3 / 3)\n",
    "    comp2 = torch.cos(x[:, 0] * torch.pi) / torch.pi\n",
    "\n",
    "    return comp1 + comp2\n",
    "\n",
    "H_merge = symplectic_field_of_merge(x_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(H_merge.reshape(20, 20).cpu().detach().numpy())\n",
    "# plt.imshow(psi.reshape(20, 20).cpu().detach().numpy())\n",
    "H_sim = 0.2 * psi + 0.8 * H_merge\n",
    "plt.imshow(H_sim.reshape(20, 20).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5334e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(H_test.reshape(20, 20).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"H_test mean and std\")\n",
    "print(H_test.mean().item(), H_test.std().item())\n",
    "# print(pred_v.norm(dim=1).mean().item())\n",
    "\n",
    "print(\"H_test min and max\")\n",
    "print(H_test.min().item(), H_test.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41aae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "import numpy as np\n",
    "\n",
    "from utils import make_grid\n",
    "x_grid_sq, x_grid = make_grid(N_SIDE)\n",
    "\n",
    "# x_grid: [400, 2], assumed to be on a regular 20x20 grid\n",
    "# H_test: [400, 1]\n",
    "# Make sure to detach everything from the computation graph\n",
    "H_vals = H_test.view(20, 20).cpu().detach().numpy()\n",
    "\n",
    "# Recover grid for plotting\n",
    "x = x_grid[:, 0].view(20, 20).cpu().numpy()\n",
    "y = x_grid[:, 1].view(20, 20).cpu().numpy()\n",
    "\n",
    "# 3D Surface Plot\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(x, y, H_vals, cmap='viridis')\n",
    "ax.set_title(\"Scalar Potential H(x, y)\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"H(x, y)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
