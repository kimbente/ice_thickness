{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8781eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from gpytorch_models import dfRBFKernel\n",
    "\n",
    "import linear_operator\n",
    "from linear_operator import to_linear_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d817e3b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "047b1410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device to GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# overwrite if needed: # device = 'cpu'\n",
    "print('Using device:', device)\n",
    "\n",
    "region_name = \"region_lower_byrd\"\n",
    "\n",
    "# define paths based on region_name\n",
    "path_to_training_tensor = \"data/real_data/\" + region_name + \"_train_tensor.pt\"\n",
    "path_to_test_tensor = \"data/real_data/\" + region_name + \"_test_tensor.pt\"\n",
    "\n",
    "# load and tranpose to have rows as points\n",
    "train = torch.load(path_to_training_tensor, weights_only = False).T \n",
    "test = torch.load(path_to_test_tensor, weights_only = False).T\n",
    "\n",
    "# train\n",
    "x_train = train[:, [0, 1]].to(device)\n",
    "y_train = train[:, [3, 4]].to(device)\n",
    "\n",
    "# test\n",
    "x_test = test[:, [0, 1]].to(device)\n",
    "y_test = test[:, [3, 4]].to(device)\n",
    "\n",
    "scalar = 25\n",
    "x_train = x_train * scalar\n",
    "x_test = x_test * scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65d775d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6900, 0.5000], device='cuda:0', grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel = dfRBFKernel().to(device)\n",
    "# Remember that these will be squared\n",
    "kernel.lengthscale = torch.tensor([0.69, 0.5], device = device) * 1\n",
    "print(kernel.lengthscale)\n",
    "\n",
    "K_train_train = kernel(x_train, x_train).evaluate()\n",
    "K_test_test = kernel(x_test, x_test).evaluate()\n",
    "K_train_test = kernel(x_train, x_test).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd2d31ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000,      0.0000,      0.0000,      0.0000],\n",
       "        [     0.0000,      0.0000,      0.0000,      0.0000],\n",
       "        [    -0.0000,      0.0000,     -0.0000,      0.0000],\n",
       "        [     0.0000,     -0.0000,      0.0000,     -0.0000]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision = 4, sci_mode = False)\n",
    "K_train_test[0:4, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66c21105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "torch.allclose(K_train_train, K_train_train.T, atol = 1e-4)\n",
    "print((K_train_train - K_train_train.T).max().item())\n",
    "\n",
    "torch.allclose(K_test_test, K_test_test.T, atol = 1e-4)\n",
    "print((K_test_test - K_test_test.T).max().item())\n",
    "# K_train test is not meant to be symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788157e",
   "metadata": {},
   "source": [
    "# Inference in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8a573f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_scalar = 20\n",
    "K_train_train = K_train_train * output_scalar\n",
    "K_test_test = K_test_test * output_scalar\n",
    "K_train_test = K_train_test * output_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75eb4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "80.00000762939453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9.5465, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure symmetric + PSD: add jitter for numerical stability\n",
    "K_train_train_jittered = K_train_train + 1e-2 * torch.eye(K_train_train.shape[0], device=device)\n",
    "\n",
    "# Cholesky factor (L @ L.T = K_train_train)\n",
    "L = torch.linalg.cholesky(K_train_train_jittered)\n",
    "\n",
    "# Flatten target: shape (N * T, 1)\n",
    "y_train_flat_interleaved = y_train.reshape(-1, 1)\n",
    "\n",
    "# Solve (K + σ²I)⁻¹ y via Cholesky\n",
    "alpha = torch.cholesky_solve(y_train_flat_interleaved, L, upper=False)\n",
    "\n",
    "# Predictive mean: K_*^T @ α\n",
    "K_test_train = K_train_test.transpose(-2, -1)  # shape (M*T, N*T)\n",
    "predictive_mean = torch.matmul(K_test_train, alpha).squeeze(-1)  # shape (M*T,)\n",
    "\n",
    "# Predictive covariance: K_ss - v.T @ v\n",
    "v = torch.linalg.solve_triangular(L, K_train_test, upper=False)\n",
    "predictive_covariance = K_test_test - torch.matmul(v.transpose(-2, -1), v)\n",
    "\n",
    "print((predictive_covariance - predictive_covariance.T).max().item())\n",
    "print(predictive_covariance.max().item())\n",
    "\n",
    "predictive_distribution = gpytorch.distributions.MultitaskMultivariateNormal(\n",
    "    mean = predictive_mean.reshape(-1, 2),\n",
    "    covariance_matrix = predictive_covariance\n",
    ")\n",
    "\n",
    "gpytorch.metrics.negative_log_predictive_density(\n",
    "    predictive_distribution, y_test.to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66919228",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_train\n",
    "x2 = x_train\n",
    "\n",
    "# Extract the chosen device\n",
    "device = x1.device\n",
    "\n",
    "N = x1.shape[0]\n",
    "M = x2.shape[0]\n",
    "\n",
    "# Extract both lengthscales\n",
    "l1, l2 = kernel.lengthscale[0], kernel.lengthscale[1]\n",
    "\n",
    "# STEP 1: Pairwise differences of shape [N, M, 2]\n",
    "# Expand row_tensor [N, 2] -> [N, 1, 2] and column_tensor [M, 2] -> [1, M, 2]\n",
    "diff = (x1[:, None, :] - x2[None, :, :]).to(device)\n",
    "\n",
    "# Extract the relative components (columns of diff) for convenience, matching paper notation\n",
    "r1 = diff[:, :, 0]\n",
    "r2 = diff[:, :, 1]\n",
    "\n",
    "K_uu = to_linear_operator(((1 - (r2**2 / l2**2)) / l2**2).contiguous())\n",
    "K_uv = to_linear_operator(((r1 * r2) / (l1**2 * l2**2)).contiguous())\n",
    "K_vu = K_uv\n",
    "K_vv = to_linear_operator(((1 - (r1**2 / l1**2)) / l1**2).contiguous())\n",
    "\n",
    "# STEP 3: RBF/SE envelope (elementwise) (shape N × M)\n",
    "# NOTE: If column_tensor == row_tensor, the diagonal elements will be 1\n",
    "exp_term = to_linear_operator(torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2)).contiguous()).to(device)\n",
    "\n",
    "# STEP 4: Combine and stack\n",
    "# Final scaled components (each shape N × M)\n",
    "K_uu = K_uu * exp_term\n",
    "K_uv = K_uv * exp_term\n",
    "K_vu = K_vu * exp_term\n",
    "K_vv = K_vv * exp_term\n",
    "\n",
    "### Step 1: Create inticators for \"interleaving\" Kronecker product\n",
    "K_uu_indicator = torch.zeros(2, 2).to(device)\n",
    "K_uu_indicator[0, 0] = 1.0\n",
    "K_uu_indicator_lo = to_linear_operator(K_uu_indicator)\n",
    "\n",
    "K_uv_indicator = torch.zeros(2, 2).to(device)\n",
    "K_uv_indicator[0, 1] = 1.0\n",
    "K_uv_indicator_lo = to_linear_operator(K_uv_indicator)\n",
    "\n",
    "K_vu_indicator = torch.zeros(2, 2).to(device)\n",
    "K_vu_indicator[1, 0] = 1.0\n",
    "K_vu_indicator_lo = to_linear_operator(K_vu_indicator)\n",
    "\n",
    "K_vv_indicator = torch.zeros(2, 2).to(device)\n",
    "K_vv_indicator[1, 1] = 1.0\n",
    "K_vv_indicator_lo = to_linear_operator(K_vv_indicator)\n",
    "\n",
    "# Step 2: Create Kronecker product linear operators\n",
    "K_uu_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_uu,\n",
    "    K_uu_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_uv_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_uv,\n",
    "    K_uv_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_vu_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_vu,\n",
    "    K_vu_indicator_lo, # NOTE: The order is important here, it is not\n",
    ")\n",
    "\n",
    "K_vv_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_vv,\n",
    "    K_vv_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_interleaved = K_uu_expand + K_uv_expand + K_vu_expand + K_vv_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b9ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (x1[:, None, :] - x2[None, :, :]).to(device)\n",
    "\n",
    "# Extract the relative components (columns of diff) for convenience, matching paper notation\n",
    "r1 = diff[:, :, 0]\n",
    "r2 = diff[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44e2e8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(K_interleaved.to_dense() - K_interleaved.to_dense()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe46add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0011,  0.0002,  ..., -0.0006, -0.0014, -0.0019],\n",
       "        [ 0.0011,  0.0000,  0.0096,  ..., -0.0088, -0.0079, -0.0054],\n",
       "        [ 0.0002,  0.0096,  0.0000,  ...,  0.0021,  0.0051,  0.0071],\n",
       "        ...,\n",
       "        [-0.0006, -0.0088,  0.0021,  ...,  0.0000, -0.0028, -0.0061],\n",
       "        [-0.0014, -0.0079,  0.0051,  ..., -0.0028,  0.0000, -0.0011],\n",
       "        [-0.0019, -0.0054,  0.0071,  ..., -0.0061, -0.0011,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_uv.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db37a412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0014,  0.0000, -0.0019],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0011,  0.0000,  ..., -0.0079,  0.0000, -0.0054],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0019,  0.0000,  ..., -0.0011,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<MatmulBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_uv_expand.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae71993a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0011,  0.0002,  ..., -0.0006, -0.0014, -0.0019],\n",
       "        [ 0.0011,  0.0000,  0.0096,  ..., -0.0088, -0.0079, -0.0054],\n",
       "        [ 0.0002,  0.0096,  0.0000,  ...,  0.0021,  0.0051,  0.0071],\n",
       "        ...,\n",
       "        [-0.0006, -0.0088,  0.0021,  ...,  0.0000, -0.0028, -0.0061],\n",
       "        [-0.0014, -0.0079,  0.0051,  ..., -0.0028,  0.0000, -0.0011],\n",
       "        [-0.0019, -0.0054,  0.0071,  ..., -0.0061, -0.0011,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_vu.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ae95ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.1004, 0.0019,  ..., 0.0053, 0.0189, 0.0370],\n",
       "        [0.1004, 1.0000, 0.3263,  ..., 0.2506, 0.4740, 0.6346],\n",
       "        [0.0019, 0.3263, 1.0000,  ..., 0.0759, 0.1240, 0.1533],\n",
       "        ...,\n",
       "        [0.0053, 0.2506, 0.0759,  ..., 1.0000, 0.8995, 0.7572],\n",
       "        [0.0189, 0.4740, 0.1240,  ..., 0.8995, 1.0000, 0.9600],\n",
       "        [0.0370, 0.6346, 0.1533,  ..., 0.7572, 0.9600, 1.0000]],\n",
       "       device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_term.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac6f0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0011,  0.0002,  ..., -0.0006, -0.0014, -0.0019],\n",
       "        [ 0.0011,  0.0000,  0.0096,  ..., -0.0088, -0.0079, -0.0054],\n",
       "        [ 0.0002,  0.0096,  0.0000,  ...,  0.0021,  0.0051,  0.0071],\n",
       "        ...,\n",
       "        [-0.0006, -0.0088,  0.0021,  ...,  0.0000, -0.0028, -0.0061],\n",
       "        [-0.0014, -0.0079,  0.0051,  ..., -0.0028,  0.0000, -0.0011],\n",
       "        [-0.0019, -0.0054,  0.0071,  ..., -0.0061, -0.0011,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_uv.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23770d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.0000,   12.6979,  113.8843,  ..., -129.7339,  -85.5610,\n",
       "          -61.5250],\n",
       "        [  12.6979,    0.0000,   34.8503,  ...,  -41.7442,  -19.8875,\n",
       "          -10.1077],\n",
       "        [ 113.8843,   34.8503,    0.0000,  ...,   32.5165,   48.8842,\n",
       "           54.8879],\n",
       "        ...,\n",
       "        [-129.7339,  -41.7442,   32.5165,  ...,    0.0000,   -3.6545,\n",
       "           -9.5903],\n",
       "        [ -85.5610,  -19.8875,   48.8842,  ...,   -3.6545,    0.0000,\n",
       "           -1.4040],\n",
       "        [ -61.5250,  -10.1077,   54.8879,  ...,   -9.5903,   -1.4040,\n",
       "            0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 * r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3242a",
   "metadata": {},
   "source": [
    "These are only symmetric if we copy after multiplication with exp_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703612bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_train\n",
    "x2 = x_train\n",
    "\n",
    "# Extract the chosen device\n",
    "device = x1.device\n",
    "\n",
    "N = x1.shape[0]\n",
    "M = x2.shape[0]\n",
    "\n",
    "# Extract both lengthscales\n",
    "l1, l2 = kernel.lengthscale[0], kernel.lengthscale[1]\n",
    "\n",
    "# STEP 1: Pairwise differences of shape [N, M, 2]\n",
    "# Expand row_tensor [N, 2] -> [N, 1, 2] and column_tensor [M, 2] -> [1, M, 2]\n",
    "diff = (x1[:, None, :] - x2[None, :, :]).to(device)\n",
    "\n",
    "# Extract the relative components (columns of diff) for convenience, matching paper notation\n",
    "# NOTE: r1 and r2 are negative symmetric for like pairs \n",
    "r1 = diff[:, :, 0]\n",
    "r2 = diff[:, :, 1]\n",
    "            \n",
    "# STEP 2: Block matrix\n",
    "# Block components (shape N × M each)\n",
    "K_uu = to_linear_operator(((1 - (r2**2 / l2**2)) / l2**2).contiguous())\n",
    "K_uv = to_linear_operator(((r1 * r2) / (l1**2 * l2**2)).contiguous())\n",
    "# K_vu = K_uv\n",
    "K_vv = to_linear_operator(((1 - (r1**2 / l1**2)) / l1**2).contiguous())\n",
    "\n",
    "# STEP 3: RBF/SE envelope (elementwise) (shape N × M)\n",
    "# NOTE: If column_tensor == row_tensor, the diagonal elements will be 1\n",
    "exp_term = to_linear_operator(torch.exp(-0.5 * ((r1 / l1) ** 2 + (r2 / l2) ** 2)).contiguous()).to(device)\n",
    "\n",
    "# STEP 4: Combine and stack\n",
    "# Final scaled components (each shape N × M)\n",
    "K_uu = K_uu * exp_term\n",
    "K_uv = K_uv * exp_term\n",
    "K_vu = K_uv\n",
    "K_vv = K_vv * exp_term\n",
    "\n",
    "### Step 1: Create inticators for \"interleaving\" Kronecker product\n",
    "K_uu_indicator = torch.zeros(2, 2).to(device)\n",
    "K_uu_indicator[0, 0] = 1.0\n",
    "K_uu_indicator_lo = to_linear_operator(K_uu_indicator)\n",
    "\n",
    "K_uv_indicator = torch.zeros(2, 2).to(device)\n",
    "K_uv_indicator[0, 1] = 1.0\n",
    "K_uv_indicator_lo = to_linear_operator(K_uv_indicator)\n",
    "\n",
    "K_vu_indicator = torch.zeros(2, 2).to(device)\n",
    "K_vu_indicator[1, 0] = 1.0\n",
    "K_vu_indicator_lo = to_linear_operator(K_vu_indicator)\n",
    "\n",
    "K_vv_indicator = torch.zeros(2, 2).to(device)\n",
    "K_vv_indicator[1, 1] = 1.0\n",
    "K_vv_indicator_lo = to_linear_operator(K_vv_indicator)\n",
    "\n",
    "# Step 2: Create Kronecker product linear operators\n",
    "K_uu_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_uu,\n",
    "    K_uu_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_uv_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_uv,\n",
    "    K_uv_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_vu_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_vu,\n",
    "    K_vu_indicator_lo, # NOTE: The order is important here, it is not\n",
    ")\n",
    "\n",
    "K_vv_expand = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "    K_vv,\n",
    "    K_vv_indicator_lo, # NOTE: The order is important here, it is not commutative\n",
    ")\n",
    "\n",
    "K_interleaved = K_uu_expand + K_uv_expand + K_vu_expand + K_vv_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<linear_operator.operators.dense_linear_operator.DenseLinearOperator at 0x7fd6edf77190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_term"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
