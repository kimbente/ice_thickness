{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692d0867",
   "metadata": {},
   "source": [
    "# Understand 2D process with derivates\n",
    "\n",
    "https://docs.gpytorch.ai/en/v1.12/examples/08_Advanced_Usage/Simple_GP_Regression_Derivative_Information_2d.html\n",
    "https://docs.gpytorch.ai/en/v1.12/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a23c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "829f4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(X, Y):\n",
    "    term1 = .75*torch.exp(-((9*X - 2).pow(2) + (9*Y - 2).pow(2))/4)\n",
    "    term2 = .75*torch.exp(-((9*X + 1).pow(2))/49 - (9*Y + 1)/10)\n",
    "    term3 = .5*torch.exp(-((9*X - 7).pow(2) + (9*Y - 3).pow(2))/4)\n",
    "    term4 = .2*torch.exp(-(9*X - 4).pow(2) - (9*Y - 7).pow(2))\n",
    "\n",
    "    f = term1 + term2 + term3 - term4\n",
    "    dfx = -2*(9*X - 2)*9/4 * term1 - 2*(9*X + 1)*9/49 * term2 + \\\n",
    "          -2*(9*X - 7)*9/4 * term3 + 2*(9*X - 4)*9 * term4\n",
    "    dfy = -2*(9*Y - 2)*9/4 * term1 - 9/10 * term2 + \\\n",
    "          -2*(9*Y - 3)*9/4 * term3 + 2*(9*Y - 7)*9 * term4\n",
    "\n",
    "    return f, dfx, dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af68981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3])\n"
     ]
    }
   ],
   "source": [
    "xv, yv = torch.meshgrid(torch.linspace(0, 1, 10), torch.linspace(0, 1, 10), indexing=\"ij\")\n",
    "train_x = torch.cat((\n",
    "    xv.contiguous().view(xv.numel(), 1),\n",
    "    yv.contiguous().view(yv.numel(), 1)),\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "f, dfx, dfy = franke(train_x[:, 0], train_x[:, 1])\n",
    "train_y = torch.stack([f, dfx, dfy], -1).squeeze(1)\n",
    "\n",
    "train_y += 0.05 * torch.randn(train_y.size()) # Add noise to both values and gradients\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2246a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPModelWithDerivatives(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPModelWithDerivatives, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMeanGrad()\n",
    "        self.base_kernel = gpytorch.kernels.RBFKernelGrad(ard_num_dims = 2)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(self.base_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mean_x shape: torch.Size([100, 3])\n",
    "        mean_x = self.mean_module(x)\n",
    "        # print(\"mean_x shape:\", mean_x.shape)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # covar_x shape: torch.Size([300, 300])\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Access via likelihood.raw_task_noises\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks = 3)  # Value + x-derivative + y-derivative\n",
    "model = GPModelWithDerivatives(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d81276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_task_noises torch.Size([3])\n",
      "raw_noise torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.5971, -2.6760, -2.6152], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name, param in likelihood.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "likelihood.raw_task_noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f410b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 1.278   lengthscales: 0.693, 0.693   noise: 0.693\n",
      "Iter 2/50 - Loss: 1.263   lengthscales: 0.668, 0.668   noise: 0.669\n",
      "Iter 3/50 - Loss: 1.247   lengthscales: 0.645, 0.644   noise: 0.644\n",
      "Iter 4/50 - Loss: 1.232   lengthscales: 0.621, 0.621   noise: 0.621\n",
      "Iter 5/50 - Loss: 1.215   lengthscales: 0.599, 0.598   noise: 0.598\n",
      "Iter 6/50 - Loss: 1.199   lengthscales: 0.576, 0.576   noise: 0.576\n",
      "Iter 7/50 - Loss: 1.182   lengthscales: 0.555, 0.555   noise: 0.554\n",
      "Iter 8/50 - Loss: 1.164   lengthscales: 0.534, 0.534   noise: 0.533\n",
      "Iter 9/50 - Loss: 1.146   lengthscales: 0.513, 0.514   noise: 0.513\n",
      "Iter 10/50 - Loss: 1.128   lengthscales: 0.493, 0.494   noise: 0.493\n",
      "Iter 11/50 - Loss: 1.109   lengthscales: 0.473, 0.474   noise: 0.474\n",
      "Iter 12/50 - Loss: 1.090   lengthscales: 0.453, 0.455   noise: 0.455\n",
      "Iter 13/50 - Loss: 1.070   lengthscales: 0.435, 0.437   noise: 0.436\n",
      "Iter 14/50 - Loss: 1.050   lengthscales: 0.416, 0.419   noise: 0.419\n",
      "Iter 15/50 - Loss: 1.030   lengthscales: 0.399, 0.402   noise: 0.402\n",
      "Iter 16/50 - Loss: 1.010   lengthscales: 0.382, 0.386   noise: 0.385\n",
      "Iter 17/50 - Loss: 0.989   lengthscales: 0.365, 0.370   noise: 0.369\n",
      "Iter 18/50 - Loss: 0.968   lengthscales: 0.349, 0.356   noise: 0.353\n",
      "Iter 19/50 - Loss: 0.947   lengthscales: 0.334, 0.344   noise: 0.338\n",
      "Iter 20/50 - Loss: 0.927   lengthscales: 0.319, 0.332   noise: 0.323\n",
      "Iter 21/50 - Loss: 0.907   lengthscales: 0.305, 0.323   noise: 0.309\n",
      "Iter 22/50 - Loss: 0.888   lengthscales: 0.292, 0.316   noise: 0.295\n",
      "Iter 23/50 - Loss: 0.869   lengthscales: 0.282, 0.310   noise: 0.282\n",
      "Iter 24/50 - Loss: 0.850   lengthscales: 0.273, 0.306   noise: 0.269\n",
      "Iter 25/50 - Loss: 0.831   lengthscales: 0.267, 0.304   noise: 0.257\n",
      "Iter 26/50 - Loss: 0.811   lengthscales: 0.264, 0.303   noise: 0.245\n",
      "Iter 27/50 - Loss: 0.790   lengthscales: 0.263, 0.304   noise: 0.234\n",
      "Iter 28/50 - Loss: 0.769   lengthscales: 0.263, 0.305   noise: 0.223\n",
      "Iter 29/50 - Loss: 0.748   lengthscales: 0.265, 0.307   noise: 0.212\n",
      "Iter 30/50 - Loss: 0.727   lengthscales: 0.268, 0.308   noise: 0.202\n",
      "Iter 31/50 - Loss: 0.706   lengthscales: 0.271, 0.308   noise: 0.192\n",
      "Iter 32/50 - Loss: 0.686   lengthscales: 0.275, 0.307   noise: 0.183\n",
      "Iter 33/50 - Loss: 0.666   lengthscales: 0.277, 0.305   noise: 0.174\n",
      "Iter 34/50 - Loss: 0.646   lengthscales: 0.279, 0.302   noise: 0.166\n",
      "Iter 35/50 - Loss: 0.626   lengthscales: 0.280, 0.297   noise: 0.158\n",
      "Iter 36/50 - Loss: 0.606   lengthscales: 0.279, 0.291   noise: 0.150\n",
      "Iter 37/50 - Loss: 0.585   lengthscales: 0.276, 0.284   noise: 0.143\n",
      "Iter 38/50 - Loss: 0.563   lengthscales: 0.272, 0.276   noise: 0.136\n",
      "Iter 39/50 - Loss: 0.542   lengthscales: 0.268, 0.268   noise: 0.129\n",
      "Iter 40/50 - Loss: 0.521   lengthscales: 0.263, 0.260   noise: 0.123\n",
      "Iter 41/50 - Loss: 0.500   lengthscales: 0.258, 0.252   noise: 0.117\n",
      "Iter 42/50 - Loss: 0.480   lengthscales: 0.253, 0.245   noise: 0.111\n",
      "Iter 43/50 - Loss: 0.459   lengthscales: 0.250, 0.240   noise: 0.106\n",
      "Iter 44/50 - Loss: 0.439   lengthscales: 0.247, 0.236   noise: 0.100\n",
      "Iter 45/50 - Loss: 0.418   lengthscales: 0.245, 0.233   noise: 0.095\n",
      "Iter 46/50 - Loss: 0.397   lengthscales: 0.244, 0.232   noise: 0.091\n",
      "Iter 47/50 - Loss: 0.377   lengthscales: 0.243, 0.232   noise: 0.086\n",
      "Iter 48/50 - Loss: 0.356   lengthscales: 0.243, 0.233   noise: 0.082\n",
      "Iter 49/50 - Loss: 0.336   lengthscales: 0.243, 0.234   noise: 0.078\n",
      "Iter 50/50 - Loss: 0.316   lengthscales: 0.242, 0.234   noise: 0.074\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = - mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print(\"Iter %d/%d - Loss: %.3f   lengthscales: %.3f, %.3f   noise: %.3f\" % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.squeeze()[0],\n",
    "        model.covar_module.base_kernel.lengthscale.squeeze()[1],\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7918fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 300])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.covariance_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice_thickness_gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
