{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2058369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import linear_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a0ad402",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.linspace(0, 1, steps = 10).unsqueeze(-1)\n",
    "x2 = torch.linspace(10, 100, steps = 10).unsqueeze(-1)\n",
    "x = torch.cat([x1, x2], dim = -1)\n",
    "\n",
    "covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernelGrad(ard_num_dims = 2, lengthscale_constraint = gpytorch.constraints.GreaterThan(1e-5)))\n",
    "covar_module.base_kernel.lengthscale = torch.tensor([1.0, 1.5])\n",
    "covar = covar_module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "184d37ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.69, 0.00, 0.00],\n",
       "        [0.00, 0.69, 0.00],\n",
       "        [0.00, 0.00, 0.31]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar.to_dense()[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec6937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf244388b0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(covar.to_dense().detach().numpy(), cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "10 9 2\n",
      "torch.Size([])\n",
      "10 9 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 18])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x\n",
    "x2 = x[0:9]\n",
    "\n",
    "batch_shape = x1.shape[:-2]\n",
    "# 0 if only 2D\n",
    "print(batch_shape)\n",
    "N, d = x1.shape[-2:]\n",
    "# d must be same\n",
    "n2 = x2.shape[-2]\n",
    "print(N, n2, d)\n",
    "\n",
    "# Initialises K: torch.Size([30, 27])\n",
    "K = torch.zeros(*batch_shape, n1 * (d + 1), n2 * (d + 1), device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "l1 = 0.5\n",
    "l2 = 1.0\n",
    "\n",
    "lengthscale = torch.tensor([l1, l2], device=x1.device, dtype=x1.dtype)\n",
    "\n",
    "# Each dim is scaled by it's represctive lengthscale\n",
    "x1_ = x1.div(lengthscale)\n",
    "x2_ = x2.div(lengthscale)\n",
    "\n",
    "# outer[:, :, 0] are x1-x1'/l1\n",
    "# outer[:, :, 1] are x2-x2'/l2\n",
    "outer = x1_.view(*batch_shape, n1, 1, d) - x2_.view(*batch_shape, 1, n2, d) # torch.Size([10, 9, 2])\n",
    "# manual = (x1[:, 0].unsqueeze(-1) - x2[:, 0].unsqueeze(0)).div(l1)\n",
    "# manual == outer[:, :, 0]  # torch.Size([10, 9])\n",
    "\n",
    "# lengthscale.unsqueeze(-2): torch.Size([1, 2])\n",
    "# torch.Size([10, 9, 2]) now x1-x1'/l1/l1\n",
    "outer = outer / lengthscale.unsqueeze(-2)\n",
    "# torch.Size([10, 2, 9]) N, D, M : swops last two dims\n",
    "outer_now = torch.transpose(outer, -1, -2).contiguous()\n",
    "\n",
    "# 1) Kernel block\n",
    "from gpytorch.kernels.rbf_kernel import postprocess_rbf, RBFKernel\n",
    "RBFKernel = gpytorch.kernels.RBFKernel(ard_num_dims = 2, lengthscale_constraint = gpytorch.constraints.GreaterThan(1e-5))\n",
    "# function from RBF class\n",
    "diff = RBFKernel.covar_dist(x1_, x2_, square_dist = True, lengthscale = lengthscale)\n",
    "K_11 = postprocess_rbf(diff)\n",
    "# blockwise assignment\n",
    "K[..., :N, :n2] = K_11\n",
    "\n",
    "# 2) First gradient block (uv)\n",
    "outer1 = outer.view(*batch_shape, N, n2 * d)\n",
    "# where does n_batch_dims come from?\n",
    "n_batch_dims = len(batch_shape)\n",
    "# x1 = x\n",
    "x2 = x[0:9]\n",
    "\n",
    "batch_shape = x1.shape[:-2]\n",
    "# 0 if only 2D\n",
    "print(batch_shape)\n",
    "N, d = x1.shape[-2:]\n",
    "# d must be same\n",
    "n2 = x2.shape[-2]\n",
    "print(N, n2, d)\n",
    "\n",
    "# Initialises K: torch.Size([30, 27])\n",
    "K = torch.zeros(*batch_shape, n1 * (d + 1), n2 * (d + 1), device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "l1 = 0.5\n",
    "l2 = 1.0\n",
    "\n",
    "lengthscale = torch.tensor([l1, l2], device=x1.device, dtype=x1.dtype)\n",
    "\n",
    "# Each dim is scaled by it's represctive lengthscale\n",
    "x1_ = x1.div(lengthscale)\n",
    "x2_ = x2.div(lengthscale)\n",
    "\n",
    "# outer[:, :, 0] are x1-x1'/l1\n",
    "# outer[:, :, 1] are x2-x2'/l2\n",
    "outer = x1_.view(*batch_shape, n1, 1, d) - x2_.view(*batch_shape, 1, n2, d) # torch.Size([10, 9, 2])\n",
    "# manual = (x1[:, 0].unsqueeze(-1) - x2[:, 0].unsqueeze(0)).div(l1)\n",
    "# manual == outer[:, :, 0]  # torch.Size([10, 9])\n",
    "\n",
    "# lengthscale.unsqueeze(-2): torch.Size([1, 2])\n",
    "# torch.Size([10, 9, 2]) now x1-x1'/l1^2\n",
    "outer = outer / lengthscale.unsqueeze(-2)\n",
    "# torch.Size([10, 2, 9]) N, D, M : swops last two dims\n",
    "outer = torch.transpose(outer, -1, -2).contiguous()\n",
    "\n",
    "# 1) Kernel block\n",
    "from gpytorch.kernels.rbf_kernel import postprocess_rbf, RBFKernel\n",
    "RBFKernel = gpytorch.kernels.RBFKernel(ard_num_dims = 2, lengthscale_constraint = gpytorch.constraints.GreaterThan(1e-5))\n",
    "# function from RBF class\n",
    "diff = RBFKernel.covar_dist(x1_, x2_, square_dist = True, lengthscale = lengthscale)\n",
    "K_11 = postprocess_rbf(diff)\n",
    "# blockwise assignment\n",
    "K[..., :n1, :n2] = K_11\n",
    "\n",
    "# 2) First gradient block (uv)\n",
    "outer1 = outer.view(*batch_shape, n1, n2 * d)\n",
    "# where does n_batch_dims come from?\n",
    "n_batch_dims = len(batch_shape)\n",
    "# torch.Size([10, 18]) \n",
    "K[..., :n1, n2:] = outer1 * K_11.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "# (outer1 * K_11.repeat([*([1] * (n_batch_dims + 1)), d])).shape\n",
    "\n",
    "# 3) Second gradient block (vu)\n",
    "outer2 = outer.transpose(-1, -3).reshape(*batch_shape, n2, n1 * d)\n",
    "outer2 = outer2.transpose(-1, -2)\n",
    "# torch.Size([20, 9]) lower left (tall)\n",
    "K[..., n1:, :n2] = -outer2 * K_11.repeat([*([1] * n_batch_dims), d, 1])\n",
    "# (-outer2 * K_11.repeat([*([1] * n_batch_dims), d, 1])).shape\n",
    "\n",
    "# 4) Hessian block (second derivates)\n",
    "# torch.Size([20, 18]) & torch.Size([20, 18])\n",
    "outer3 = outer1.repeat([*([1] * n_batch_dims), d, 1]) * outer2.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "# torch.Size([20, 18])\n",
    "# first torch.Size([10, 9]) block is just filled with 1/l1**2\n",
    "# second (top right) torch.Size([10, 9]) block is zeros\n",
    "# third (bottom left) torch.Size([10, 9]) block is zeros\n",
    "# fourth (bottom right) torch.Size([10, 9]) block is filled with 1/l2**2\n",
    "kp = linear_operator.operators.KroneckerProductLinearOperator(\n",
    "                # [(1/l1^2), 0][0, 1/l2^2]\n",
    "                torch.eye(d, d, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1) / lengthscale.pow(2),\n",
    "                # torch.Size([10, 9]) filled with ones\n",
    "                torch.ones(n1, n2, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "            )\n",
    "\n",
    "# 1 /l1**2 - outer3\n",
    "# torch.Size([20, 18]) with 4 big blocks\n",
    "chain_rule = kp.to_dense() - outer3\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "# elementswise mul torch.Size([20, 18])\n",
    "K[..., n1:, n2:] = chain_rule * K_11.repeat([*([1] * n_batch_dims), d, d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389901a",
   "metadata": {},
   "source": [
    "# draft my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from linear_operator.operators import KroneckerProductLinearOperator\n",
    "from gpytorch.kernels.rbf_kernel import postprocess_rbf, RBFKernel\n",
    "\n",
    "\n",
    "class dfRBFKernel(RBFKernel):\n",
    "    r\"\"\"\n",
    "    Computes a divergence-free RBF covariance matrix of the RBF kernel that models the covariance\n",
    "    for inputs :math:`\\mathbf{x_1}` and :math:`\\mathbf{x_2}`. The code is heavily based on the Hessian component of the RBF grad kernel, also inheriting from Gpytorch's RBF kernel (see source code here: https://docs.gpytorch.ai/en/stable/_modules/gpytorch/kernels/rbf_kernel_grad.html#RBFKernelGrad) to enable computational speed ups.\n",
    "\n",
    "    Notes: \n",
    "    - This only works for 2D currently. \n",
    "    - Uses self.lengthscale object.\n",
    "\n",
    "    See :class:`gpytorch.kernels.Kernel` for descriptions of the lengthscale options.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        This kernel does not have an `outputscale` parameter. To add a scaling parameter,\n",
    "        decorate this kernel with a :class:`gpytorch.kernels.ScaleKernel`.\n",
    "\n",
    "    :param ard_num_dims: Set this if you want a separate lengthscale for each input\n",
    "        dimension. It should be `d` if x1 is a `n x d` matrix. (Default: `None`.)\n",
    "    :param batch_shape: Set this if you want a separate lengthscale for each batch of input\n",
    "        data. It should be :math:`B_1 \\times \\ldots \\times B_k` if :math:`\\mathbf x1` is\n",
    "        a :math:`B_1 \\times \\ldots \\times B_k \\times N \\times D` tensor.\n",
    "    :param active_dims: Set this if you want to compute the covariance of only\n",
    "        a few input dimensions. The ints corresponds to the indices of the\n",
    "        dimensions. (Default: `None`.)\n",
    "    :param lengthscale_prior: Set this if you want to apply a prior to the\n",
    "        lengthscale parameter. (Default: `None`)\n",
    "    :param lengthscale_constraint: Set this if you want to apply a constraint\n",
    "        to the lengthscale parameter. (Default: `Positive`.)\n",
    "    :param eps: The minimum value that the lengthscale can take (prevents\n",
    "        divide by zero errors). (Default: `1e-6`.)\n",
    "\n",
    "    :ivar torch.Tensor lengthscale: The lengthscale parameter. Size/shape of parameter depends on the\n",
    "        ard_num_dims and batch_shape arguments.\n",
    "\n",
    "    Example:\n",
    "        >>> x = torch.randn(10, 2)\n",
    "        >>> # Non-batch: Simple option\n",
    "        >>> covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.dfRBFKernel())\n",
    "        >>> covar = covar_module(x)  # Output: LinearOperator of size (20 x 20), where 20 = n * d\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x1, x2, diag = False, **params):\n",
    "\n",
    "        ### STEP 1: EXTRACT BATCHES & DIMS ###\n",
    "\n",
    "        # BATCHES\n",
    "        # NOTE: We write this in a batch compatible way, using negative indexing (from the right)\n",
    "        # batch_shape is torch.Size([]) if only 2D\n",
    "        batch_shape = x1.shape[:-2]\n",
    "        # usually zero, one, or two\n",
    "        n_batch_dims = len(batch_shape)\n",
    "\n",
    "        # DIMS\n",
    "        N, d = x1.shape[-2:]\n",
    "        # d must be same\n",
    "        M = x2.shape[-2]\n",
    "\n",
    "        # We save compute when diag = True by only computing what is needed\n",
    "        if not diag:\n",
    "\n",
    "            ### STEP 2: DIRECTIONAL SCALED DIFFERENCES ###\n",
    "            # Scale the inputs by the lengthscale(s) (e.g. two lengthscales if ard_num_dims = 2)\n",
    "            # HACK: Applying div before subtracting increases stability\n",
    "            x1_ = x1.div(self.lengthscale)\n",
    "            x2_ = x2.div(self.lengthscale)\n",
    "\n",
    "            # Broadcast and compute directional (scaled) differences (..., N, M, d)\n",
    "            directional_scaled_diffs = x1_.view(*batch_shape, N, 1, d) - x2_.view(*batch_shape, 1, M, d)\n",
    "            # Divide by lengthscales again to get directional_scaled_diffs: (x1 - x2) / ℓ^2\n",
    "            # lengthscale e.g. shape (1, 2) (unsqueeze to broadcast)\n",
    "            directional_scaled_diffs = directional_scaled_diffs / self.lengthscale.unsqueeze(-2)\n",
    "\n",
    "            # HACK: Flip the last axis to have d2, d1 ordering. The off-diagonals thus remain the same while the diagonals are flipped. This is new for the dfRBF kernel.\n",
    "            directional_scaled_diffs = torch.flip(directional_scaled_diffs, dims = [-1])\n",
    "\n",
    "            # (..., N, d, M): swops last two dims\n",
    "            directional_scaled_diffs = torch.transpose(directional_scaled_diffs, -1, -2).contiguous()\n",
    "\n",
    "            # torch.Size([..., N, d * M]) where the first M indices are d1 and the latter M indices are d2 for 2d\n",
    "            # d1 diffs are the left block, d2 diffs are the right block\n",
    "            directional_scaled_diffs_N_rows_wide = directional_scaled_diffs.view(*batch_shape, N, d * M)\n",
    "            \n",
    "            # transpose swop N and M so makes torch.Size([..., M, d, N])\n",
    "            # reshape torch.Size([..., M, d * N])\n",
    "            directional_scaled_diffs_M_rows_wide = directional_scaled_diffs.transpose(-1, -3).reshape(*batch_shape, M, d * N)\n",
    "            # d1 diffs are the upper block, d2 diffs are the lower block\n",
    "            directional_scaled_diffs_2N_rows_tall = directional_scaled_diffs_M_rows_wide.transpose(-1, -2)\n",
    "\n",
    "            # 1) Kernel block\n",
    "            # NOTE: as an instance of the RBF kernel, we can use the covar_dist method to compute the squared distance;\n",
    "            # This uses our lengthscale.\n",
    "            diff = self.covar_dist(x1_, x2_, square_dist = True, **params)\n",
    "            # torch.Size([..., N, M])\n",
    "            K_rbf = postprocess_rbf(diff)\n",
    "\n",
    "            ### STEP 4: BLOCKWISE ASSIGNMENTS ###\n",
    "            # torch.Size([..., N * d, M * d])\n",
    "            # First term: Last axis stays the same, second last axis (rows) is repeated\n",
    "            directional_scaled_diffs_two_rows = directional_scaled_diffs_N_rows_wide.repeat([*([1] * n_batch_dims), d, 1]) \n",
    "            # Second term: Last axis (columns) is repeated, second last axis (rows) stays the same\n",
    "            directional_scaled_diffs_two_columns = directional_scaled_diffs_2N_rows_tall.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "\n",
    "            # Upper left is r_1**2/l_1**4\n",
    "            # Upper right and lower left are r_1 * r_2 / (l_1**2 * l_2**2)\n",
    "            # Lower right is r_2**2 / l_2**4\n",
    "            directional_scaled_diffs_product_block = directional_scaled_diffs_two_rows * directional_scaled_diffs_two_columns\n",
    "\n",
    "            ### STEP 5: SIGN BLOCK ###\n",
    "            # Create sign block to negate off-diagonal blocks\n",
    "            sign_block = KroneckerProductLinearOperator(\n",
    "                torch.tensor([[1., -1.], [-1., 1.]], device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "                torch.ones(N, M, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1)\n",
    "            )\n",
    "\n",
    "            directional_scaled_diffs_product_block = sign_block * directional_scaled_diffs_product_block\n",
    "\n",
    "            ### STEP 6: KRONECKER PRODUCT BLOCK ###\n",
    "            # torch.Size([..., N * d, M * d])\n",
    "            kp = KroneckerProductLinearOperator(\n",
    "                        # Upper left block is (1/l1^2)\n",
    "                        # Lower right block is (1/l2^2)\n",
    "                        # Upper right and lower left blocks are (0)\n",
    "                        # HACK: Flip the last axis to match the dfRBF ordering. This is another change from the RBF grad kernel.\n",
    "                        torch.eye(d, d, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1) / lengthscale.flip(-1).pow(2),\n",
    "                        # Expand\n",
    "                        torch.ones(N, M, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "                    )\n",
    "            \n",
    "            ### STEP 6: SUBTRACT BLOCKS ###\n",
    "            # Upper left block is (1/l1^2 - product)\n",
    "            # Lower right block is (1/l2^2 - product)\n",
    "            # Upper right and lower left blocks are (0 - product), resulting in the negative product\n",
    "            subtracted_blocks = kp.to_dense() - directional_scaled_diffs_product_block\n",
    "            # repeat K_rbf d * d times\n",
    "            K = subtracted_blocks * K_rbf.repeat([*([1] * n_batch_dims), d, d])\n",
    "\n",
    "            # Symmetrize for stability (Not for K_train_test of course)\n",
    "            if N == M and torch.eq(x1, x2).all():\n",
    "                K = 0.5 * (K.transpose(-1, -2) + K)\n",
    "\n",
    "            # Apply a perfect shuffle permutation to match the MutiTask ordering\n",
    "            pi1 = torch.arange(N * d).view(d, N).t().reshape((N * d))\n",
    "            pi2 = torch.arange(M * d).view(d, M).t().reshape((M * d))\n",
    "            K = K[..., pi1, :][..., :, pi2]\n",
    "\n",
    "            return K\n",
    "\n",
    "        # If diag = True, we only compute the diagonal elements\n",
    "        else:\n",
    "            if not (N == M and torch.eq(x1, x2).all()):\n",
    "                raise RuntimeError(\"diag = True only works when x1 == x2\")\n",
    "            \n",
    "            # NOTE: We have to flip the last axis of lengthscale to match the dfRBF ordering.\n",
    "            grad_diag = torch.ones(*batch_shape, M, d, device = x1.device, dtype = x1.dtype) / lengthscale.flip(-1).pow(2)\n",
    "            grad_diag = grad_diag.transpose(-1, -2).reshape(*batch_shape, M * d)\n",
    "\n",
    "            # The permutation indices for the diagonal elements to match interleaved format in Multitask settinga\n",
    "            pi = torch.arange(M * d).view(d, M).t().reshape((M * d))\n",
    "            return grad_diag[..., pi]\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        return x1.size(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e047c",
   "metadata": {},
   "source": [
    "# Write only Hessian portion in my language with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9199e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HESSIAN BLOCK ###\n",
    "\n",
    "import torch\n",
    "from linear_operator.operators import KroneckerProductLinearOperator\n",
    "from gpytorch.kernels.rbf_kernel import postprocess_rbf, RBFKernel\n",
    "\n",
    "x1 = torch.linspace(0, 1, steps = 10).unsqueeze(-1)\n",
    "x2 = torch.linspace(10, 100, steps = 10).unsqueeze(-1)\n",
    "x = torch.cat([x1, x2], dim = -1)\n",
    "\n",
    "x1 = x\n",
    "# keep indices seperable\n",
    "x2 = x[0:9]\n",
    "\n",
    "diag = False\n",
    "l1 = 0.5 * 5\n",
    "l2 = 1.0 * 5\n",
    "lengthscale = torch.tensor([l1, l2], device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "# BATCHES\n",
    "# NOTE: We write this in a batch compatible way, using negative indexing (from the right)\n",
    "# batch_shape is torch.Size([]) if only 2D\n",
    "batch_shape = x1.shape[:-2]\n",
    "# usually zero, one, or two\n",
    "n_batch_dims = len(batch_shape)\n",
    "\n",
    "# DIMS\n",
    "N, d = x1.shape[-2:]\n",
    "# d must be same\n",
    "M = x2.shape[-2]\n",
    "\n",
    "# We save compute when diag = True by only computing what is needed\n",
    "if not diag:\n",
    "\n",
    "    # K = torch.zeros(*batch_shape, N * d, M * d, device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "    ### STEP 2: DIRECTIONAL SCALED DIFFERENCES ###\n",
    "    # Scale the inputs by the lengthscale(s) (e.g. two lengthscales if ard_num_dims = 2)\n",
    "    # HACK: Applying div before subtracting increases stability\n",
    "    x1_ = x1.div(lengthscale)\n",
    "    x2_ = x2.div(lengthscale)\n",
    "\n",
    "    # Broadcast and compute directional (scaled) differences (..., N, M, d)\n",
    "    directional_scaled_diffs = x1_.view(*batch_shape, N, 1, d) - x2_.view(*batch_shape, 1, M, d)\n",
    "    # Divide by lengthscales again to get directional_scaled_diffs: (x1 - x2) / ℓ^2\n",
    "    # lengthscale e.g. shape (1, 2) (unsqueeze to broadcast)\n",
    "    directional_scaled_diffs = directional_scaled_diffs / lengthscale.unsqueeze(-2)\n",
    "    # (..., N, d, M): swops last two dims\n",
    "    directional_scaled_diffs = torch.transpose(directional_scaled_diffs, -1, -2).contiguous()\n",
    "\n",
    "    # torch.Size([..., N, d * M]) where the first M indices are d1 and the latter M indices are d2 for 2d\n",
    "    # d1 diffs are the left block, d2 diffs are the right block\n",
    "    directional_scaled_diffs_N_rows_wide = directional_scaled_diffs.view(*batch_shape, N, d * M)\n",
    "    \n",
    "    # transpose swop N and M so makes torch.Size([..., M, d, N])\n",
    "    # reshape torch.Size([..., M, d * N])\n",
    "    directional_scaled_diffs_M_rows_wide = directional_scaled_diffs.transpose(-1, -3).reshape(*batch_shape, M, d * N)\n",
    "    # d1 diffs are the upper block, d2 diffs are the lower block\n",
    "    directional_scaled_diffs_2N_rows_tall = directional_scaled_diffs_M_rows_wide.transpose(-1, -2)\n",
    "\n",
    "    ### STEP 3: RBF BLOCK ###\n",
    "    RBFKernel = gpytorch.kernels.RBFKernel(ard_num_dims = 2, lengthscale_constraint = gpytorch.constraints.GreaterThan(1e-5))\n",
    "    diff = RBFKernel.covar_dist(x1_, x2_, square_dist = True, lengthscale = lengthscale)\n",
    "    # torch.Size([..., N, M])\n",
    "    K_rbf = postprocess_rbf(diff)\n",
    "\n",
    "    ### STEP 4: BLOCKWISE ASSIGNMENTS ###\n",
    "    # torch.Size([..., N * d, M * d])\n",
    "    # First term: Last axis stays the same, second last axis (rows) is repeated\n",
    "    directional_scaled_diffs_two_rows = directional_scaled_diffs_N_rows_wide.repeat([*([1] * n_batch_dims), d, 1]) \n",
    "    # Second term: Last axis (columns) is repeated, second last axis (rows) stays the same\n",
    "    directional_scaled_diffs_two_columns = directional_scaled_diffs_2N_rows_tall.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "\n",
    "    # Upper left is r_1**2/l_1**4\n",
    "    # Upper right and lower left are r_1 * r_2 / (l_1**2 * l_2**2)\n",
    "    # Lower right is r_2**2 / l_2**4\n",
    "    directional_scaled_diffs_product_block = directional_scaled_diffs_two_rows * directional_scaled_diffs_two_columns\n",
    "\n",
    "    ### STEP 5: KRONECKER PRODUCT BLOCK ###\n",
    "    # torch.Size([..., N * d, M * d])\n",
    "    kp = KroneckerProductLinearOperator(\n",
    "                # Upper left block is (1/l1^2)\n",
    "                # Lower right block is (1/l2^2)\n",
    "                # Upper right and lower left blocks are (0)\n",
    "                torch.eye(d, d, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1) / lengthscale.pow(2),\n",
    "                # Expand\n",
    "                torch.ones(N, M, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "            )\n",
    "    \n",
    "    ### STEP 6: SUBTRACT BLOCKS ###\n",
    "    # Upper left block is (1/l1^2 - product)\n",
    "    # Lower right block is (1/l2^2 - product)\n",
    "    # Upper right and lower left blocks are (0 - product), resulting in the negative product\n",
    "    subtracted_blocks = kp.to_dense() - directional_scaled_diffs_product_block\n",
    "    # repeat K_rbf d * d times\n",
    "    K_hess = subtracted_blocks * K_rbf.repeat([*([1] * n_batch_dims), d, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83b4471a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe364dd8af0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(K_hess.to_dense().detach().numpy(), cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56015d86",
   "metadata": {},
   "source": [
    "# Make changes to get dfRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "879d3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dfRBF BLOCK ###\n",
    "\n",
    "import torch\n",
    "from linear_operator.operators import KroneckerProductLinearOperator\n",
    "from gpytorch.kernels.rbf_kernel import postprocess_rbf, RBFKernel\n",
    "\n",
    "x1 = torch.linspace(0, 1, steps = 10).unsqueeze(-1)\n",
    "x2 = torch.linspace(10, 100, steps = 10).unsqueeze(-1)\n",
    "x = torch.cat([x1, x2], dim = -1)\n",
    "\n",
    "x1 = x\n",
    "# keep indices seperable\n",
    "# x2 = x[0:9]\n",
    "# For diagonal test\n",
    "x2 = x\n",
    "\n",
    "diag = False\n",
    "l1 = 0.5 * 5\n",
    "l2 = 1.0 * 5\n",
    "lengthscale = torch.tensor([l1, l2], device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "# BATCHES\n",
    "# NOTE: We write this in a batch compatible way, using negative indexing (from the right)\n",
    "# batch_shape is torch.Size([]) if only 2D\n",
    "batch_shape = x1.shape[:-2]\n",
    "# usually zero, one, or two\n",
    "n_batch_dims = len(batch_shape)\n",
    "\n",
    "# DIMS\n",
    "N, d = x1.shape[-2:]\n",
    "# d must be same\n",
    "M = x2.shape[-2]\n",
    "\n",
    "# We save compute when diag = True by only computing what is needed\n",
    "if not diag:\n",
    "\n",
    "    # K = torch.zeros(*batch_shape, N * d, M * d, device = x1.device, dtype = x1.dtype)\n",
    "\n",
    "    ### STEP 2: DIRECTIONAL SCALED DIFFERENCES ###\n",
    "    # Scale the inputs by the lengthscale(s) (e.g. two lengthscales if ard_num_dims = 2)\n",
    "    # HACK: Applying div before subtracting increases stability\n",
    "    x1_ = x1.div(lengthscale)\n",
    "    x2_ = x2.div(lengthscale)\n",
    "\n",
    "    # Broadcast and compute directional (scaled) differences (..., N, M, d)\n",
    "    directional_scaled_diffs = x1_.view(*batch_shape, N, 1, d) - x2_.view(*batch_shape, 1, M, d)\n",
    "    # Divide by lengthscales again to get directional_scaled_diffs: (x1 - x2) / ℓ^2\n",
    "    # lengthscale e.g. shape (1, 2) (unsqueeze to broadcast)\n",
    "    directional_scaled_diffs = directional_scaled_diffs / lengthscale.unsqueeze(-2)\n",
    "\n",
    "    # HACK: Flip the last axis to have d2, d1 ordering. The off-diagonals thus remain the same while the diagonals are flipped. This is new for the dfRBF kernel.\n",
    "    directional_scaled_diffs = torch.flip(directional_scaled_diffs, dims = [-1])\n",
    "\n",
    "    # (..., N, d, M): swops last two dims\n",
    "    directional_scaled_diffs = torch.transpose(directional_scaled_diffs, -1, -2).contiguous()\n",
    "\n",
    "    # torch.Size([..., N, d * M]) where the first M indices are d1 and the latter M indices are d2 for 2d\n",
    "    # d1 diffs are the left block, d2 diffs are the right block\n",
    "    directional_scaled_diffs_N_rows_wide = directional_scaled_diffs.view(*batch_shape, N, d * M)\n",
    "    \n",
    "    # transpose swop N and M so makes torch.Size([..., M, d, N])\n",
    "    # reshape torch.Size([..., M, d * N])\n",
    "    directional_scaled_diffs_M_rows_wide = directional_scaled_diffs.transpose(-1, -3).reshape(*batch_shape, M, d * N)\n",
    "    # d1 diffs are the upper block, d2 diffs are the lower block\n",
    "    directional_scaled_diffs_2N_rows_tall = directional_scaled_diffs_M_rows_wide.transpose(-1, -2)\n",
    "\n",
    "    ### STEP 3: RBF BLOCK ###\n",
    "    RBFKernel = gpytorch.kernels.RBFKernel(ard_num_dims = 2, lengthscale_constraint = gpytorch.constraints.GreaterThan(1e-5))\n",
    "    diff = RBFKernel.covar_dist(x1_, x2_, square_dist = True, lengthscale = lengthscale)\n",
    "    # torch.Size([..., N, M])\n",
    "    K_rbf = postprocess_rbf(diff)\n",
    "\n",
    "    ### STEP 4: BLOCKWISE ASSIGNMENTS ###\n",
    "    # torch.Size([..., N * d, M * d])\n",
    "    # First term: Last axis stays the same, second last axis (rows) is repeated\n",
    "    directional_scaled_diffs_two_rows = directional_scaled_diffs_N_rows_wide.repeat([*([1] * n_batch_dims), d, 1]) \n",
    "    # Second term: Last axis (columns) is repeated, second last axis (rows) stays the same\n",
    "    directional_scaled_diffs_two_columns = directional_scaled_diffs_2N_rows_tall.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "\n",
    "    # Upper left is r_1**2/l_1**4\n",
    "    # Upper right and lower left are r_1 * r_2 / (l_1**2 * l_2**2)\n",
    "    # Lower right is r_2**2 / l_2**4\n",
    "    directional_scaled_diffs_product_block = directional_scaled_diffs_two_rows * directional_scaled_diffs_two_columns\n",
    "\n",
    "    ### STEP 5: SIGN BLOCK ###\n",
    "    # Create sign block to negate off-diagonal blocks\n",
    "    sign_block = KroneckerProductLinearOperator(\n",
    "        torch.tensor([[1., -1.], [-1., 1.]], device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "        torch.ones(N, M, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1)\n",
    "    )\n",
    "\n",
    "    directional_scaled_diffs_product_block = sign_block * directional_scaled_diffs_product_block\n",
    "\n",
    "    ### STEP 6: KRONECKER PRODUCT BLOCK ###\n",
    "    # torch.Size([..., N * d, M * d])\n",
    "    kp = KroneckerProductLinearOperator(\n",
    "                # Upper left block is (1/l1^2)\n",
    "                # Lower right block is (1/l2^2)\n",
    "                # Upper right and lower left blocks are (0)\n",
    "                # HACK: Flip the last axis\n",
    "                torch.eye(d, d, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1) / lengthscale.flip(-1).pow(2),\n",
    "                # Expand\n",
    "                torch.ones(N, M, device = x1.device, dtype = x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "            )\n",
    "    \n",
    "    ### STEP 6: SUBTRACT BLOCKS ###\n",
    "    # Upper left block is (1/l1^2 - product)\n",
    "    # Lower right block is (1/l2^2 - product)\n",
    "    # Upper right and lower left blocks are (0 - product), resulting in the negative product\n",
    "    subtracted_blocks = kp.to_dense() - directional_scaled_diffs_product_block\n",
    "    # repeat K_rbf d * d times\n",
    "    K = subtracted_blocks * K_rbf.repeat([*([1] * n_batch_dims), d, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84123179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
       "        0.0400, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600,\n",
       "        0.1600, 0.1600])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_matrix = K.to_dense()\n",
    "torch.diag(K_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa48946",
   "metadata": {},
   "outputs": [],
   "source": [
    "        else:\n",
    "            if not (N == M and torch.eq(x1, x2).all()):\n",
    "                raise RuntimeError(\"diag = True only works when x1 == x2\")\n",
    "\n",
    "            kernel_diag = super(dfRBFKernel, self).forward(x1, x2, diag = True)\n",
    "            grad_diag = torch.ones(*batch_shape, M, d, device = x1.device, dtype = x1.dtype) / self.lengthscale.flip(-1).pow(2)\n",
    "            grad_diag = grad_diag.transpose(-1, -2).reshape(*batch_shape, M * d)\n",
    "            k_diag = torch.cat((kernel_diag, grad_diag), dim = -1)\n",
    "            pi = torch.arange(M * d).view(d, M).t().reshape((M * d))\n",
    "            return k_diag[..., pi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30861d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0400, 0.1600, 0.0400, 0.1600, 0.0400, 0.1600, 0.0400, 0.1600, 0.0400,\n",
       "        0.1600, 0.0400, 0.1600, 0.0400, 0.1600, 0.0400, 0.1600, 0.0400, 0.1600,\n",
       "        0.0400, 0.1600])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_diag = torch.ones(*batch_shape, M, d, device = x1.device, dtype = x1.dtype) / lengthscale.flip(-1).pow(2)\n",
    "grad_diag = grad_diag.transpose(-1, -2).reshape(*batch_shape, M * d)\n",
    "grad_diag\n",
    "pi = torch.arange(M * d).view(d, M).t().reshape((M * d))\n",
    "grad_diag[..., pi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84a61bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1600, 0.0400])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/lengthscale.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fdf308d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
       "        0.0400, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600,\n",
       "        0.1600, 0.1600])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(K_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbf4b36b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (18) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([LL, LR], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m reconstructed_hessian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([U, L], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m (\u001b[43mreconstructed_hessian\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK_hess\u001b[49m)\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (18) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "K_matrix = K.to_dense()\n",
    "LR = K_matrix[:N, :M]\n",
    "UL = K_matrix[N:, M:]\n",
    "LL = - K_matrix[N:, :M]\n",
    "UR = - K_matrix[:N, M:]\n",
    "\n",
    "U = torch.concat([UL, UR], dim = -1)\n",
    "L = torch.concat([LL, LR], dim = -1)\n",
    "reconstructed_hessian = torch.concat([U, L], dim = 0)\n",
    "\n",
    "(reconstructed_hessian == K_hess).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7695bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe35d1fa230>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGdCAYAAADnmo8wAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH+hJREFUeJzt3X9wVPX97/HXJsjGOmSRErJZCb+UHxVJolFiKBS4SU0yDiXUUszQS0CkMw50dDL4I44Q/HGbqlWpJQO2V4x+rQLOaOwokxaiQJnwoxAzFaflkjSQcGGDyTVZEq8Bk71/eF27kk/IymezsHk+Zs4M55zPOXnvspNXPnt2z9vh9/v9AgCgFzGRLgAAcPkiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgNGQSBdgQ09Pj06dOqVhw4bJ4XBEuhwAuKz5/X6dPXtWHo9HMTF9zxWiIiROnTql5OTkSJcBAFeUpqYmjR49us8xURESw4YNkyTdtGiNYofGXdK5rv2vgzZKkiQNGdv3kw+ExNYsmTvxDHpf9pzTrqY/Bn539iUqQuLrt5hih8ZdckgMcVxlo6SvzhXjtHYugJCAbf15e54L1wAAI0ICAGAUtpAoKyvTuHHjFBcXp4yMDB082Pd7/W+99ZamTJmiuLg4TZs2Tdu3bw9XaQCAfgpLSGzdulVFRUUqKSlRTU2NUlNTlZOTozNnzvQ6vrq6WgUFBVq+fLk++ugj5efnKz8/X0eOHAlHeQCAfnKEo+lQRkaGbrvtNm3YsEHSV99jSE5O1q9+9Ss98sgjF4xftGiROjs79d577wW23X777UpLS9OmTZsu+vN8Pp9cLpdS//v/uOQL1yM277uk4//TkHFjrJ0L4MI1bPmyp0s7T5Spvb1d8fHxfY61PpM4d+6cDh8+rOzs7G9+SEyMsrOztW9f77+A9+3bFzReknJycozju7q65PP5ghYAgH3WQ6KlpUXd3d1KTEwM2p6YmCiv19vrMV6vN6TxpaWlcrlcgYUv0gFAeFyRn24qLi5We3t7YGlqaop0SQAQlax/mW7kyJGKjY1Vc3Nz0Pbm5ma53e5ej3G73SGNdzqdcjr5ohoAhJv1mcTQoUOVnp6uqqqqwLaenh5VVVUpMzOz12MyMzODxkvSjh07jOMBAAMjLLflKCoqUmFhoW699VZNnz5d69evV2dnp5YtWyZJWrJkia677jqVlpZKku6//37Nnj1bzz33nO68805t2bJFhw4d0h/+8IdwlAcA6KewhMSiRYv06aefau3atfJ6vUpLS1NlZWXg4nRjY2PQ7WlnzJihN954Q4899pgeffRRTZw4URUVFbrpppvCUR4AoJ/C8j2Jgcb3JDAo8D0JWBLR70kAAKJHVNwq/GvX/tfBS77V9/+5x97FcluzEmYkVzCbnRJtzQAux5pw2WImAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARlHVvnTI2NEaEuO8pHPYajkq2WuFarMmWqEOMJvtPW21HY32mmAVMwkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACPrIVFaWqrbbrtNw4YN06hRo5Sfn6+jR4/2eUx5ebkcDkfQEhcXZ7s0AECIrIfE7t27tXLlSu3fv187duzQ+fPndccdd6izs7PP4+Lj43X69OnAcuLECdulAQBCZL3pUGVlZdB6eXm5Ro0apcOHD+tHP/qR8TiHwyG32227HADAJQh7Z7r29nZJ0ogRI/oc19HRobFjx6qnp0e33HKLfv3rX2vq1Km9ju3q6lJXV1dg3efzWavXZuc2Wx3lbHW4k+zVRIe7CLDVvc1WNzkpumuCpDBfuO7p6dEDDzygH/7wh7rpppuM4yZPnqzNmzfr3Xff1euvv66enh7NmDFDJ0+e7HV8aWmpXC5XYElOTg7XQwCAQS2sIbFy5UodOXJEW7Zs6XNcZmamlixZorS0NM2ePVtvv/22EhIS9NJLL/U6vri4WO3t7YGlqakpHOUDwKAXtrebVq1apffee0979uzR6NGjQzr2qquu0s0336y6urpe9zudTjmdThtlAgD6YH0m4ff7tWrVKr3zzjv64IMPNH78+JDP0d3drY8//lhJSUm2ywMAhMD6TGLlypV644039O6772rYsGHyer2SJJfLpauvvlqStGTJEl133XUqLS2VJD3xxBO6/fbbdcMNN6itrU3PPvusTpw4oXvvvdd2eQCAEFgPiY0bN0qS5syZE7T9lVde0dKlSyVJjY2Nion5ZhLz2WefacWKFfJ6vbr22muVnp6u6upq3XjjjbbLAwCEwHpI+Pvx8bNdu3YFrb/wwgt64YUXbJcCALhE3LsJAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAUdjblw5mtlp82mo5KtlrhWqzJlqhDjCb7T1ttR2N9pquYMwkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEZ0prsC2OzcZqujnK0Od5K9muhwFwG2urfZ6iYnRXdNEcBMAgBgREgAAIwICQCAESEBADAiJAAARtZDYt26dXI4HEHLlClT+jzmrbfe0pQpUxQXF6dp06Zp+/bttssCAHwHYZlJTJ06VadPnw4se/fuNY6trq5WQUGBli9fro8++kj5+fnKz8/XkSNHwlEaACAEYQmJIUOGyO12B5aRI0cax/7ud79Tbm6uHnzwQf3gBz/Qk08+qVtuuUUbNmwIR2kAgBCEJSSOHTsmj8ejCRMmaPHixWpsbDSO3bdvn7Kzs4O25eTkaN8+8xesurq65PP5ghYAgH3WQyIjI0Pl5eWqrKzUxo0b1dDQoFmzZuns2bO9jvd6vUpMTAzalpiYKK/Xa/wZpaWlcrlcgSU5OdnqYwAAfMV6SOTl5WnhwoVKSUlRTk6Otm/frra2Nm3bts3azyguLlZ7e3tgaWpqsnZuAMA3wn7vpuHDh2vSpEmqq6vrdb/b7VZzc3PQtubmZrndbuM5nU6nnE6n1ToBABcK+/ckOjo6VF9fr6SkpF73Z2ZmqqqqKmjbjh07lJlp7wZyAIDvxnpIrF69Wrt379bx48dVXV2tBQsWKDY2VgUFBZKkJUuWqLi4ODD+/vvvV2VlpZ577jn961//0rp163To0CGtWrXKdmkAgBBZf7vp5MmTKigoUGtrqxISEjRz5kzt379fCQkJkqTGxkbFxHyTTTNmzNAbb7yhxx57TI8++qgmTpyoiooK3XTTTbZLAwCEyHpIbNmypc/9u3btumDbwoULtXDhQtulAAAuEfduAgAYERIAACPalw4ytlp82mo5KtlrhWqzJlqhDjCb7T1ttR2N9pr6iZkEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIjOdPhObHZus9VRzlaHO8leTXS4iwBb3dtsdZOTLr+aQjgPMwkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACPrITFu3Dg5HI4LlpUrV/Y6vry8/IKxcXFxtssCAHwH1vtJ/P3vf1d3d3dg/ciRI/rxj3+shQsXGo+Jj4/X0aNHA+sOm/dxBwB8Z9ZDIiEhIWj9N7/5ja6//nrNnj3beIzD4ZDb7bZdCgDgEoX1msS5c+f0+uuv65577ulzdtDR0aGxY8cqOTlZ8+fP1yeffBLOsgAA/RTW9qUVFRVqa2vT0qVLjWMmT56szZs3KyUlRe3t7frtb3+rGTNm6JNPPtHo0aN7Paarq0tdXV2BdZ/PZ7t0DCBbLT5ttRyV7LVCHfXB/7ZyHkSArZajkr22o7ZqCuE8YZ1JvPzyy8rLy5PH4zGOyczM1JIlS5SWlqbZs2fr7bffVkJCgl566SXjMaWlpXK5XIElOTk5HOUDwKAXtpA4ceKEdu7cqXvvvTek46666irdfPPNqqurM44pLi5We3t7YGlqarrUcgEAvQhbSLzyyisaNWqU7rzzzpCO6+7u1scff6ykpCTjGKfTqfj4+KAFAGBfWEKip6dHr7zyigoLCzVkSPBljyVLlqi4uDiw/sQTT+ivf/2r/v3vf6umpka/+MUvdOLEiZBnIAAA+8Jy4Xrnzp1qbGzUPffcc8G+xsZGxcR8k02fffaZVqxYIa/Xq2uvvVbp6emqrq7WjTfeGI7SAAAhcPj9Ni/hR4bP55PL5VL22JUaEuOMdDmIkC+PN1o7F59uglWX2aebvuzp0s4TZWpvb7/o2/XcuwkAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIBRWDvTAQPJVoc7yWKXO4s14Qpm6xZ5tu4BFcJ5mEkAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIAR7Uu/zVZ7QMley0IMOFutUN+v/rOV80jSf1t6r5XzXP2/zlg5DyLA1u+UEM7DTAIAYERIAACMCAkAgBEhAQAwIiQAAEYhh8SePXs0b948eTweORwOVVRUBO33+/1au3atkpKSdPXVVys7O1vHjh276HnLyso0btw4xcXFKSMjQwcPHgy1NACAZSGHRGdnp1JTU1VWVtbr/meeeUYvvviiNm3apAMHDuiaa65RTk6OvvjiC+M5t27dqqKiIpWUlKimpkapqanKycnRmTN8VA8AIinkkMjLy9NTTz2lBQsWXLDP7/dr/fr1euyxxzR//nylpKTotdde06lTpy6Ycfyn559/XitWrNCyZct04403atOmTfre976nzZs3h1oeAMAiq9ckGhoa5PV6lZ2dHdjmcrmUkZGhffv29XrMuXPndPjw4aBjYmJilJ2dbTymq6tLPp8vaAEA2Gc1JLxeryQpMTExaHtiYmJg37e1tLSou7s7pGNKS0vlcrkCS3JysoXqAQDfdkV+uqm4uFjt7e2BpampKdIlAUBUshoSbrdbktTc3By0vbm5ObDv20aOHKnY2NiQjnE6nYqPjw9aAAD2WQ2J8ePHy+12q6qqKrDN5/PpwIEDyszM7PWYoUOHKj09PeiYnp4eVVVVGY8BAAyMkO8C29HRobq6usB6Q0ODamtrNWLECI0ZM0YPPPCAnnrqKU2cOFHjx4/XmjVr5PF4lJ+fHzgmKytLCxYs0KpVqyRJRUVFKiws1K233qrp06dr/fr16uzs1LJlyy79EQIAvrOQQ+LQoUOaO3duYL2oqEiSVFhYqPLycj300EPq7OzUL3/5S7W1tWnmzJmqrKxUXFxc4Jj6+nq1tLQE1hctWqRPP/1Ua9euldfrVVpamiorKy+4mA0AGFgOv//Kb3rg8/nkcrmUPXalhsQ4L+1k9JOARfSTwOXoy54u7TxRpvb29ote070iP90EABgY0dWZzuG49JmAzb/+bc1KmJFcsWz99S9JH5T/TyvnsVkTs5Lox0wCAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMoqt9qd9/6a0+bbUcley1Hb0ca0K/2GzvaavtqK02qJK9mmiDevliJgEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYBRySOzZs0fz5s2Tx+ORw+FQRUVFYN/58+f18MMPa9q0abrmmmvk8Xi0ZMkSnTp1qs9zrlu3Tg6HI2iZMmVKyA8GAGBXyCHR2dmp1NRUlZWVXbDv888/V01NjdasWaOamhq9/fbbOnr0qH7yk59c9LxTp07V6dOnA8vevXtDLQ0AYFnITYfy8vKUl5fX6z6Xy6UdO3YEbduwYYOmT5+uxsZGjRkzxlzIkCFyu92hlgMACKOwd6Zrb2+Xw+HQ8OHD+xx37NgxeTwexcXFKTMzU6WlpcZQ6erqUldXV2Dd5/PZK9hm5zZbHeWivSb0i63ubba6yUn2utzZrIkud3aF9cL1F198oYcfflgFBQWKj483jsvIyFB5ebkqKyu1ceNGNTQ0aNasWTp79myv40tLS+VyuQJLcnJyuB4CAAxqYQuJ8+fP6+c//7n8fr82btzY59i8vDwtXLhQKSkpysnJ0fbt29XW1qZt27b1Or64uFjt7e2BpampKRwPAQAGvbC83fR1QJw4cUIffPBBn7OI3gwfPlyTJk1SXV1dr/udTqecTqeNUgEAfbA+k/g6II4dO6adO3fq+9//fsjn6OjoUH19vZKSkmyXBwAIQcgh0dHRodraWtXW1kqSGhoaVFtbq8bGRp0/f14/+9nPdOjQIf3pT39Sd3e3vF6vvF6vzp07FzhHVlaWNmzYEFhfvXq1du/erePHj6u6uloLFixQbGysCgoKLv0RAgC+s5Dfbjp06JDmzp0bWC8qKpIkFRYWat26dfrzn/8sSUpLSws67sMPP9ScOXMkSfX19WppaQnsO3nypAoKCtTa2qqEhATNnDlT+/fvV0JCQqjlAQAsCjkk5syZI38fH3/sa9/Xjh8/HrS+ZcuWUMsAAAwA7t0EADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAKOztSwc1Wy0+bbUclaK7JvSLzfaettqO2mqDKtmriTaoX2EmAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADCiM92VwGbnNlsd5aK9JvSLre5ttrrJSfa63Nms6UrucsdMAgBgREgAAIwICQCAESEBADAiJAAARiGHxJ49ezRv3jx5PB45HA5VVFQE7V+6dKkcDkfQkpube9HzlpWVady4cYqLi1NGRoYOHjwYamkAAMtCDonOzk6lpqaqrKzMOCY3N1enT58OLG+++Waf59y6dauKiopUUlKimpoapaamKicnR2fOXLkfGwOAaBDy9yTy8vKUl5fX5xin0ym3293vcz7//PNasWKFli1bJknatGmT3n//fW3evFmPPPJIqCUCACwJyzWJXbt2adSoUZo8ebLuu+8+tba2GseeO3dOhw8fVnZ29jdFxcQoOztb+/bt6/WYrq4u+Xy+oAUAYJ/1kMjNzdVrr72mqqoqPf3009q9e7fy8vLU3d3d6/iWlhZ1d3crMTExaHtiYqK8Xm+vx5SWlsrlcgWW5ORk2w8DAKAw3Jbj7rvvDvx72rRpSklJ0fXXX69du3YpKyvLys8oLi5WUVFRYN3n8xEUABAGYf8I7IQJEzRy5EjV1dX1un/kyJGKjY1Vc3Nz0Pbm5mbjdQ2n06n4+PigBQBgX9hD4uTJk2ptbVVSUlKv+4cOHar09HRVVVUFtvX09KiqqkqZmZnhLg8A0IeQQ6Kjo0O1tbWqra2VJDU0NKi2tlaNjY3q6OjQgw8+qP379+v48eOqqqrS/PnzdcMNNygnJydwjqysLG3YsCGwXlRUpD/+8Y969dVX9c9//lP33XefOjs7A592AgBERsjXJA4dOqS5c+cG1r++NlBYWKiNGzfqH//4h1599VW1tbXJ4/Hojjvu0JNPPimn0xk4pr6+Xi0tLYH1RYsW6dNPP9XatWvl9XqVlpamysrKCy5mAwAGVsghMWfOHPn7uG//X/7yl4ue4/jx4xdsW7VqlVatWhVqOQCAMOLeTQAAI0ICAGBE+9LBxlaLT1stR6Xorgn9YrO9p622o7baoEr2aopEG1RmEgAAI0ICAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjOtPhu7HZuc1WR7lorwn9Yqt7m61ucpK9Lne2avryyy+kE/0by0wCAGBESAAAjAgJAIARIQEAMCIkAABGhAQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMAo5JDYs2eP5s2bJ4/HI4fDoYqKiqD9Doej1+XZZ581nnPdunUXjJ8yZUrIDwYAYFfIIdHZ2anU1FSVlZX1uv/06dNBy+bNm+VwOHTXXXf1ed6pU6cGHbd3795QSwMAWBZy06G8vDzl5eUZ97vd7qD1d999V3PnztWECRP6LmTIkAuOBQBEVlivSTQ3N+v999/X8uXLLzr22LFj8ng8mjBhghYvXqzGxkbj2K6uLvl8vqAFAGBfWNuXvvrqqxo2bJh++tOf9jkuIyND5eXlmjx5sk6fPq3HH39cs2bN0pEjRzRs2LALxpeWlurxxx8PV9kYaLZafNpqOSrRdhTW2qBK9tqO2mqD6jvbo2sn9W9sWGcSmzdv1uLFixUXF9fnuLy8PC1cuFApKSnKycnR9u3b1dbWpm3btvU6vri4WO3t7YGlqakpHOUDwKAXtpnE3/72Nx09elRbt24N+djhw4dr0qRJqqur63W/0+mU0+m81BIBABcRtpnEyy+/rPT0dKWmpoZ8bEdHh+rr65WUlBSGygAA/RVySHR0dKi2tla1tbWSpIaGBtXW1gZdaPb5fHrrrbd07729vw+XlZWlDRs2BNZXr16t3bt36/jx46qurtaCBQsUGxurgoKCUMsDAFgU8ttNhw4d0ty5cwPrRUVFkqTCwkKVl5dLkrZs2SK/32/8JV9fX6+WlpbA+smTJ1VQUKDW1lYlJCRo5syZ2r9/vxISEkItDwBgkcPvv/I/xuHz+eRyuZQ9dqWGxHCtYtDi0024TP3fSaOsnMfup5v+rfb2dsXHx/c5lns3AQCMCAkAgBEhAQAwIiQAAEaEBADAiJAAABgREgAAI0ICAGBESAAAjAgJAIARIQEAMAprZzpgQNm835Kt+0BxDyjIXpc7Wx3uvvzyC0nr+jWWmQQAwIiQAAAYERIAACNCAgBgREgAAIwICQCAESEBADAiJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAKCo60/n/f/evL3vORbgSRA060+Ey9FVHOXvn8ffj9enw92fUZe7kyZNKTk6OdBkAcEVpamrS6NGj+xwTFSHR09OjU6dOadiwYXL08Regz+dTcnKympqaFB8fP4AVDk483wOP53xgXanPt9/v19mzZ+XxeBQT0/dVh6h4uykmJuaiafif4uPjr6j/0Csdz/fA4zkfWFfi8+1yufo1jgvXAAAjQgIAYDSoQsLpdKqkpEROpzPSpQwKPN8Dj+d8YA2G5zsqLlwDAMJjUM0kAAChISQAAEaEBADAiJAAABgNmpAoKyvTuHHjFBcXp4yMDB08eDDSJUWtdevWyeFwBC1TpkyJdFlRY8+ePZo3b548Ho8cDocqKiqC9vv9fq1du1ZJSUm6+uqrlZ2drWPHjkWm2Chxsed86dKlF7zmc3NzI1OsZYMiJLZu3aqioiKVlJSopqZGqampysnJ0ZkzZyJdWtSaOnWqTp8+HVj27t0b6ZKiRmdnp1JTU1VWVtbr/meeeUYvvviiNm3apAMHDuiaa65RTk6OvvjCzs3hBqOLPeeSlJubG/Saf/PNNwewwjDyDwLTp0/3r1y5MrDe3d3t93g8/tLS0ghWFb1KSkr8qampkS5jUJDkf+eddwLrPT09frfb7X/22WcD29ra2vxOp9P/5ptvRqDC6PPt59zv9/sLCwv98+fPj0g94Rb1M4lz587p8OHDys7ODmyLiYlRdna29u3bF8HKotuxY8fk8Xg0YcIELV68WI2NjZEuaVBoaGiQ1+sNer27XC5lZGTweg+zXbt2adSoUZo8ebLuu+8+tba2RrokK6I+JFpaWtTd3a3ExMSg7YmJifJ6vRGqKrplZGSovLxclZWV2rhxoxoaGjRr1iydPXs20qVFva9f07zeB1Zubq5ee+01VVVV6emnn9bu3buVl5en7u7uSJd2yaLiLrC4vOTl5QX+nZKSooyMDI0dO1bbtm3T8uXLI1gZEB5333134N/Tpk1TSkqKrr/+eu3atUtZWVkRrOzSRf1MYuTIkYqNjVVzc3PQ9ubmZrnd7ghVNbgMHz5ckyZNUl1dXaRLiXpfv6Z5vUfWhAkTNHLkyKh4zUd9SAwdOlTp6emqqqoKbOvp6VFVVZUyMzMjWNng0dHRofr6eiUlJUW6lKg3fvx4ud3uoNe7z+fTgQMHeL0PoJMnT6q1tTUqXvOD4u2moqIiFRYW6tZbb9X06dO1fv16dXZ2atmyZZEuLSqtXr1a8+bN09ixY3Xq1CmVlJQoNjZWBQUFkS4tKnR0dAT9hdrQ0KDa2lqNGDFCY8aM0QMPPKCnnnpKEydO1Pjx47VmzRp5PB7l5+dHrugrXF/P+YgRI/T444/rrrvuktvtVn19vR566CHdcMMNysnJiWDVlkT641UD5fe//71/zJgx/qFDh/qnT5/u379/f6RLilqLFi3yJyUl+YcOHeq/7rrr/IsWLfLX1dVFuqyo8eGHH/olXbAUFhb6/f6vPga7Zs0af2Jiot/pdPqzsrL8R48ejWzRV7i+nvPPP//cf8cdd/gTEhL8V111lX/s2LH+FStW+L1eb6TLtoJbhQMAjKL+mgQA4LsjJAAARoQEAMCIkAAAGBESAAAjQgIAYERIAACMCAkAgBEhAQAwIiQAAEaEBADAiJAAABj9PzrLzla+TK7QAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(K.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3184383f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     1.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     1.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000,\n",
       "             0.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             1.0000,     0.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     1.0000,     0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     1.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "             0.0000,     0.0000,     0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "K_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "508ae789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33, -1.78, -4.44,\n",
       "         -2.22, -5.56, -2.67, -6.67, -3.11, -7.78, -3.56, -8.89],\n",
       "        [ 0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33,\n",
       "         -1.78, -4.44, -2.22, -5.56, -2.67, -6.67, -3.11, -7.78],\n",
       "        [ 0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22,\n",
       "         -1.33, -3.33, -1.78, -4.44, -2.22, -5.56, -2.67, -6.67],\n",
       "        [ 1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11,\n",
       "         -0.89, -2.22, -1.33, -3.33, -1.78, -4.44, -2.22, -5.56],\n",
       "        [ 1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00,\n",
       "         -0.44, -1.11, -0.89, -2.22, -1.33, -3.33, -1.78, -4.44],\n",
       "        [ 2.22,  5.56,  1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11,\n",
       "          0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33],\n",
       "        [ 2.67,  6.67,  2.22,  5.56,  1.78,  4.44,  1.33,  3.33,  0.89,  2.22,\n",
       "          0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22],\n",
       "        [ 3.11,  7.78,  2.67,  6.67,  2.22,  5.56,  1.78,  4.44,  1.33,  3.33,\n",
       "          0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11],\n",
       "        [ 3.56,  8.89,  3.11,  7.78,  2.67,  6.67,  2.22,  5.56,  1.78,  4.44,\n",
       "          1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00],\n",
       "        [ 4.00, 10.00,  3.56,  8.89,  3.11,  7.78,  2.67,  6.67,  2.22,  5.56,\n",
       "          1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11],\n",
       "        [ 0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33, -1.78, -4.44,\n",
       "         -2.22, -5.56, -2.67, -6.67, -3.11, -7.78, -3.56, -8.89],\n",
       "        [ 0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33,\n",
       "         -1.78, -4.44, -2.22, -5.56, -2.67, -6.67, -3.11, -7.78],\n",
       "        [ 0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22,\n",
       "         -1.33, -3.33, -1.78, -4.44, -2.22, -5.56, -2.67, -6.67],\n",
       "        [ 1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11,\n",
       "         -0.89, -2.22, -1.33, -3.33, -1.78, -4.44, -2.22, -5.56],\n",
       "        [ 1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00,\n",
       "         -0.44, -1.11, -0.89, -2.22, -1.33, -3.33, -1.78, -4.44],\n",
       "        [ 2.22,  5.56,  1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11,\n",
       "          0.00,  0.00, -0.44, -1.11, -0.89, -2.22, -1.33, -3.33],\n",
       "        [ 2.67,  6.67,  2.22,  5.56,  1.78,  4.44,  1.33,  3.33,  0.89,  2.22,\n",
       "          0.44,  1.11,  0.00,  0.00, -0.44, -1.11, -0.89, -2.22],\n",
       "        [ 3.11,  7.78,  2.67,  6.67,  2.22,  5.56,  1.78,  4.44,  1.33,  3.33,\n",
       "          0.89,  2.22,  0.44,  1.11,  0.00,  0.00, -0.44, -1.11],\n",
       "        [ 3.56,  8.89,  3.11,  7.78,  2.67,  6.67,  2.22,  5.56,  1.78,  4.44,\n",
       "          1.33,  3.33,  0.89,  2.22,  0.44,  1.11,  0.00,  0.00],\n",
       "        [ 4.00, 10.00,  3.56,  8.89,  3.11,  7.78,  2.67,  6.67,  2.22,  5.56,\n",
       "          1.78,  4.44,  1.33,  3.33,  0.89,  2.22,  0.44,  1.11]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x\n",
    "x2 = x[0:9]\n",
    "\n",
    "batch_shape = x1.shape[:-2]\n",
    "n_batch_dims = len(batch_shape)\n",
    "n1, d = x1.shape[-2:]\n",
    "# d must be same\n",
    "n2 = x2.shape[-2]\n",
    "\n",
    "x1_ = x1.div(lengthscale)\n",
    "x2_ = x2.div(lengthscale)\n",
    "\n",
    "outer = x1_.view(*batch_shape, n1, 1, d) - x2_.view(*batch_shape, 1, n2, d)\n",
    "outer = outer / lengthscale.unsqueeze(-2)\n",
    "outer = torch.transpose(outer, -1, -2).contiguous()\n",
    "outer.shape\n",
    "\n",
    "outer1.repeat([*([1] * n_batch_dims), d, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5a46c729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00, 10.00],\n",
       "        [ 0.22, 20.00],\n",
       "        [ 0.44, 30.00],\n",
       "        [ 0.67, 40.00],\n",
       "        [ 0.89, 50.00],\n",
       "        [ 1.11, 60.00],\n",
       "        [ 1.33, 70.00],\n",
       "        [ 1.56, 80.00],\n",
       "        [ 1.78, 90.00]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "460d7c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 18])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_11.repeat([*([1] * n_batch_dims), d, d]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08684d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(n1, n2, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ed95a879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(d, d, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08546c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 18])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer1 = outer.view(*batch_shape, n1, n2 * d)\n",
    "outer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_shape = x1.shape[:-2]\n",
    "        n_batch_dims = len(batch_shape)\n",
    "        n1, d = x1.shape[-2:]\n",
    "        n2 = x2.shape[-2]\n",
    "\n",
    "        if not diag:\n",
    "            K = torch.zeros(*batch_shape, n1 * (d + 1), n2 * (d + 1), device=x1.device, dtype=x1.dtype)\n",
    "\n",
    "            # Scale the inputs by the lengthscale (for stability)\n",
    "            x1_ = x1.div(self.lengthscale)\n",
    "            x2_ = x2.div(self.lengthscale)\n",
    "\n",
    "            # Form all possible rank-1 products for the gradient and Hessian blocks\n",
    "            outer = x1_.view(*batch_shape, n1, 1, d) - x2_.view(*batch_shape, 1, n2, d)\n",
    "            outer = outer / self.lengthscale.unsqueeze(-2)\n",
    "            outer = torch.transpose(outer, -1, -2).contiguous()\n",
    "\n",
    "            # 1) Kernel block\n",
    "            diff = self.covar_dist(x1_, x2_, square_dist=True, **params)\n",
    "            K_11 = postprocess_rbf(diff)\n",
    "            K[..., :n1, :n2] = K_11\n",
    "\n",
    "            # 2) First gradient block\n",
    "            outer1 = outer.view(*batch_shape, n1, n2 * d)\n",
    "            K[..., :n1, n2:] = outer1 * K_11.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "\n",
    "            # 3) Second gradient block\n",
    "            outer2 = outer.transpose(-1, -3).reshape(*batch_shape, n2, n1 * d)\n",
    "            outer2 = outer2.transpose(-1, -2)\n",
    "            K[..., n1:, :n2] = -outer2 * K_11.repeat([*([1] * n_batch_dims), d, 1])\n",
    "\n",
    "            # 4) Hessian block\n",
    "            outer3 = outer1.repeat([*([1] * n_batch_dims), d, 1]) * outer2.repeat([*([1] * (n_batch_dims + 1)), d])\n",
    "            kp = KroneckerProductLinearOperator(\n",
    "                torch.eye(d, d, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1) / self.lengthscale.pow(2),\n",
    "                torch.ones(n1, n2, device=x1.device, dtype=x1.dtype).repeat(*batch_shape, 1, 1),\n",
    "            )\n",
    "            chain_rule = kp.to_dense() - outer3\n",
    "            K[..., n1:, n2:] = chain_rule * K_11.repeat([*([1] * n_batch_dims), d, d])\n",
    "\n",
    "            # Symmetrize for stability\n",
    "            if n1 == n2 and torch.eq(x1, x2).all():\n",
    "                K = 0.5 * (K.transpose(-1, -2) + K)\n",
    "\n",
    "            # Apply a perfect shuffle permutation to match the MutiTask ordering\n",
    "            pi1 = torch.arange(n1 * (d + 1)).view(d + 1, n1).t().reshape((n1 * (d + 1)))\n",
    "            pi2 = torch.arange(n2 * (d + 1)).view(d + 1, n2).t().reshape((n2 * (d + 1)))\n",
    "            K = K[..., pi1, :][..., :, pi2]\n",
    "\n",
    "            return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fff902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch_models import dfGP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
