{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bf128c",
   "metadata": {},
   "source": [
    "# Start with dfGP for real data\n",
    "\n",
    "- check if noise is enough\n",
    "- liklihood: observation specific noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== CURVE ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "Training inputs device: cuda:0\n",
      "Training observations device: cuda:0\n",
      "\n",
      "=== CURVE ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "Test inputs device: cuda:0\n",
      "Test observations device: cuda:0\n",
      "\n",
      "\n",
      "--- Training Run 1/1 ---\n",
      "\n",
      "Start Training\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dfRBFKernel' object has no attribute 'data_covar_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 226\u001b[0m\n\u001b[1;32m    224\u001b[0m sigma_n_over_epochs[epoch] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mnoise\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    225\u001b[0m sigma_f_over_epochs[epoch] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcovar_module\u001b[38;5;241m.\u001b[39moutputscale\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 226\u001b[0m l1_over_epochs[epoch] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_covar_module\u001b[49m\u001b[38;5;241m.\u001b[39mlengthscale[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    227\u001b[0m l2_over_epochs[epoch] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbase_kernel\u001b[38;5;241m.\u001b[39mdata_covar_module\u001b[38;5;241m.\u001b[39mlengthscale[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Print a bit more information for the first run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ice_thickness_gpytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dfRBFKernel' object has no attribute 'data_covar_module'"
     ]
    }
   ],
   "source": [
    "# REAL DATA EXPERIMENTS\n",
    "# RUN WITH python run_real_experiments_dfGP.py\n",
    "#               _                 _   _      \n",
    "#              | |               | | (_)     \n",
    "#    __ _ _ __ | |_ __ _ _ __ ___| |_ _  ___ \n",
    "#   / _` | '_ \\| __/ _` | '__/ __| __| |/ __|\n",
    "#  | (_| | | | | || (_| | | | (__| |_| | (__ \n",
    "#   \\__,_|_| |_|\\__\\__,_|_|  \\___|\\__|_|\\___|\n",
    "# \n",
    "model_name = \"dfGP\"\n",
    "from gpytorch_models import dfGP\n",
    "\n",
    "# import configs to we can access the hypers with getattr\n",
    "import configs\n",
    "from configs import PATIENCE, MAX_NUM_EPOCHS, NUM_RUNS, WEIGHT_DECAY\n",
    "from configs import TRACK_EMISSIONS_BOOL\n",
    "\n",
    "# Reiterating import for visibility\n",
    "MAX_NUM_EPOCHS = MAX_NUM_EPOCHS\n",
    "NUM_RUNS = NUM_RUNS\n",
    "NUM_RUNS = 1\n",
    "WEIGHT_DECAY = WEIGHT_DECAY\n",
    "PATIENCE = PATIENCE\n",
    "\n",
    "# assign model-specific variable\n",
    "MODEL_LEARNING_RATE = getattr(configs, f\"{model_name}_REAL_LEARNING_RATE\")\n",
    "MODEL_REAL_RESULTS_DIR = getattr(configs, f\"{model_name}_REAL_RESULTS_DIR\")\n",
    "import os\n",
    "os.makedirs(MODEL_REAL_RESULTS_DIR, exist_ok = True)\n",
    "\n",
    "# basics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "# universals \n",
    "from metrics import compute_divergence_field\n",
    "from utils import set_seed, make_grid\n",
    "import gc\n",
    "import warnings\n",
    "set_seed(42)\n",
    "\n",
    "# setting device to GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# overwrite if needed: # device = 'cpu'\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "### START TIMING ###\n",
    "import time\n",
    "start_time = time.time()  # Start timing after imports\n",
    "\n",
    "### START TRACKING EXPERIMENT EMISSIONS ###\n",
    "if TRACK_EMISSIONS_BOOL:\n",
    "    from codecarbon import EmissionsTracker\n",
    "    tracker = EmissionsTracker(project_name = \"dfGP_real_experiments\", output_dir = MODEL_REAL_RESULTS_DIR)\n",
    "    tracker.start()\n",
    "\n",
    "#############################\n",
    "### LOOP 1 - over REGIONS ###\n",
    "#############################\n",
    "\n",
    "for region_name in [\"region_lower_byrd\", \"region_mid_byrd\", \"region_upper_byrd\"]:\n",
    "\n",
    "    print(f\"\\nTraining for {region_name.upper()}...\")\n",
    "\n",
    "    # Store metrics for the current region (used for *metrics_summary* report and *metrics_per_run*)\n",
    "    region_results = []\n",
    "\n",
    "    ##########################################\n",
    "    ### x_train & y_train, x_test & x_test ###\n",
    "    ##########################################\n",
    "\n",
    "    # define paths based on region_name\n",
    "    path_to_training_tensor = \"data/real_data/\" + region_name + \"_train_tensor.pt\"\n",
    "    path_to_test_tensor = \"data/real_data/\" + region_name + \"_test_tensor.pt\"\n",
    "\n",
    "    # load and tranpose to have rows as points\n",
    "    train = torch.load(path_to_training_tensor, weights_only = False).T \n",
    "    test = torch.load(path_to_test_tensor, weights_only = False).T\n",
    "\n",
    "    # The train and test tensors have the following columns:\n",
    "    # [:, 0] = x\n",
    "    # [:, 1] = y\n",
    "    # [:, 2] = surface elevation (s)\n",
    "    # [:, 3] = ice flux in x direction (u)\n",
    "    # [:, 4] = ice flux in y direction (v)\n",
    "    # [:, 5] = ice flux error in x direction (u_err)\n",
    "    # [:, 6] = ice flux error in y direction (v_err)\n",
    "    # [:, 7] = source age\n",
    "\n",
    "    # train\n",
    "    x_train = train[:, [0, 1]].to(device)\n",
    "    y_train = train[:, [3, 4]].to(device)\n",
    "\n",
    "    # test\n",
    "    x_test = test[:, [0, 1]].to(device)\n",
    "    y_test = test[:, [3, 4]].to(device)\n",
    "\n",
    "    ### NOISE MODEL ###\n",
    "    # TRAIN\n",
    "    # noise variance (h * sigma_u)^2 and (h * sigma_v)^2 (tensor contains [h sig_u, h sig_v] stds)\n",
    "    noise_var_h_times_uv_train = torch.concat((train[:, 5], train[:, 6]), dim = 0)**2\n",
    "    # assume age dependent noise sigma_h on ice thickness measurements: ~10 - 20 m std (1000 scaling)\n",
    "    sigma_h = 0.01 * torch.log(train[:, 7] + 3)\n",
    "    # calculate noise variance (u * sigma_h)^2 and (v * sigma_h)^2\n",
    "    noise_var_uv_times_h_train = (torch.concat((train[:, 3], train[:, 4]), dim = 0) * torch.cat([sigma_h, sigma_h]))**2\n",
    "    # combine both noise variances into the std for each dimension\n",
    "    train_noise_diag = torch.sqrt(noise_var_h_times_uv_train + noise_var_uv_times_h_train).to(device)\n",
    "\n",
    "    # Compute midpoint\n",
    "    midpoint = train_noise_diag.shape[0] // 2\n",
    "\n",
    "    # Print noise levels for train, formatted to 4 decimal places\n",
    "    print(f\"Mean noise std per x dimension: {train_noise_diag[:midpoint].mean(dim = 0).item():.4f}\")\n",
    "    print(f\"Mean noise std per y dimension: {train_noise_diag[midpoint:].mean(dim = 0).item():.4f}\")\n",
    "\n",
    "    # TEST\n",
    "    # noise variance (h * sigma_u)^2 and (h * sigma_v)^2 (tensor contains [h sig_u, h sig_v] stds)\n",
    "    noise_var_h_times_uv_test = torch.concat((test[:, 5], test[:, 6]), dim = 0)**2\n",
    "    # assume age dependent noise sigma_h on ice thickness measurements: ~10 - 20 m std (1000 scaling)\n",
    "    sigma_h = 0.01 * torch.log(test[:, 7] + 3)\n",
    "    # calculate noise variance (u * sigma_h)^2 and (v * sigma_h)^2\n",
    "    noise_var_uv_times_h_test = (torch.concat((test[:, 3], test[:, 4]), dim = 0) * torch.cat([sigma_h, sigma_h]))**2\n",
    "    # combine both noise variances into the std for each dimension\n",
    "    test_noise_diag = torch.sqrt(noise_var_h_times_uv_test + noise_var_uv_times_h_test).to(device)\n",
    "\n",
    "    # Print train details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Training inputs shape: {x_train.shape}\")\n",
    "    print(f\"Training observations shape: {y_train.shape}\")\n",
    "    print(f\"Training inputs dtype: {x_train.dtype}\")\n",
    "    print()\n",
    "\n",
    "    # Print test details\n",
    "    print(f\"=== {region_name.upper()} ===\")\n",
    "    print(f\"Test inputs shape: {x_test.shape}\")\n",
    "    print(f\"Test observations shape: {y_test.shape}\")\n",
    "    print(f\"Test inputs dtype: {x_test.dtype}\")\n",
    "    print()\n",
    "\n",
    "    ##################################\n",
    "    ### LOOP 2 - over training run ###\n",
    "    ##################################\n",
    "\n",
    "    # NOTE: GPs don't train on batches, use full data\n",
    "\n",
    "    for run in range(NUM_RUNS):\n",
    "\n",
    "        print(f\"\\n--- Training Run {run + 1}/{NUM_RUNS} ---\")\n",
    "\n",
    "        # Initialise the likelihood for the GP model (estimates noise)\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "\n",
    "        # Intialise fresh GP model with flat x_train and y_train_noisy (block-flat)\n",
    "        model = dfGP(\n",
    "            x_train.T.reshape(-1),\n",
    "            y_train.T.reshape(-1), \n",
    "            likelihood\n",
    "            ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr = MODEL_LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "        \n",
    "        # Use ExactMarginalLogLikelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        # _________________\n",
    "        # BEFORE EPOCH LOOP\n",
    "        \n",
    "        # Export the convergence just for first run only\n",
    "        if run == 0:\n",
    "            # initialise tensors to store losses over epochs (for convergence plot)\n",
    "            train_losses_NLML_over_epochs = torch.zeros(MAX_NUM_EPOCHS) # objective\n",
    "            train_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS) # by-product\n",
    "            # monitor performance transfer to test (only RMSE easy to calc without covar)\n",
    "            test_losses_RMSE_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "\n",
    "            # NOTE: No sigma_n\n",
    "            sigma_f_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "            l1_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "            l2_over_epochs = torch.zeros(MAX_NUM_EPOCHS)\n",
    "\n",
    "        # Early stopping variables\n",
    "        best_loss = float('inf')\n",
    "        # counter starts at 0\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        ############################\n",
    "        ### LOOP 3 - over EPOCHS ###\n",
    "        ############################\n",
    "        print(\"\\nStart Training\")\n",
    "\n",
    "        for epoch in range(MAX_NUM_EPOCHS):\n",
    "\n",
    "            # Set to train\n",
    "            model.train()\n",
    "            likelihood.train()\n",
    "\n",
    "            # Do a step\n",
    "            optimizer.zero_grad()\n",
    "            # model outputs a multivariate normal distribution\n",
    "            train_pred_dist = model(x_train.T.reshape(-1).to(device))\n",
    "            loss = - mll(train_pred_dist, y_train.T.reshape(-1).to(device))  # negative marginal log likelihood\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # For Run 1 we save a bunch of metrics and update, while for the rest we only update\n",
    "            if run == 0:\n",
    "\n",
    "                model.eval()\n",
    "                likelihood.eval()\n",
    "\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", gpytorch.utils.warnings.GPInputWarning)\n",
    "                    train_pred_dist = model(x_train.T.reshape(-1).to(device))\n",
    "                test_pred_dist = model(x_test.T.reshape(-1).to(device))\n",
    "\n",
    "                # Compute RMSE for training and test predictions (given true data, not noisy)\n",
    "                train_RMSE = torch.sqrt(gpytorch.metrics.mean_squared_error(train_pred_dist, y_train.T.reshape(-1).to(device)))\n",
    "                test_RMSE = torch.sqrt(gpytorch.metrics.mean_squared_error(test_pred_dist, y_test.T.reshape(-1).to(device)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice_thickness_gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
