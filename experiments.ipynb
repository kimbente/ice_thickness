{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualise import visualise_v_stream, visualise_v_quiver\n",
    "from NN_models import dfNN_for_vmap, PINN_backbone\n",
    "from simulate import simulate_convergence, simulate_branching, simulate_ridge, simulate_merge, simulate_deflection\n",
    "from metrics import compute_RMSE, compute_MAE\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.func import vmap, jacfwd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full loop for dfNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONVERGENCE ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== BRANCHING ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== MERGE ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== DEFLECTION ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== RIDGE ===\n",
      "Training inputs shape: torch.Size([196, 2])\n",
      "Training observations shape: torch.Size([196, 2])\n",
      "Training inputs dtype: torch.float32\n",
      "\n",
      "=== Generating test data ===\n",
      "=== CONVERGENCE ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "=== BRANCHING ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "=== MERGE ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "=== DEFLECTION ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "=== RIDGE ===\n",
      "Test inputs shape: torch.Size([400, 2])\n",
      "Test observations shape: torch.Size([400, 2])\n",
      "Test inputs dtype: torch.float32\n",
      "\n",
      "\n",
      "Training for CONVERGENCE...\n",
      "\n",
      "--- Training Run 1/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.4743\n",
      "Epoch 2/5, Training Loss (RMSE): 0.4848\n",
      "Epoch 3/5, Training Loss (RMSE): 0.4601\n",
      "Epoch 4/5, Training Loss (RMSE): 0.4580\n",
      "Epoch 5/5, Training Loss (RMSE): 0.4820\n",
      "Training of dfNN complete for CONVERGENCE. Restored best model.\n",
      "\n",
      "--- Training Run 2/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.5596\n",
      "Epoch 2/5, Training Loss (RMSE): 0.5677\n",
      "Epoch 3/5, Training Loss (RMSE): 0.5741\n",
      "Epoch 4/5, Training Loss (RMSE): 0.5492\n",
      "Epoch 5/5, Training Loss (RMSE): 0.5367\n",
      "Training of dfNN complete for CONVERGENCE. Restored best model.\n",
      "\n",
      "--- Training Run 3/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.6324\n",
      "Epoch 2/5, Training Loss (RMSE): 0.6274\n",
      "Epoch 3/5, Training Loss (RMSE): 0.6077\n",
      "Epoch 4/5, Training Loss (RMSE): 0.5903\n",
      "Epoch 5/5, Training Loss (RMSE): 0.5798\n",
      "Training of dfNN complete for CONVERGENCE. Restored best model.\n",
      "\n",
      "Results saved to results/convergence_dfNN_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results/convergence_dfNN_metrics_summary.csv\n",
      "\n",
      "Training for BRANCHING...\n",
      "\n",
      "--- Training Run 1/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.4578\n",
      "Epoch 2/5, Training Loss (RMSE): 0.4332\n",
      "Epoch 3/5, Training Loss (RMSE): 0.4365\n",
      "Epoch 4/5, Training Loss (RMSE): 0.4600\n",
      "Epoch 5/5, Training Loss (RMSE): 0.4411\n",
      "Training of dfNN complete for BRANCHING. Restored best model.\n",
      "\n",
      "--- Training Run 2/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.4679\n",
      "Epoch 2/5, Training Loss (RMSE): 0.4564\n",
      "Epoch 3/5, Training Loss (RMSE): 0.4431\n",
      "Epoch 4/5, Training Loss (RMSE): 0.4334\n",
      "Epoch 5/5, Training Loss (RMSE): 0.4458\n",
      "Training of dfNN complete for BRANCHING. Restored best model.\n",
      "\n",
      "--- Training Run 3/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.4789\n",
      "Epoch 2/5, Training Loss (RMSE): 0.4825\n",
      "Epoch 3/5, Training Loss (RMSE): 0.4489\n",
      "Epoch 4/5, Training Loss (RMSE): 0.4478\n",
      "Epoch 5/5, Training Loss (RMSE): 0.4571\n",
      "Training of dfNN complete for BRANCHING. Restored best model.\n",
      "\n",
      "Results saved to results/branching_dfNN_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results/branching_dfNN_metrics_summary.csv\n",
      "\n",
      "Training for MERGE...\n",
      "\n",
      "--- Training Run 1/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 1.0105\n",
      "Epoch 2/5, Training Loss (RMSE): 1.0279\n",
      "Epoch 3/5, Training Loss (RMSE): 1.0414\n",
      "Epoch 4/5, Training Loss (RMSE): 1.0124\n",
      "Epoch 5/5, Training Loss (RMSE): 0.9842\n",
      "Training of dfNN complete for MERGE. Restored best model.\n",
      "\n",
      "--- Training Run 2/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.9095\n",
      "Epoch 2/5, Training Loss (RMSE): 0.9282\n",
      "Epoch 3/5, Training Loss (RMSE): 0.8865\n",
      "Epoch 4/5, Training Loss (RMSE): 0.8857\n",
      "Epoch 5/5, Training Loss (RMSE): 0.8762\n",
      "Training of dfNN complete for MERGE. Restored best model.\n",
      "\n",
      "--- Training Run 3/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.9140\n",
      "Epoch 2/5, Training Loss (RMSE): 0.9302\n",
      "Epoch 3/5, Training Loss (RMSE): 0.9357\n",
      "Epoch 4/5, Training Loss (RMSE): 0.9265\n",
      "Epoch 5/5, Training Loss (RMSE): 0.9483\n",
      "Training of dfNN complete for MERGE. Restored best model.\n",
      "\n",
      "Results saved to results/merge_dfNN_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results/merge_dfNN_metrics_summary.csv\n",
      "\n",
      "Training for DEFLECTION...\n",
      "\n",
      "--- Training Run 1/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.8658\n",
      "Epoch 2/5, Training Loss (RMSE): 0.8566\n",
      "Epoch 3/5, Training Loss (RMSE): 0.8066\n",
      "Epoch 4/5, Training Loss (RMSE): 0.8079\n",
      "Epoch 5/5, Training Loss (RMSE): 0.8279\n",
      "Training of dfNN complete for DEFLECTION. Restored best model.\n",
      "\n",
      "--- Training Run 2/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.8813\n",
      "Epoch 2/5, Training Loss (RMSE): 0.9329\n",
      "Epoch 3/5, Training Loss (RMSE): 0.8901\n",
      "Epoch 4/5, Training Loss (RMSE): 0.9045\n",
      "Epoch 5/5, Training Loss (RMSE): 0.8703\n",
      "Training of dfNN complete for DEFLECTION. Restored best model.\n",
      "\n",
      "--- Training Run 3/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 0.9043\n",
      "Epoch 2/5, Training Loss (RMSE): 0.8693\n",
      "Epoch 3/5, Training Loss (RMSE): 0.9058\n",
      "Epoch 4/5, Training Loss (RMSE): 0.9370\n",
      "Epoch 5/5, Training Loss (RMSE): 0.8782\n",
      "Training of dfNN complete for DEFLECTION. Restored best model.\n",
      "\n",
      "Results saved to results/deflection_dfNN_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results/deflection_dfNN_metrics_summary.csv\n",
      "\n",
      "Training for RIDGE...\n",
      "\n",
      "--- Training Run 1/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 1.2483\n",
      "Epoch 2/5, Training Loss (RMSE): 1.2424\n",
      "Epoch 3/5, Training Loss (RMSE): 1.2279\n",
      "Epoch 4/5, Training Loss (RMSE): 1.2223\n",
      "Epoch 5/5, Training Loss (RMSE): 1.2135\n",
      "Training of dfNN complete for RIDGE. Restored best model.\n",
      "\n",
      "--- Training Run 2/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 1.2301\n",
      "Epoch 2/5, Training Loss (RMSE): 1.2011\n",
      "Epoch 3/5, Training Loss (RMSE): 1.2116\n",
      "Epoch 4/5, Training Loss (RMSE): 1.2239\n",
      "Epoch 5/5, Training Loss (RMSE): 1.2201\n",
      "Training of dfNN complete for RIDGE. Restored best model.\n",
      "\n",
      "--- Training Run 3/3 ---\n",
      "\n",
      "Start Training\n",
      "Epoch 1/5, Training Loss (RMSE): 1.1855\n",
      "Epoch 2/5, Training Loss (RMSE): 1.1797\n",
      "Epoch 3/5, Training Loss (RMSE): 1.2033\n",
      "Epoch 4/5, Training Loss (RMSE): 1.1906\n",
      "Epoch 5/5, Training Loss (RMSE): 1.1752\n",
      "Training of dfNN complete for RIDGE. Restored best model.\n",
      "\n",
      "Results saved to results/ridge_dfNN_metrics_per_run.csv\n",
      "\n",
      "Mean & Std saved to results/ridge_dfNN_metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from NN_models import dfNN_for_vmap, PINN_backbone\n",
    "from simulate import simulate_convergence, simulate_branching, simulate_ridge, simulate_merge, simulate_deflection\n",
    "from metrics import compute_RMSE, compute_MAE\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "from torch.func import vmap, jacfwd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "model_name = \"dfNN\"\n",
    "\n",
    "#########################\n",
    "### x_train & y_train ###\n",
    "#########################\n",
    "\n",
    "# Import all simulation functions\n",
    "from simulate import (\n",
    "    simulate_convergence,\n",
    "    simulate_branching,\n",
    "    simulate_merge,\n",
    "    simulate_deflection,\n",
    "    simulate_ridge,\n",
    ")\n",
    "\n",
    "# Define simulations as a dictionary with names as keys to function objects\n",
    "simulations = {\n",
    "    \"convergence\": simulate_convergence,\n",
    "    \"branching\": simulate_branching,\n",
    "    \"merge\": simulate_merge,\n",
    "    \"deflection\": simulate_deflection,\n",
    "    \"ridge\": simulate_ridge,\n",
    "}\n",
    "\n",
    "# Load training inputs\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised_0to1.pt\").float()\n",
    "\n",
    "# Storage dictionaries\n",
    "y_train_dict = {}\n",
    "\n",
    "# Make y_train_dict: Iterate over all simulation functions\n",
    "for name, sim_func in simulations.items():\n",
    "\n",
    "    # Generate training observations\n",
    "    y_train = sim_func(x_train)\n",
    "    y_train_dict[name] = y_train  # Store training outputs\n",
    "\n",
    "    # Print details\n",
    "    print(f\"=== {name.upper()} ===\")\n",
    "    print(f\"Training inputs shape: {x_train.shape}\")\n",
    "    print(f\"Training observations shape: {y_train.shape}\")\n",
    "    print(f\"Training inputs dtype: {x_train.dtype}\")\n",
    "    print()\n",
    "\n",
    "#######################\n",
    "### x_test & y_test ###\n",
    "#######################\n",
    "\n",
    "print(\"=== Generating test data ===\")\n",
    "\n",
    "# Choose discretisation that is good for simulations and also for quiver plotting\n",
    "N_SIDE = 20\n",
    "\n",
    "side_array = torch.linspace(start = 0.0, end = 1.0, steps = N_SIDE)\n",
    "XX, YY = torch.meshgrid(side_array, side_array, indexing = \"xy\")\n",
    "x_test_grid = torch.cat([XX.unsqueeze(-1), YY.unsqueeze(-1)], dim = -1)\n",
    "# long format\n",
    "x_test = x_test_grid.reshape(-1, 2)\n",
    "\n",
    "# Storage dictionaries\n",
    "y_test_dict = {}\n",
    "\n",
    "# Make y_test_dict: Iterate over all simulation functions\n",
    "for name, sim_func in simulations.items():\n",
    "\n",
    "    # Generate test observations\n",
    "    y_test = sim_func(x_test)\n",
    "    y_test_dict[name] = y_test  # Store test outputs\n",
    "\n",
    "    # Print details\n",
    "    print(f\"=== {name.upper()} ===\")\n",
    "    print(f\"Test inputs shape: {x_test.shape}\")\n",
    "    print(f\"Test observations shape: {y_test.shape}\")\n",
    "    print(f\"Test inputs dtype: {x_test.dtype}\")\n",
    "    print()\n",
    "\n",
    "    # visualise_v_quiver(y_test, x_test, title_string = name)\n",
    "\n",
    "#####################\n",
    "### Training loop ###\n",
    "#####################\n",
    "\n",
    "# Early stopping parameters\n",
    "PATIENCE = 50  # Stop after 50 epochs with no improvement\n",
    "max_num_epochs = 5 # 2000\n",
    "\n",
    "# Number of training runs for mean and std of metrics\n",
    "NUM_RUNS = 3 # 10\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Ensure the results folder exists\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok = True)\n",
    "\n",
    "### LOOP OVER SIMULATIONS ###\n",
    "for name, sim_func in simulations.items():\n",
    "    print(f\"\\nTraining for {name.upper()}...\")\n",
    "\n",
    "    # Store metrics for the current simulation\n",
    "    simulation_results = []\n",
    "\n",
    "    # x_train is the same, select y_train\n",
    "    y_train = y_train_dict[name]\n",
    "\n",
    "    ### LOOP OVER RUNS ###\n",
    "    for run in range(NUM_RUNS):\n",
    "        print(f\"\\n--- Training Run {run + 1}/{NUM_RUNS} ---\")\n",
    "\n",
    "        # Convert to DataLoader for batching\n",
    "        dataset = TensorDataset(x_train, y_train)\n",
    "        dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "        # Initialise fresh model\n",
    "        # we seeded so this is reproducible\n",
    "        dfNN_model = dfNN_for_vmap()\n",
    "        dfNN_model.train()\n",
    "\n",
    "        # Define loss function (e.g., MSE for regression)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # Define optimizer (e.g., AdamW)\n",
    "        optimizer = optim.AdamW(dfNN_model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "\n",
    "        # Initialise tensors to store losses\n",
    "        epoch_train_losses = torch.zeros(max_num_epochs)\n",
    "        epoch_test_losses = torch.zeros(max_num_epochs)\n",
    "\n",
    "        # Early stopping variables\n",
    "        best_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        ### LOOP OVER EPOCHS ###\n",
    "        print(\"\\nStart Training\")\n",
    "        for epoch in range(max_num_epochs):\n",
    "\n",
    "            epoch_train_loss = 0.0  # Accumulate batch losses within epoch\n",
    "            epoch_test_loss = 0.0\n",
    "\n",
    "            for batch in dataloader:\n",
    "                x_batch, y_batch = batch\n",
    "                x_batch.requires_grad_()\n",
    "\n",
    "                # Forward pass\n",
    "                y_pred = vmap(dfNN_model)(x_batch)\n",
    "\n",
    "                # Compute loss (RMSE for same units as data)\n",
    "                loss = torch.sqrt(criterion(y_pred, y_batch))\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Compute test loss for loss convergence plot\n",
    "                y_test_pred = vmap(dfNN_model)(x_test)\n",
    "                epoch_test_loss += torch.sqrt(criterion(y_test_pred, y_test)).item()\n",
    "\n",
    "            # Compute average loss for the epoch\n",
    "            avg_train_loss = epoch_train_loss / len(dataloader)\n",
    "            avg_test_loss = epoch_test_loss / len(dataloader)\n",
    "\n",
    "            epoch_train_losses[epoch] = avg_train_loss\n",
    "            epoch_test_losses[epoch] = avg_test_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{max_num_epochs}, Training Loss (RMSE): {avg_train_loss:.4f}\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if avg_train_loss < best_loss:\n",
    "                best_loss = avg_train_loss\n",
    "                epochs_no_improve = 0  # Reset counter\n",
    "                best_model_state = dfNN_model.state_dict()  # Save best model\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                break\n",
    "\n",
    "        # Load the best model before stopping\n",
    "        dfNN_model.load_state_dict(best_model_state)\n",
    "        print(f\"Training of {model_name} complete for {name.upper()}. Restored best model.\")\n",
    "\n",
    "        ################\n",
    "        ### EVALUATE ###\n",
    "        ################\n",
    "\n",
    "        # Evaluate the trained model\n",
    "        dfNN_model.eval()\n",
    "\n",
    "        y_train_dfNN_predicted = vmap(dfNN_model)(x_train).detach()\n",
    "        y_test_dfNN_predicted = vmap(dfNN_model)(x_test).detach()\n",
    "\n",
    "        # Only save things for one run\n",
    "        if run == 0:\n",
    "            #(1) Save predictions from first run so we can visualise them later\n",
    "            torch.save(y_test_dfNN_predicted, f\"{results_dir}/{name}_{model_name}_test_predictions.pt\")\n",
    "\n",
    "            #(2) Save loss over epochs\n",
    "            df_losses = pd.DataFrame({\n",
    "                'Epoch': list(range(epoch_train_losses.shape[0])), # pythonic\n",
    "                'Train Loss RMSE': epoch_train_losses.tolist(), \n",
    "                'Test Loss RMSE': epoch_test_losses.tolist()\n",
    "                })\n",
    "            \n",
    "            df_losses.to_csv(f\"{results_dir}/{name}_{model_name}_losses_over_epochs.csv\", index = False)\n",
    "\n",
    "        # Compute Divergence (convert tensor to float)\n",
    "        dfNN_train_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_train), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "        dfNN_test_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_test), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "\n",
    "        # Compute metrics (convert tensors to float)\n",
    "        dfNN_train_RMSE = compute_RMSE(y_train, y_train_dfNN_predicted).item()\n",
    "        dfNN_train_MAE = compute_MAE(y_train, y_train_dfNN_predicted).item()\n",
    "\n",
    "        dfNN_test_RMSE = compute_RMSE(y_test, y_test_dfNN_predicted).item()\n",
    "        dfNN_test_MAE = compute_MAE(y_test, y_test_dfNN_predicted).item()\n",
    "\n",
    "        # Store results in list\n",
    "        simulation_results.append([\n",
    "            run + 1, dfNN_train_RMSE, dfNN_train_MAE, dfNN_train_div,\n",
    "            dfNN_test_RMSE, dfNN_test_MAE, dfNN_test_div\n",
    "        ])\n",
    "\n",
    "    ### FINISH LOOP OVER RUNS ###\n",
    "    # Convert results to a Pandas DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        simulation_results, \n",
    "        columns = [\"Run\", \"Train RMSE\", \"Train MAE\", \"Train Divergence\",\n",
    "                   \"Test RMSE\", \"Test MAE\", \"Test Divergence\"])\n",
    "\n",
    "    # Compute mean and standard deviation for each metric\n",
    "    mean_std_df = df.iloc[:, 1:].agg([\"mean\", \"std\"])  # Exclude \"Run\" column\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_file = os.path.join(results_dir, f\"{name}_{model_name}_metrics_per_run.csv\")\n",
    "    df.to_csv(results_file, index = False)\n",
    "    print(f\"\\nResults saved to {results_file}\")\n",
    "\n",
    "    # Save mean and standard deviation to CSV\n",
    "    mean_std_file = os.path.join(results_dir, f\"{name}_{model_name}_metrics_summary.csv\")\n",
    "    mean_std_df.to_csv(mean_std_file)\n",
    "    print(f\"\\nMean & Std saved to {mean_std_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epoch_train_losses.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(epoch_train_losses.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate_convergence, simulate_branching, simulate_ridge, simulate_merge, simulate_deflection\n",
    "\n",
    "x_train = torch.load(\"data/sim_data/x_train_lines_discretised.pt\").float()\n",
    "y_train = simulate_convergence(x_train)\n",
    "\n",
    "# small data\n",
    "print(f\"The shape of the training inputs is {x_train.shape}.\")\n",
    "print(f\"The shape of the training observations is {y_train.shape}.\")\n",
    "print()\n",
    "print(f\"The dtype of the training inputs is {x_train.dtype}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rather dense grid for eval\n",
    "side = torch.linspace(start = 0., end = 3., steps = 20)\n",
    "XX, YY = torch.meshgrid(side, side, indexing = \"xy\")\n",
    "x_test_grid = torch.cat([XX.unsqueeze(-1), YY.unsqueeze(-1)], dim = -1)\n",
    "x_test = x_test_grid.reshape(-1, 2)\n",
    "\n",
    "# Retrieve true\n",
    "y_test = simulate_convergence(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Convert to DataLoader for batching\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# Initialise fresh model\n",
    "dfNN_model = dfNN_for_vmap()\n",
    "dfNN_model.train()\n",
    "\n",
    "# Define loss function (e.g., MSE for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (e.g., AdamW)\n",
    "optimizer = optim.AdamW(dfNN_model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "max_num_epochs = 1000 \n",
    "\n",
    "# Initialise tensor to store losses\n",
    "epoch_losses = torch.zeros(max_num_epochs)\n",
    "epoch_test_losses = torch.zeros(max_num_epochs)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 50  # Stop after 50 epochs with no improvement\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(\"\\nStart Training\")\n",
    "for epoch in range(max_num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0  # Accumulate batch losses\n",
    "    epoch_test_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch.requires_grad_()\n",
    "\n",
    "        y_pred = vmap(dfNN_model)(x_batch)\n",
    "\n",
    "        # Compute loss (RMSE for same units as data)\n",
    "        loss = torch.sqrt(criterion(y_pred, y_batch))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Test loss\n",
    "        y_test_pred = vmap(dfNN_model)(x_test)\n",
    "        test_loss = torch.sqrt(criterion(y_test_pred, y_test))\n",
    "        epoch_test_loss += test_loss.item()\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    avg_train_loss = epoch_loss / len(dataloader)\n",
    "    avg_test_loss = epoch_test_loss / len(dataloader)\n",
    "\n",
    "    epoch_losses[epoch] = avg_train_loss\n",
    "    epoch_test_losses[epoch] = avg_test_loss\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_num_epochs}, Training Loss (RMSE): {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_train_loss < best_loss:\n",
    "        best_loss = avg_train_loss\n",
    "        epochs_no_improve = 0  # Reset counter\n",
    "        best_model_state = dfNN_model.state_dict()  # Save best model\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "# Load the best model before stopping\n",
    "dfNN_model.load_state_dict(best_model_state)\n",
    "print(\"Training complete. Restored best model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the results folder exists\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Number of training runs\n",
    "num_runs = 10\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n--- Training Run {run + 1}/{num_runs} ---\")\n",
    "    \n",
    "    # Initialize model and set to training mode\n",
    "    dfNN_model = dfNN_for_vmap()\n",
    "    dfNN_model.train()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.AdamW(dfNN_model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "    # Training loop\n",
    "    max_num_epochs = 1000\n",
    "    for epoch in range(max_num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch.requires_grad_()\n",
    "\n",
    "            y_pred = vmap(dfNN_model)(x_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = torch.sqrt(criterion(y_pred, y_batch))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the trained model\n",
    "    dfNN_model.eval()\n",
    "\n",
    "    y_train_dfNN_predicted = vmap(dfNN_model)(x_train).detach()\n",
    "    y_test_dfNN_predicted = vmap(dfNN_model)(x_test).detach()\n",
    "\n",
    "    # Compute Divergence (convert tensor to float)\n",
    "    dfNN_train_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_train), dim1=-2, dim2=-1).detach().sum().item()\n",
    "    dfNN_test_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_test), dim1=-2, dim2=-1).detach().sum().item()\n",
    "\n",
    "    # Compute metrics (convert tensors to float)\n",
    "    dfNN_train_RMSE = compute_RMSE(y_train, y_train_dfNN_predicted).item()\n",
    "    dfNN_train_MAE = compute_MAE(y_train, y_train_dfNN_predicted).item()\n",
    "\n",
    "    dfNN_test_RMSE = compute_RMSE(y_test, y_test_dfNN_predicted).item()\n",
    "    dfNN_test_MAE = compute_MAE(y_test, y_test_dfNN_predicted).item()\n",
    "\n",
    "    # Store results in list\n",
    "    all_results.append([\n",
    "        run + 1, dfNN_train_RMSE, dfNN_train_MAE, dfNN_train_div,\n",
    "        dfNN_test_RMSE, dfNN_test_MAE, dfNN_test_div\n",
    "    ])\n",
    "\n",
    "# Convert results to a Pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    all_results, \n",
    "    columns=[\"Run\", \"Train RMSE\", \"Train MAE\", \"Train Divergence\",\n",
    "             \"Test RMSE\", \"Test MAE\", \"Test Divergence\"]\n",
    ")\n",
    "\n",
    "# Compute mean and standard deviation for each metric\n",
    "mean_std_df = df.iloc[:, 1:].agg([\"mean\", \"std\"])  # Exclude \"Run\" column\n",
    "\n",
    "# Save results to CSV\n",
    "results_file = os.path.join(results_dir, \"dfNN_performance.csv\")\n",
    "df.to_csv(results_file, index=False)\n",
    "print(f\"\\nResults saved to {results_file}\")\n",
    "\n",
    "# Save mean and standard deviation to CSV\n",
    "mean_std_file = os.path.join(results_dir, \"dfNN_performance_summary.csv\")\n",
    "mean_std_df.to_csv(mean_std_file)\n",
    "print(f\"\\nMean & Std saved to {mean_std_file}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nMean & Std of 10 Runs:\")\n",
    "print(mean_std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json  # To save structured results\n",
    "\n",
    "# Ensure the results folder exists\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "dfNN_model.eval()\n",
    "\n",
    "# Pass through\n",
    "y_train_dfNN_predicted = vmap(dfNN_model)(x_train).detach()\n",
    "y_test_dfNN_predicted = vmap(dfNN_model)(x_test).detach()\n",
    "\n",
    "# Compute Divergence (convert tensor to float)\n",
    "dfNN_train_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_train), dim1=-2, dim2=-1).detach().sum().item()\n",
    "dfNN_test_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_test), dim1=-2, dim2=-1).detach().sum().item()\n",
    "\n",
    "# Compute metrics (convert tensors to float)\n",
    "dfNN_train_RMSE = compute_RMSE(y_train, y_train_dfNN_predicted).item()\n",
    "dfNN_train_MAE = compute_MAE(y_train, y_train_dfNN_predicted).item()\n",
    "\n",
    "dfNN_test_RMSE = compute_RMSE(y_test, y_test_dfNN_predicted).item()\n",
    "dfNN_test_MAE = compute_MAE(y_test, y_test_dfNN_predicted).item()\n",
    "\n",
    "# Print results\n",
    "print(f\"dfNN Train RMSE: {dfNN_train_RMSE:.4f}\")\n",
    "print(f\"dfNN Train MAE: {dfNN_train_MAE:.4f}\")\n",
    "print(f\"dfNN Train Divergence: {dfNN_train_div:.4f}\\n\")\n",
    "\n",
    "print(f\"dfNN Test RMSE: {dfNN_test_RMSE:.4f}\")\n",
    "print(f\"dfNN Test MAE: {dfNN_test_MAE:.4f}\")\n",
    "print(f\"dfNN Test Divergence: {dfNN_test_div:.4f}\")\n",
    "\n",
    "# Convert results to a dictionary\n",
    "results = {\n",
    "    \"train\": {\n",
    "        \"RMSE\": dfNN_train_RMSE,\n",
    "        \"MAE\": dfNN_train_MAE,\n",
    "        \"Divergence\": dfNN_train_div\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"RMSE\": dfNN_test_RMSE,\n",
    "        \"MAE\": dfNN_test_MAE,\n",
    "        \"Divergence\": dfNN_test_div\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to a JSON file\n",
    "results_file = os.path.join(results_dir, \"dfNN_performance.json\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"\\nResults saved to {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader for batching\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# Initialise fresh model\n",
    "dfNN_model = dfNN_for_vmap()\n",
    "dfNN_model.train()\n",
    "\n",
    "# Define loss function (e.g., MSE for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (e.g., Adam)\n",
    "optimizer = optim.AdamW(dfNN_model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "num_epochs = 1000 # 600 are good\n",
    "\n",
    "# Initialise tensor to store losses\n",
    "epoch_losses = torch.zeros(num_epochs)\n",
    "epoch_test_losses = torch.zeros(num_epochs)\n",
    "\n",
    "print()\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0  # Accumulate batch losses\n",
    "    epoch_test_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch.requires_grad_()\n",
    "\n",
    "        y_pred = vmap(dfNN_model)(x_batch)\n",
    "\n",
    "        # Compute loss (RMSE for same units as data)\n",
    "        loss = torch.sqrt(criterion(y_pred, y_batch))\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Test loss\n",
    "        y_test_pred = vmap(dfNN_model)(x_test)\n",
    "        test_loss = torch.sqrt(criterion(y_test_pred, y_test))\n",
    "        epoch_test_loss += test_loss.item()\n",
    "    \n",
    "    # Store the average loss for the epoch\n",
    "    epoch_losses[epoch] = epoch_loss / len(dataloader)\n",
    "    epoch_test_losses[epoch] = epoch_test_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss (RMSE): {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs + 1), epoch_losses, label = \"Train Loss\", color = \"blue\")\n",
    "plt.plot(range(1, num_epochs + 1), epoch_test_losses, label = \"Test Loss\", color = \"red\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.title(\"dfNN Training & Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNN_model.eval()\n",
    "# Pass through\n",
    "y_train_dfNN_predicted = vmap(dfNN_model)(x_train)\n",
    "y_test_dfNN_predicted = vmap(dfNN_model)(x_test)\n",
    "\n",
    "# Divergence\n",
    "dfNN_train_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_train), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "dfNN_test_div = torch.diagonal(vmap(jacfwd(dfNN_model))(x_test), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "\n",
    "# Train\n",
    "dfNN_train_RMSE = compute_RMSE(y_train, y_train_dfNN_predicted)\n",
    "print(f\"dfNN Train RMSE: {dfNN_train_RMSE:.4f}\")\n",
    "dfNN_train_MAE = compute_MAE(y_train , y_train_dfNN_predicted)\n",
    "print(f\"dfNN Train MAE: {dfNN_train_MAE:.4f}\")\n",
    "print(f\"dfNN Train Divergence: {dfNN_train_div:.4f}\")\n",
    "\n",
    "# Test\n",
    "print(\"\")\n",
    "dfNN_test_RMSE = compute_RMSE(y_test, y_test_dfNN_predicted)\n",
    "print(f\"dfNN Test RMSE: {dfNN_test_RMSE:.4f}\")\n",
    "dfNN_test_MAE = compute_MAE(y_test, y_test_dfNN_predicted)\n",
    "print(f\"dfNN Test MAE: {dfNN_test_MAE:.4f}\")\n",
    "print(f\"dfNN Test Divergence: {dfNN_test_div:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_v_quiver(y_test_dfNN_predicted.detach(), x_test.detach(), title_string = \"dfNN Predicted Convergence Field\") # order is v, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No test loss calculated - faster\n",
    "\n",
    "# Convert to DataLoader for batching\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# equal weighting in loss\n",
    "w = 0.5\n",
    "\n",
    "# Initialise fresh model\n",
    "PINN_model = PINN_backbone()\n",
    "PINN_model.train()\n",
    "\n",
    "# Define loss function (e.g., MSE for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (e.g., Adam)\n",
    "optimizer = optim.AdamW(PINN_model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "num_epochs = 1000\n",
    "\n",
    "# Initialise tensor to store losses\n",
    "epoch_train_losses = torch.zeros(num_epochs)\n",
    "epoch_train_rmse_losses = torch.zeros(num_epochs)\n",
    "epoch_test_losses = torch.zeros(num_epochs)\n",
    "epoch_test_rmse_losses = torch.zeros(num_epochs)\n",
    "\n",
    "print()\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_train_loss = 0.0  # Accumulate batch losses\n",
    "    epoch_train_rmse_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch.requires_grad_()\n",
    "\n",
    "        y_pred = vmap(PINN_model)(x_batch)\n",
    "        # torch.Size([32 (batch_dim), 2 (out_dim), 2 (in_dim)])\n",
    "        batch_divergence = vmap(jacfwd(PINN_model))(x_batch)\n",
    "        # sum: f1/x1 + f2/x2, square to account for negative\n",
    "        batch_divergence_loss = torch.square(torch.diagonal(batch_divergence, dim1 = -2, dim2 = -1).sum())\n",
    "\n",
    "        # Compute loss (RMSE for same units as data) + divergence loss\n",
    "        loss = (1 - w) * torch.sqrt(criterion(y_pred, y_batch)) + w * batch_divergence_loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        epoch_train_rmse_loss += torch.sqrt(criterion(y_pred, y_batch)).item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Store the average loss for the epoch\n",
    "    epoch_train_losses[epoch] = epoch_train_loss / len(dataloader)\n",
    "    epoch_train_rmse_losses[epoch] = epoch_train_rmse_loss / len(dataloader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss (RMSE + divergence loss): {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataLoader for batching\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# equal weighting in loss\n",
    "w = 0.5\n",
    "\n",
    "# Initialise fresh model\n",
    "PINN_model = PINN_backbone()\n",
    "PINN_model.train()\n",
    "\n",
    "# Define loss function (e.g., MSE for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (e.g., Adam)\n",
    "optimizer = optim.AdamW(PINN_model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "num_epochs = 1000\n",
    "\n",
    "# Initialise tensor to store losses\n",
    "epoch_train_losses = torch.zeros(num_epochs)\n",
    "epoch_train_rmse_losses = torch.zeros(num_epochs)\n",
    "epoch_test_losses = torch.zeros(num_epochs)\n",
    "epoch_test_rmse_losses = torch.zeros(num_epochs)\n",
    "\n",
    "print()\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_train_loss = 0.0  # Accumulate batch losses\n",
    "    epoch_train_rmse_loss = 0.0\n",
    "    epoch_test_loss = 0.0\n",
    "    epoch_test_rmse_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch.requires_grad_()\n",
    "\n",
    "        y_pred = vmap(PINN_model)(x_batch)\n",
    "        # torch.Size([32 (batch_dim), 2 (out_dim), 2 (in_dim)])\n",
    "        batch_divergence = vmap(jacfwd(PINN_model))(x_batch)\n",
    "        # sum: f1/x1 + f2/x2, square to account for negative\n",
    "        batch_divergence_loss = torch.square(torch.diagonal(batch_divergence, dim1 = -2, dim2 = -1).sum())\n",
    "\n",
    "        # Compute loss (RMSE for same units as data) + divergence loss\n",
    "        loss = (1 - w) * torch.sqrt(criterion(y_pred, y_batch)) + w * batch_divergence_loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        epoch_train_rmse_loss += torch.sqrt(criterion(y_pred, y_batch)).item()\n",
    "\n",
    "        # Test loss\n",
    "        y_test_pred = vmap(PINN_model)(x_test)\n",
    "        epoch_test_rmse_loss += torch.sqrt(criterion(y_test_pred, y_test)).item()\n",
    "        epoch_test_loss += (1 - w) * torch.sqrt(criterion(y_test_pred, y_test)) + w * torch.square(torch.diagonal(vmap(jacfwd(PINN_model))(x_test), dim1 = -2, dim2 = -1).sum()).item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Store the average loss for the epoch\n",
    "    epoch_train_losses[epoch] = epoch_train_loss / len(dataloader)\n",
    "    epoch_train_rmse_losses[epoch] = epoch_train_rmse_loss / len(dataloader)\n",
    "    epoch_test_losses[epoch] = epoch_test_loss / len(dataloader)\n",
    "    epoch_test_rmse_losses[epoch] = epoch_test_rmse_loss / len(dataloader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss (RMSE + divergence loss): {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs + 1), epoch_train_losses, label = \"Train Loss\", color = \"blue\")\n",
    "plt.plot(range(1, num_epochs + 1), epoch_train_rmse_losses.detach(), label = \"Train RMSE Loss\", color = \"lightblue\")\n",
    "# plt.plot(range(1, num_epochs + 1), epoch_test_losses.detach(), label = \"Test Loss\", color = \"red\")\n",
    "plt.plot(range(1, num_epochs + 1), epoch_test_rmse_losses.detach(), label = \"Test RMSE Loss\", color = \"pink\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.title(\"PINN Training & Test Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN_model.eval()\n",
    "# Pass through\n",
    "y_train_PINN_predicted = vmap(PINN_model)(x_train)\n",
    "y_test_PINN_predicted = vmap(PINN_model)(x_test)\n",
    "\n",
    "# Divergence\n",
    "PINN_train_div = torch.diagonal(vmap(jacfwd(PINN_model))(x_train), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "PINN_test_div = torch.diagonal(vmap(jacfwd(PINN_model))(x_test), dim1 = -2, dim2 = -1).detach().sum().item()\n",
    "PINN_test_div_field = torch.diagonal(vmap(jacfwd(PINN_model))(x_test), dim1 = -2, dim2 = -1).sum(-1).detach()\n",
    "\n",
    "# Train\n",
    "PINN_train_RMSE = compute_RMSE(y_train, y_train_PINN_predicted)\n",
    "print(f\"PINN Train RMSE: {PINN_train_RMSE:.4f}\")\n",
    "PINN_train_MAE = compute_MAE(y_train , y_train_PINN_predicted)\n",
    "print(f\"PINN Train MAE: {PINN_train_MAE:.4f}\")\n",
    "print(f\"PINN Train Divergence: {PINN_train_div:.4f}\")\n",
    "\n",
    "# Test\n",
    "print(\"\")\n",
    "PINN_test_RMSE = compute_RMSE(y_test, y_test_PINN_predicted)\n",
    "print(f\"PINN Test RMSE: {PINN_test_RMSE:.4f}\")\n",
    "PINN_test_MAE = compute_MAE(y_test, y_test_PINN_predicted)\n",
    "print(f\"PINN Test MAE: {PINN_test_MAE:.4f}\")\n",
    "print(f\"PINN Test Divergence: {PINN_test_div:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_v_quiver(\n",
    "    y_test_PINN_predicted.detach(), \n",
    "    x_test.detach(), \n",
    "    PINN_test_div_field, \n",
    "    title_string = \"PINN Predicted Convergence Field\", \n",
    "    color_abs_max = 0.1) # order is v, x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
