{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.func import jacrev, jacfwd, vmap\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # need 3.10 plus for \"berlin\" cmap\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQBiZXJsaW4gY29sb3JtYXAy4K9UAAAAG3RFWHREZXNjcmlwdGlvbgBiZXJsaW4gY29sb3JtYXB7d7ewAAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My45LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmdhmcVTAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ08/WnQAAAItSURBVHic7dZBEuIgEAVQYu5/hbnCnFCYhUErJIg12//ehuqm6ejub3/+1lZKKbW0Ukopz+PsdW2Tfp9vk36p39+P/VaHerZnqI93n99Tz/vaZH42V5/n+zrMX+5fdXvPDfXivtVVfZyTd+XHPaV9nyuT71364/xk7+V3tbHf6+ewZ5hrs73n75fp/53Ul/f3/3u25zPfbucv9XjWNrkf+696u9zf93u99br82C9tcZZF/zi3c/8x6Y/nY7vvX/dM+os9Y3/c96m3xX2vt9v7R3/fv/fed+5/5ibn47G47/Vrbh/q9/2wZ+/1uz/U47vj3C9z/dwX+1bn/vXdNvvO5X8s7qfvz/19+b9+2/Nrf/q9af++3vf/3FMAgDgCAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAACCQAAEEgAAIBAAgAABBIAACCQAAAAgQQAAAgkAABAIAEAAAIJAAAQSAAAgEACAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAACCQAAEEgAAIBAAgAABBIAACCQAAAAgQQAAAgkAABAIAEAAAIJAAAQSAAAgEACAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAAC/QPNUU7m7EFKwQAAAABJRU5ErkJggg==",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>berlin</strong> </div><div class=\"cmap\"><img alt=\"berlin colormap\" title=\"berlin\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQBiZXJsaW4gY29sb3JtYXAy4K9UAAAAG3RFWHREZXNjcmlwdGlvbgBiZXJsaW4gY29sb3JtYXB7d7ewAAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My45LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmdhmcVTAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ08/WnQAAAItSURBVHic7dZBEuIgEAVQYu5/hbnCnFCYhUErJIg12//ehuqm6ejub3/+1lZKKbW0Ukopz+PsdW2Tfp9vk36p39+P/VaHerZnqI93n99Tz/vaZH42V5/n+zrMX+5fdXvPDfXivtVVfZyTd+XHPaV9nyuT71364/xk7+V3tbHf6+ewZ5hrs73n75fp/53Ul/f3/3u25zPfbucv9XjWNrkf+696u9zf93u99br82C9tcZZF/zi3c/8x6Y/nY7vvX/dM+os9Y3/c96m3xX2vt9v7R3/fv/fed+5/5ibn47G47/Vrbh/q9/2wZ+/1uz/U47vj3C9z/dwX+1bn/vXdNvvO5X8s7qfvz/19+b9+2/Nrf/q9af++3vf/3FMAgDgCAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAACCQAAEEgAAIBAAgAABBIAACCQAAAAgQQAAAgkAABAIAEAAAIJAAAQSAAAgEACAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAACCQAAEEgAAIBAAgAABBIAACCQAAAAgQQAAAgkAABAIAEAAAIJAAAQSAAAgEACAAAEEgAAIJAAAACBBAAACCQAAEAgAQAAAgkAABBIAACAQAIAAAQSAAAgkAAAAIEEAAAIJAAAQCABAAAC/QPNUU7m7EFKwQAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#9eb0ffff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #9eb0ffff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#ffadadff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #ffadadff;\"></div></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x7f31c0490490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Berlin colormap although it is only available in Matplotlib 3.10\n",
    "# print(matplotlib.__version__)\n",
    "\n",
    "_berlin_data = [\n",
    "    [0.62108, 0.69018, 0.99951],\n",
    "    [0.61216, 0.68923, 0.99537],\n",
    "    [0.6032, 0.68825, 0.99124],\n",
    "    [0.5942, 0.68726, 0.98709],\n",
    "    [0.58517, 0.68625, 0.98292],\n",
    "    [0.57609, 0.68522, 0.97873],\n",
    "    [0.56696, 0.68417, 0.97452],\n",
    "    [0.55779, 0.6831, 0.97029],\n",
    "    [0.54859, 0.68199, 0.96602],\n",
    "    [0.53933, 0.68086, 0.9617],\n",
    "    [0.53003, 0.67969, 0.95735],\n",
    "    [0.52069, 0.67848, 0.95294],\n",
    "    [0.51129, 0.67723, 0.94847],\n",
    "    [0.50186, 0.67591, 0.94392],\n",
    "    [0.49237, 0.67453, 0.9393],\n",
    "    [0.48283, 0.67308, 0.93457],\n",
    "    [0.47324, 0.67153, 0.92975],\n",
    "    [0.46361, 0.6699, 0.92481],\n",
    "    [0.45393, 0.66815, 0.91974],\n",
    "    [0.44421, 0.66628, 0.91452],\n",
    "    [0.43444, 0.66427, 0.90914],\n",
    "    [0.42465, 0.66212, 0.90359],\n",
    "    [0.41482, 0.65979, 0.89785],\n",
    "    [0.40498, 0.65729, 0.89191],\n",
    "    [0.39514, 0.65458, 0.88575],\n",
    "    [0.3853, 0.65167, 0.87937],\n",
    "    [0.37549, 0.64854, 0.87276],\n",
    "    [0.36574, 0.64516, 0.8659],\n",
    "    [0.35606, 0.64155, 0.8588],\n",
    "    [0.34645, 0.63769, 0.85145],\n",
    "    [0.33698, 0.63357, 0.84386],\n",
    "    [0.32764, 0.62919, 0.83602],\n",
    "    [0.31849, 0.62455, 0.82794],\n",
    "    [0.30954, 0.61966, 0.81963],\n",
    "    [0.30078, 0.6145, 0.81111],\n",
    "    [0.29231, 0.60911, 0.80238],\n",
    "    [0.2841, 0.60348, 0.79347],\n",
    "    [0.27621, 0.59763, 0.78439],\n",
    "    [0.26859, 0.59158, 0.77514],\n",
    "    [0.26131, 0.58534, 0.76578],\n",
    "    [0.25437, 0.57891, 0.7563],\n",
    "    [0.24775, 0.57233, 0.74672],\n",
    "    [0.24146, 0.5656, 0.73707],\n",
    "    [0.23552, 0.55875, 0.72735],\n",
    "    [0.22984, 0.5518, 0.7176],\n",
    "    [0.2245, 0.54475, 0.7078],\n",
    "    [0.21948, 0.53763, 0.698],\n",
    "    [0.21469, 0.53043, 0.68819],\n",
    "    [0.21017, 0.52319, 0.67838],\n",
    "    [0.20589, 0.5159, 0.66858],\n",
    "    [0.20177, 0.5086, 0.65879],\n",
    "    [0.19788, 0.50126, 0.64903],\n",
    "    [0.19417, 0.4939, 0.63929],\n",
    "    [0.19056, 0.48654, 0.62957],\n",
    "    [0.18711, 0.47918, 0.6199],\n",
    "    [0.18375, 0.47183, 0.61024],\n",
    "    [0.1805, 0.46447, 0.60062],\n",
    "    [0.17737, 0.45712, 0.59104],\n",
    "    [0.17426, 0.44979, 0.58148],\n",
    "    [0.17122, 0.44247, 0.57197],\n",
    "    [0.16824, 0.43517, 0.56249],\n",
    "    [0.16529, 0.42788, 0.55302],\n",
    "    [0.16244, 0.42061, 0.5436],\n",
    "    [0.15954, 0.41337, 0.53421],\n",
    "    [0.15674, 0.40615, 0.52486],\n",
    "    [0.15391, 0.39893, 0.51552],\n",
    "    [0.15112, 0.39176, 0.50623],\n",
    "    [0.14835, 0.38459, 0.49697],\n",
    "    [0.14564, 0.37746, 0.48775],\n",
    "    [0.14288, 0.37034, 0.47854],\n",
    "    [0.14014, 0.36326, 0.46939],\n",
    "    [0.13747, 0.3562, 0.46024],\n",
    "    [0.13478, 0.34916, 0.45115],\n",
    "    [0.13208, 0.34215, 0.44209],\n",
    "    [0.1294, 0.33517, 0.43304],\n",
    "    [0.12674, 0.3282, 0.42404],\n",
    "    [0.12409, 0.32126, 0.41507],\n",
    "    [0.12146, 0.31435, 0.40614],\n",
    "    [0.1189, 0.30746, 0.39723],\n",
    "    [0.11632, 0.30061, 0.38838],\n",
    "    [0.11373, 0.29378, 0.37955],\n",
    "    [0.11119, 0.28698, 0.37075],\n",
    "    [0.10861, 0.28022, 0.362],\n",
    "    [0.10616, 0.2735, 0.35328],\n",
    "    [0.10367, 0.26678, 0.34459],\n",
    "    [0.10118, 0.26011, 0.33595],\n",
    "    [0.098776, 0.25347, 0.32734],\n",
    "    [0.096347, 0.24685, 0.31878],\n",
    "    [0.094059, 0.24026, 0.31027],\n",
    "    [0.091788, 0.23373, 0.30176],\n",
    "    [0.089506, 0.22725, 0.29332],\n",
    "    [0.087341, 0.2208, 0.28491],\n",
    "    [0.085142, 0.21436, 0.27658],\n",
    "    [0.083069, 0.20798, 0.26825],\n",
    "    [0.081098, 0.20163, 0.25999],\n",
    "    [0.07913, 0.19536, 0.25178],\n",
    "    [0.077286, 0.18914, 0.24359],\n",
    "    [0.075571, 0.18294, 0.2355],\n",
    "    [0.073993, 0.17683, 0.22743],\n",
    "    [0.07241, 0.17079, 0.21943],\n",
    "    [0.071045, 0.1648, 0.2115],\n",
    "    [0.069767, 0.1589, 0.20363],\n",
    "    [0.068618, 0.15304, 0.19582],\n",
    "    [0.06756, 0.14732, 0.18812],\n",
    "    [0.066665, 0.14167, 0.18045],\n",
    "    [0.065923, 0.13608, 0.17292],\n",
    "    [0.065339, 0.1307, 0.16546],\n",
    "    [0.064911, 0.12535, 0.15817],\n",
    "    [0.064636, 0.12013, 0.15095],\n",
    "    [0.064517, 0.11507, 0.14389],\n",
    "    [0.064554, 0.11022, 0.13696],\n",
    "    [0.064749, 0.10543, 0.13023],\n",
    "    [0.0651, 0.10085, 0.12357],\n",
    "    [0.065383, 0.096469, 0.11717],\n",
    "    [0.065574, 0.092338, 0.11101],\n",
    "    [0.065892, 0.088201, 0.10498],\n",
    "    [0.066388, 0.084134, 0.099288],\n",
    "    [0.067108, 0.080051, 0.093829],\n",
    "    [0.068193, 0.076099, 0.08847],\n",
    "    [0.06972, 0.072283, 0.083025],\n",
    "    [0.071639, 0.068654, 0.077544],\n",
    "    [0.073978, 0.065058, 0.07211],\n",
    "    [0.076596, 0.061657, 0.066651],\n",
    "    [0.079637, 0.05855, 0.061133],\n",
    "    [0.082963, 0.055666, 0.055745],\n",
    "    [0.086537, 0.052997, 0.050336],\n",
    "    [0.090315, 0.050699, 0.04504],\n",
    "    [0.09426, 0.048753, 0.039773],\n",
    "    [0.098319, 0.047041, 0.034683],\n",
    "    [0.10246, 0.045624, 0.030074],\n",
    "    [0.10673, 0.044705, 0.026012],\n",
    "    [0.11099, 0.043972, 0.022379],\n",
    "    [0.11524, 0.043596, 0.01915],\n",
    "    [0.11955, 0.043567, 0.016299],\n",
    "    [0.12381, 0.043861, 0.013797],\n",
    "    [0.1281, 0.044459, 0.011588],\n",
    "    [0.13232, 0.045229, 0.0095315],\n",
    "    [0.13645, 0.046164, 0.0078947],\n",
    "    [0.14063, 0.047374, 0.006502],\n",
    "    [0.14488, 0.048634, 0.0053266],\n",
    "    [0.14923, 0.049836, 0.0043455],\n",
    "    [0.15369, 0.050997, 0.0035374],\n",
    "    [0.15831, 0.05213, 0.0028824],\n",
    "    [0.16301, 0.053218, 0.0023628],\n",
    "    [0.16781, 0.05424, 0.0019629],\n",
    "    [0.17274, 0.055172, 0.001669],\n",
    "    [0.1778, 0.056018, 0.0014692],\n",
    "    [0.18286, 0.05682, 0.0013401],\n",
    "    [0.18806, 0.057574, 0.0012617],\n",
    "    [0.19323, 0.058514, 0.0012261],\n",
    "    [0.19846, 0.05955, 0.0012271],\n",
    "    [0.20378, 0.060501, 0.0012601],\n",
    "    [0.20909, 0.061486, 0.0013221],\n",
    "    [0.21447, 0.06271, 0.0014116],\n",
    "    [0.2199, 0.063823, 0.0015287],\n",
    "    [0.22535, 0.065027, 0.0016748],\n",
    "    [0.23086, 0.066297, 0.0018529],\n",
    "    [0.23642, 0.067645, 0.0020675],\n",
    "    [0.24202, 0.069092, 0.0023247],\n",
    "    [0.24768, 0.070458, 0.0026319],\n",
    "    [0.25339, 0.071986, 0.0029984],\n",
    "    [0.25918, 0.07364, 0.003435],\n",
    "    [0.265, 0.075237, 0.0039545],\n",
    "    [0.27093, 0.076965, 0.004571],\n",
    "    [0.27693, 0.078822, 0.0053006],\n",
    "    [0.28302, 0.080819, 0.0061608],\n",
    "    [0.2892, 0.082879, 0.0071713],\n",
    "    [0.29547, 0.085075, 0.0083494],\n",
    "    [0.30186, 0.08746, 0.0097258],\n",
    "    [0.30839, 0.089912, 0.011455],\n",
    "    [0.31502, 0.09253, 0.013324],\n",
    "    [0.32181, 0.095392, 0.015413],\n",
    "    [0.32874, 0.098396, 0.01778],\n",
    "    [0.3358, 0.10158, 0.020449],\n",
    "    [0.34304, 0.10498, 0.02344],\n",
    "    [0.35041, 0.10864, 0.026771],\n",
    "    [0.35795, 0.11256, 0.030456],\n",
    "    [0.36563, 0.11666, 0.034571],\n",
    "    [0.37347, 0.12097, 0.039115],\n",
    "    [0.38146, 0.12561, 0.043693],\n",
    "    [0.38958, 0.13046, 0.048471],\n",
    "    [0.39785, 0.13547, 0.053136],\n",
    "    [0.40622, 0.1408, 0.057848],\n",
    "    [0.41469, 0.14627, 0.062715],\n",
    "    [0.42323, 0.15198, 0.067685],\n",
    "    [0.43184, 0.15791, 0.073044],\n",
    "    [0.44044, 0.16403, 0.07862],\n",
    "    [0.44909, 0.17027, 0.084644],\n",
    "    [0.4577, 0.17667, 0.090869],\n",
    "    [0.46631, 0.18321, 0.097335],\n",
    "    [0.4749, 0.18989, 0.10406],\n",
    "    [0.48342, 0.19668, 0.11104],\n",
    "    [0.49191, 0.20352, 0.11819],\n",
    "    [0.50032, 0.21043, 0.1255],\n",
    "    [0.50869, 0.21742, 0.13298],\n",
    "    [0.51698, 0.22443, 0.14062],\n",
    "    [0.5252, 0.23154, 0.14835],\n",
    "    [0.53335, 0.23862, 0.15626],\n",
    "    [0.54144, 0.24575, 0.16423],\n",
    "    [0.54948, 0.25292, 0.17226],\n",
    "    [0.55746, 0.26009, 0.1804],\n",
    "    [0.56538, 0.26726, 0.18864],\n",
    "    [0.57327, 0.27446, 0.19692],\n",
    "    [0.58111, 0.28167, 0.20524],\n",
    "    [0.58892, 0.28889, 0.21362],\n",
    "    [0.59672, 0.29611, 0.22205],\n",
    "    [0.60448, 0.30335, 0.23053],\n",
    "    [0.61223, 0.31062, 0.23905],\n",
    "    [0.61998, 0.31787, 0.24762],\n",
    "    [0.62771, 0.32513, 0.25619],\n",
    "    [0.63544, 0.33244, 0.26481],\n",
    "    [0.64317, 0.33975, 0.27349],\n",
    "    [0.65092, 0.34706, 0.28218],\n",
    "    [0.65866, 0.3544, 0.29089],\n",
    "    [0.66642, 0.36175, 0.29964],\n",
    "    [0.67419, 0.36912, 0.30842],\n",
    "    [0.68198, 0.37652, 0.31722],\n",
    "    [0.68978, 0.38392, 0.32604],\n",
    "    [0.6976, 0.39135, 0.33493],\n",
    "    [0.70543, 0.39879, 0.3438],\n",
    "    [0.71329, 0.40627, 0.35272],\n",
    "    [0.72116, 0.41376, 0.36166],\n",
    "    [0.72905, 0.42126, 0.37062],\n",
    "    [0.73697, 0.4288, 0.37962],\n",
    "    [0.7449, 0.43635, 0.38864],\n",
    "    [0.75285, 0.44392, 0.39768],\n",
    "    [0.76083, 0.45151, 0.40675],\n",
    "    [0.76882, 0.45912, 0.41584],\n",
    "    [0.77684, 0.46676, 0.42496],\n",
    "    [0.78488, 0.47441, 0.43409],\n",
    "    [0.79293, 0.48208, 0.44327],\n",
    "    [0.80101, 0.48976, 0.45246],\n",
    "    [0.80911, 0.49749, 0.46167],\n",
    "    [0.81722, 0.50521, 0.47091],\n",
    "    [0.82536, 0.51296, 0.48017],\n",
    "    [0.83352, 0.52073, 0.48945],\n",
    "    [0.84169, 0.52853, 0.49876],\n",
    "    [0.84988, 0.53634, 0.5081],\n",
    "    [0.85809, 0.54416, 0.51745],\n",
    "    [0.86632, 0.55201, 0.52683],\n",
    "    [0.87457, 0.55988, 0.53622],\n",
    "    [0.88283, 0.56776, 0.54564],\n",
    "    [0.89111, 0.57567, 0.55508],\n",
    "    [0.89941, 0.58358, 0.56455],\n",
    "    [0.90772, 0.59153, 0.57404],\n",
    "    [0.91603, 0.59949, 0.58355],\n",
    "    [0.92437, 0.60747, 0.59309],\n",
    "    [0.93271, 0.61546, 0.60265],\n",
    "    [0.94108, 0.62348, 0.61223],\n",
    "    [0.94945, 0.63151, 0.62183],\n",
    "    [0.95783, 0.63956, 0.63147],\n",
    "    [0.96622, 0.64763, 0.64111],\n",
    "    [0.97462, 0.65572, 0.65079],\n",
    "    [0.98303, 0.66382, 0.66049],\n",
    "    [0.99145, 0.67194, 0.67022],\n",
    "    [0.99987, 0.68007, 0.67995]]\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmaps = {\n",
    "    name: ListedColormap(data, name = name) for name, data in [\n",
    "        ('berlin', _berlin_data),\n",
    "    ]}\n",
    "\n",
    "cmaps['berlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)            # NumPy\n",
    "    torch.manual_seed(seed)         # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)    # PyTorch GPU (single-GPU)\n",
    "\n",
    "# Set seed before initializing the model\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix field reconstruction\n",
    "\n",
    "The **matrix field reconstruction** has one less Jacobian step than the **vector field reconstruction** which is why it is computationally more efficient.\n",
    "\n",
    "We use the following deterministic transformations to get from the NN output to a divergence-free vector field v:\n",
    "1. Parameterise the Skew-Symmetric decomposition of A\n",
    "    - **U_topright = NN(x)** (non-zero values U_topright (N x 1) for the Upper Triangular U (N x dims x dims). For 2D, the dimensionality of U_topright is just 1, but generally it is (dims(dims - 1)/2)).\n",
    "2. Construct anti-symmetric matrix A\n",
    "    - **A = U - U.T**\n",
    "3. Attain divergence-free vector field v via row-wise Jacobians\n",
    "    - **v = (div(A[0,:]), div(A[1,:]))**, trace of the Jacobian\n",
    "\n",
    "To check that this is divergence free we need another Jacobian.\n",
    "\n",
    "see https://github.com/facebookresearch/neural-conservation-law/blob/main/pytorch/divfree.py\n",
    "\n",
    "Dimensionalities:\n",
    "- If our input in (4 x 4, 2) so flat that is (16, 2) coordinate pairs, U_topright should be (16, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- Do we use a NN that processes a batch or points individually? (Batch)\n",
    "- What is the output shape of u_v?\n",
    "    - For the dim = 2 case, do it is always (dim * (dim - 1) / 2), which is 1 because we only estimate the upper right corner of every (N) 2 x 2 matrix\n",
    "    - Can we build this directly into the net?\n",
    "\n",
    "The model seems to only be implemented under [jax > models.py > Divfree()](https://github.com/facebookresearch/neural-conservation-law/blob/20a403d00affad905d1c47b041bc60d0ff0ea360/jax/models.py#L118). DivfreeSparse() and DivFreeImplicit() are not used anywhere.\n",
    "\n",
    "The model is used in [jax > hh_experiment_DivFree.py](https://github.com/facebookresearch/neural-conservation-law/blob/20a403d00affad905d1c47b041bc60d0ff0ea360/jax/hh_experiment_DivFree.py#L53). Hodge decomp.\n",
    "\n",
    "dim = 10.  \n",
    "mlp = MLP(depth = layers, width = width, act = act, out_dim = **dim * (dim-1) // 2**, std = 1, bias = True)\n",
    "\n",
    "For dim = 2, at each point, each matrix A (2 x 2) is antisymm. So we only have to estimate a scalar for each input point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u_fn, params, _ = build_divfree_vector_field(self.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        output_dim = int((input_dim * (input_dim - 1)) / 2)\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # put deterministic transformations here with torch functional\n",
    "        return self.net(x)  # Output shape: (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_compute_A(nn.Module):\n",
    "    def __init__(self, input_dim = 2, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Output dim follows input dims\n",
    "        # for 2D input the NN output dim is 1\n",
    "        self.output_dim = int((input_dim * (input_dim - 1)) / 2)\n",
    "\n",
    "        # Replace with something more sophisticated\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # put deterministic transformations here with torch functional\n",
    "\n",
    "        # RUN THROUGH NET\n",
    "        U_fill = self.net(x)\n",
    "\n",
    "        # Extract dims\n",
    "        N = int(x.shape[0])\n",
    "        \n",
    "        # This version works with vmap, diagonal shifts diagional one up\n",
    "        U_zero_one = torch.triu(torch.ones(N, self.input_dim, self.input_dim), diagonal = 1)\n",
    "\n",
    "        # U_zero_one is (N, 2, 2), U_fill is (N, 1), so we need to unsqueeze the first dim of U_fill\n",
    "        U = U_zero_one * U_fill.unsqueeze(1)\n",
    "\n",
    "        # U is (N, 2, 2), so we need to swap the last two dims and then subtract\n",
    "        A = U - U.transpose(1, 2)\n",
    "\n",
    "        return A  # Output shape: (N, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "# 4 x 4 grid\n",
    "N = 16  # N should be a perfect square\n",
    "N_side = int(N ** 0.5)\n",
    "\n",
    "dims = 2\n",
    "\n",
    "# inputs = torch.randn(N, dims)  # Random (N, 2) inputs\n",
    "xy_side = torch.linspace(0, 1, N_side)\n",
    "# torch meshgrid, not default but we want to index by x, y\n",
    "X_mesh, Y_mesh = torch.meshgrid(xy_side, xy_side, indexing = \"xy\")\n",
    "# Construct flat pairs of points\n",
    "inputs = torch.cat([X_mesh.reshape(-1, 1), Y_mesh.reshape(-1, 1)], dim = 1)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 2])\n"
     ]
    }
   ],
   "source": [
    "# overwrite with 20 * 20 grid\n",
    "N = 20 * 20 # N should be a perfect square\n",
    "N_side = int(N ** 0.5)\n",
    "\n",
    "dims = 2\n",
    "\n",
    "# inputs = torch.randn(N, dims)  # Random (N, 2) inputs\n",
    "xy_side = torch.linspace(0, 3, N_side)\n",
    "# torch meshgrid, not default but we want to index by x, y\n",
    "X_mesh, Y_mesh = torch.meshgrid(xy_side, xy_side, indexing = \"xy\")\n",
    "\n",
    "# Construct flat pairs of points\n",
    "# now the span [0, 3]\n",
    "inputs_03 = torch.cat([X_mesh.reshape(-1, 1), Y_mesh.reshape(-1, 1)], dim = 1)\n",
    "print(inputs_03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write this as a function because we need to input a function for the Jacobian calculation\n",
    "def compute_A(x, model_for_A):\n",
    "    # U_fill is (N, 1), which is the model output, fills upper right corner of all 2x2 matrices\n",
    "    U_fill = model_for_A(x)\n",
    "    # Extract N \n",
    "    N = int(x.shape[0])\n",
    "\n",
    "    # This version works with vmap, diagonal shifts diagional one up\n",
    "    U_zero_one = torch.triu(torch.ones(N, dims, dims), diagonal = 1)\n",
    "    # U_zero_one is (N, 2, 2), U_fill is (N, 1), so we need to unsqueeze the first dim of U_fill\n",
    "    U = U_zero_one * U_fill.unsqueeze(1)\n",
    "    # result is the same as U[:, 0, 1] = U_fill.squeeze()\n",
    "    # alternative might be torch.index_add\n",
    "    # U is (N, 2, 2), so we need to swap the last two dims and then subtract\n",
    "    A = U - U.transpose(1, 2)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_v(x, model_for_A):\n",
    "    # Compute the Jacobian of A \n",
    "    jacobian_A = vmap(jacfwd(model_for_A))(x)\n",
    "    # assert that the second dim (size N) is redundant\n",
    "    assert(jacobian_A[:, 0, : , :, :] == jacobian_A[:, -1, : , :, :]).any()\n",
    "    # remove this redundant dimension\n",
    "    jacobian_A_lean = jacobian_A[:, 0, : , :, :]\n",
    "    # print(jacobian_A_lean.shape): torch.Size([N, 2, 2, 2])\n",
    "    # dim1 is what is considered the rows, dim2 is what is considered the columns\n",
    "    # So we compute this over the last two dims because the Jacobian is N x two (2 x 2)\n",
    "    v = torch.diagonal(jacobian_A_lean, dim1 = -2, dim2 = -1).sum(dim = 1)\n",
    "    # diagonal returns torch.Size([16, 2, 2]) so now we sum over the middle dim\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_functional(x):\n",
    "    # print(jacobian_v.shape): torch.Size([16, 16, 2, 2])\n",
    "    jacobian_v = vmap(jacfwd(compute_v))(x)\n",
    "    print(jacobian_v.shape)\n",
    "    # assert that the second dim (size N) is redundant\n",
    "    assert(jacobian_v[:, 0, :, :] == jacobian_v[:, -1, :, :]).any()\n",
    "    # print(jacobian_v_lean.shape): torch.Size([16, 2, 2])\n",
    "    jacobian_v_lean = jacobian_v[:, 0, :, :]\n",
    "    # torch.Size([16, 2]) and then we sum over the last dim to combine div_x and div_y\n",
    "    # attain flat divergence field \n",
    "    div_flat = torch.diagonal(jacobian_v_lean, dim1 = -2, dim2 = -1).sum(dim = -1)\n",
    "    return div_flat\n",
    "\n",
    "# div_v = div_functional(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdiv_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_03\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[149], line 3\u001b[0m, in \u001b[0;36mdiv_functional\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiv_functional\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# print(jacobian_v.shape): torch.Size([16, 16, 2, 2])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     jacobian_v \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_v\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(jacobian_v\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# assert that the second dim (size N) is redundant\u001b[39;00m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1163\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     _, jvp_out \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[0;32m-> 1163\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpush_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1165\u001b[0m     results, aux \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1154\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn.<locals>.push_jvp\u001b[0;34m(basis)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush_jvp\u001b[39m(basis):\n\u001b[0;32m-> 1154\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# output[0] is the output of `func(*args)`\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;241m0\u001b[39m], is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1000\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    998\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    999\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m-> 1000\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[148], line 3\u001b[0m, in \u001b[0;36mcompute_v\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_v\u001b[39m(inputs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Compute the Jacobian of A \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     jacobian_A \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# assert that the second dim (size N) is redundant\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(jacobian_A[:, \u001b[38;5;241m0\u001b[39m, : , :, :] \u001b[38;5;241m==\u001b[39m jacobian_A[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, : , :, :])\u001b[38;5;241m.\u001b[39many()\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1163\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     _, jvp_out \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[0;32m-> 1163\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpush_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1165\u001b[0m     results, aux \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1154\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn.<locals>.push_jvp\u001b[0;34m(basis)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush_jvp\u001b[39m(basis):\n\u001b[0;32m-> 1154\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# output[0] is the output of `func(*args)`\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;241m0\u001b[39m], is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1000\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    998\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    999\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m-> 1000\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m, in \u001b[0;36mMLP_compute_A.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# put deterministic transformations here with torch functional\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# RUN THROUGH NET\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     U_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Extract dims\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "div_functional(inputs_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_v_stream(v, div_v, x, title_string = \"v(x)\", color_abs_max = 0.5, lw_scalar = 2):\n",
    "    \"\"\"Plots a vector field v(x) and its divergence div_v(x) as a streamplot on a square grid.\n",
    "    The linewidth corresponds to the magnitude/speed of the vector field.\n",
    "    The color corresponds to the divergence of the vector field. We use the dark doiverging colormap \"berlin\" so that zero divergence is visible as black. \n",
    "\n",
    "    Args:\n",
    "        v (torch.Size([N_long, 2])): flattened square vector field, where the first column is the u component and the second column is the v component\n",
    "        div_v (torch.Size([N_long])): flat divergence of the vector field\n",
    "        x (torch.Size([N_long, 2])): flattend meshgrids, where the first column is the x component and the second column is the y component\n",
    "        title_string (str, optional): Title for plot. Defaults to \"v(x)\".\n",
    "        color_abs_max (float, optional): Maximum absolute value for color normalization. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract N_long and calculate sqrt of N_long, N_side\n",
    "    N_long = torch.tensor(v.shape[0])\n",
    "    N_side = int(torch.sqrt(N_long))\n",
    "\n",
    "    # Extract both columns/components from v and make square\n",
    "    U = v[:, 0].reshape(N_side, N_side)\n",
    "    V = v[:, 1].reshape(N_side, N_side)\n",
    "\n",
    "    # Make coordinates square again\n",
    "    X = x[:, 0].reshape(N_side, N_side)\n",
    "    Y = x[:, 1].reshape(N_side, N_side)\n",
    "\n",
    "    div_v_square = div_v.reshape(N_side, N_side)\n",
    "    # Define symmetric normalization with zero centered\n",
    "    norm = mcolors.TwoSlopeNorm(vmin = - color_abs_max, vcenter = 0, vmax = color_abs_max)\n",
    "\n",
    "    # Magnitude i.e. speed: square each element to remove negative direction, then square root\n",
    "    mag = torch.sqrt(torch.square(U) + torch.square(V))\n",
    "    lw = mag * lw_scalar / torch.max(mag) # normalise mag\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "\n",
    "    ax.streamplot(X.numpy(), Y.numpy(), U.numpy(), V.numpy(), \n",
    "                  linewidth = lw.numpy(),\n",
    "                  color = div_v_square.numpy(), \n",
    "                  cmap = cmaps['berlin'],\n",
    "                  norm = norm)\n",
    "    \n",
    "    # coolwarm is diverging but has grey in middle\n",
    "    # add norm\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_title(title_string)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_v_quiver(v, div_v, x, title_string = \"v(x)\", color_abs_max = 0.5, lw_scalar = 2):\n",
    "    \"\"\"Plots a vector field v(x) and its divergence div_v(x) as a quiverplot on a square grid.\n",
    "    The quiverlength automatically corresponds to the magnitude/speed of the vector field.\n",
    "    The color corresponds to the divergence of the vector field. We use the dark diverging colormap \"berlin\" so that zero divergence is visible as black. \n",
    "\n",
    "    Args:\n",
    "        v (torch.Size([N_long, 2])): flattened square vector field, where the first column is the u component and the second column is the v component\n",
    "        div_v (torch.Size([N_long])): flat divergence of the vector field\n",
    "        x (torch.Size([N_long, 2])): flattend meshgrids, where the first column is the x component and the second column is the y component\n",
    "        title_string (str, optional): Title for plot. Defaults to \"v(x)\".\n",
    "        color_abs_max (float, optional): Maximum absolute value for color normalization. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract N_long and calculate sqrt of N_long, N_side\n",
    "    N_long = torch.tensor(v.shape[0])\n",
    "    N_side = int(torch.sqrt(N_long))\n",
    "\n",
    "    # Extract both columns/components from v and make square\n",
    "    U = v[:, 0].reshape(N_side, N_side)\n",
    "    V = v[:, 1].reshape(N_side, N_side)\n",
    "\n",
    "    # Make coordinates square again\n",
    "    X = x[:, 0].reshape(N_side, N_side)\n",
    "    Y = x[:, 1].reshape(N_side, N_side)\n",
    "\n",
    "    div_v_square = div_v.reshape(N_side, N_side)\n",
    "    # Define symmetric normalization with zero centered\n",
    "    norm = mcolors.TwoSlopeNorm(vmin = - color_abs_max, vcenter = 0, vmax = color_abs_max)\n",
    "\n",
    "    # Magnitude i.e. speed: square each element to remove negative direction, then square root\n",
    "    # mag = torch.sqrt(torch.square(U) + torch.square(V))\n",
    "    # lw = mag * lw_scalar / torch.max(mag) # normalise mag\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "\n",
    "    ax.quiver(X.numpy(), Y.numpy(), U.numpy(), V.numpy(),\n",
    "              div_v_square.numpy(), # color is passed directly\n",
    "              cmap = cmaps['berlin'],\n",
    "              norm = norm)\n",
    "\n",
    "    # ax.quiver(x[:, 0], x[:, 1], v[:, 0], v[:, 1])\n",
    "    \n",
    "    # coolwarm is diverging but has grey in middle\n",
    "    # add norm\n",
    "    ax.set_aspect(1)\n",
    "    ax.set_title(title_string)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m div_v \u001b[38;5;241m=\u001b[39m div_functional(inputs)\n\u001b[1;32m      4\u001b[0m visualise_v_stream(v\u001b[38;5;241m.\u001b[39mdetach(), div_v\u001b[38;5;241m.\u001b[39mdetach(), inputs, title_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv(x)\u001b[39m\u001b[38;5;124m\"\u001b[39m, color_abs_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mcompute_v\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_v\u001b[39m(inputs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Compute the Jacobian of A \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     jacobian_A \u001b[38;5;241m=\u001b[39m vmap(jacfwd(\u001b[43mmodel_A\u001b[49m))(inputs)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# assert that the second dim (size N) is redundant\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(jacobian_A[:, \u001b[38;5;241m0\u001b[39m, : , :, :] \u001b[38;5;241m==\u001b[39m jacobian_A[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, : , :, :])\u001b[38;5;241m.\u001b[39many()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_A' is not defined"
     ]
    }
   ],
   "source": [
    "v = compute_v(inputs)\n",
    "div_v = div_functional(inputs)\n",
    "\n",
    "visualise_v_stream(v.detach(), div_v.detach(), inputs, title_string = \"v(x)\", color_abs_max = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_discrete(v_flat_grid, dx = 1, dy = 1, return_components_bool = False):\n",
    "    \"\"\"Compute\n",
    "    div(v) = dU/dx + dV/dy\n",
    "    where v = (U, V) is a vector field\n",
    "    edges can be funky\n",
    "\n",
    "    Args:\n",
    "        v_flat_grid (torch.Size([N, 2])): flattened vector field\n",
    "        dx (int, optional): unit spacing between x columns. Defaults to 1.\n",
    "        dy (int, optional): unit spacing between y rows. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        div_v (torch.Size([N, 1])): Same extent as v input, but only 1 dim, torch tensor for consistency\n",
    "    OR Returns:\n",
    "        div_v (torch.Size([N, 1])): Same extent as v input, but only 1 dim\n",
    "        dU_dx (torch.Size([N, 1])): x derivative of U component\n",
    "        dV_dy (torch.Size([N, 1])): y derivative of V component\n",
    "    \"\"\"\n",
    "    N_side = int(np.sqrt(v_flat_grid.shape[0]))\n",
    "    v_square = v_flat_grid.reshape(N_side, N_side, 2)\n",
    "\n",
    "    U = v_square[:, :, 0]\n",
    "    V = v_square[:, :, 1]\n",
    "\n",
    "    # Compute the x and y derivatives\n",
    "    dU_dx = np.gradient(U, dx, axis = 1) # axis 1 is x\n",
    "    dV_dy = np.gradient(V, dy, axis = 0) # axis 0 is y\n",
    "\n",
    "    # Compute the divergence\n",
    "    div_v = dU_dx + dV_dy\n",
    "\n",
    "    if return_components_bool == True:\n",
    "        return torch.tensor(div_v).reshape(-1, 1), torch.tensor(dU_dx).reshape(-1, 1), torch.tensor(dV_dy).reshape(-1, 1)\n",
    "    else:\n",
    "        return torch.tensor(div_v).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulate_convergence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_convergence\u001b[49m(inputs_03)\n\u001b[1;32m      2\u001b[0m div_v \u001b[38;5;241m=\u001b[39m div_discrete(v)\n\u001b[1;32m      4\u001b[0m visualise_v_quiver(v, div_v, inputs_03, title_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv(x)\u001b[39m\u001b[38;5;124m\"\u001b[39m, color_abs_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simulate_convergence' is not defined"
     ]
    }
   ],
   "source": [
    "v = simulate_convergence(inputs_03)\n",
    "div_v = div_discrete(v)\n",
    "\n",
    "visualise_v_quiver(v, div_v, inputs_03, title_string = \"v(x)\", color_abs_max = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -0.1466],\n",
       "         [ 0.1466,  0.0000]],\n",
       "\n",
       "        [[ 0.0000, -0.2350],\n",
       "         [ 0.2350,  0.0000]],\n",
       "\n",
       "        [[ 0.0000, -0.4260],\n",
       "         [ 0.4260,  0.0000]],\n",
       "\n",
       "        [[ 0.0000, -0.6009],\n",
       "         [ 0.6009,  0.0000]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_A = MLP_compute_A()\n",
    "model_A.train()\n",
    "\n",
    "# fixed_value = 0.5  # Change this to your desired fixed value\n",
    "\n",
    "# with torch.no_grad():  # Ensure we don't track gradients\n",
    "#    for param in model_A.parameters():\n",
    "#        param.fill_(fixed_value)  # Set all elements to fixed_value\n",
    "\n",
    "\n",
    "x = torch.tensor([[0.0, 0.5], [1.0, 0.8], [2.0, 2.0], [3.0, 3.0]]).requires_grad_()\n",
    "A = model_A(x)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.autograd.functional.jacobian: \n",
    "\n",
    "For the N's it seems we have to use pairwise indices: 0, 0, 1, 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 2, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0110, -0.0779],\n",
       "        [ 0.1238, -0.0442],\n",
       "        [ 0.1249, -0.0522],\n",
       "        [ 0.1226, -0.0511]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_A_autograd = torch.autograd.functional.jacobian(model_A, x)\n",
    "\n",
    "print(jacobian_A_autograd.shape)\n",
    "n_i = 2\n",
    "print(jacobian_A_autograd[n_i, :, :, n_i, :])\n",
    "\n",
    "jacobian_A_autograd_lean = torch.einsum('nabnc -> nabc', jacobian_A_autograd)\n",
    "print(jacobian_A_autograd_lean.shape)\n",
    "\n",
    "jacobian_A_autograd_lean.diagonal(dim1 = -2, dim2 = -1).sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0642,  0.1081],\n",
       "        [ 0.0055,  0.2341],\n",
       "        [ 0.0249,  0.2973],\n",
       "        [ 0.0266,  0.3012]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_A_vmap_jacrev = vmap(jacrev(model_A))(x)\n",
    "# assert that the second dim (size 2) is redundant\n",
    "assert(jacobian_A_vmap_jacrev[:, 0, :, :, :] == jacobian_A_vmap_jacrev[:, 1, :, :, :]).any()\n",
    "jacobian_A_vmap_jacrev_lean = torch.einsum('n r a b c -> n a b c', jacobian_A_vmap_jacrev)\n",
    "\n",
    "print(jacobian_A_vmap_jacrev_lean.shape)\n",
    "\n",
    "jacobian_A_vmap_jacrev_lean.diagonal(dim1 = -2, dim2 = -1).sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000],\n",
       "          [ 0.0321,  0.0540]],\n",
       "\n",
       "         [[-0.0321, -0.0540],\n",
       "          [ 0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000],\n",
       "          [ 0.0321,  0.0540]],\n",
       "\n",
       "         [[-0.0321, -0.0540],\n",
       "          [ 0.0000,  0.0000]]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_A_vmap_jacrev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m jacobian_A_vmap_jacrev[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :, :, :]\n\u001b[1;32m      2\u001b[0m jacobian_A_vmap_jacrev[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, :, :, :]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(jacobian_A_vmap_jacrev[:, \u001b[38;5;241m1\u001b[39m, :, :, :] \u001b[38;5;241m==\u001b[39m jacobian_A_vmap_jacrev[:, \u001b[38;5;241m0\u001b[39m, :, :, :])\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jacobian_A_vmap_jacrev[0, 0, :, :, :]\n",
    "jacobian_A_vmap_jacrev[1, 0, :, :, :]\n",
    "\n",
    "tolerance = 1e-6  # Adjust based on precision needs\n",
    "assert torch.allclose(jacobian_A_vmap_jacrev[:, 1, :, :, :], jacobian_A_vmap_jacrev[:, 0, :, :, :], atol = tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate_convergence, simulate_merge, simulate_branching, simulate_deflection, simulate_ridge\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data is torch.Size([400, 2]).\n",
      "The dtype of the input data is torch.float32.\n",
      "\n",
      "Start Training\n",
      "Epoch 1/3000, Training Loss (MSE): 3.5045\n",
      "Epoch 2/3000, Training Loss (MSE): 2.7653\n",
      "Epoch 3/3000, Training Loss (MSE): 1.9253\n",
      "Epoch 4/3000, Training Loss (MSE): 2.7459\n",
      "Epoch 5/3000, Training Loss (MSE): 3.8651\n",
      "Epoch 6/3000, Training Loss (MSE): 2.3756\n",
      "Epoch 7/3000, Training Loss (MSE): 3.0656\n",
      "Epoch 8/3000, Training Loss (MSE): 2.8001\n",
      "Epoch 9/3000, Training Loss (MSE): 2.5379\n",
      "Epoch 10/3000, Training Loss (MSE): 3.0449\n",
      "Epoch 11/3000, Training Loss (MSE): 2.8821\n",
      "Epoch 12/3000, Training Loss (MSE): 2.4246\n",
      "Epoch 13/3000, Training Loss (MSE): 2.8064\n",
      "Epoch 14/3000, Training Loss (MSE): 2.6566\n",
      "Epoch 15/3000, Training Loss (MSE): 2.1046\n",
      "Epoch 16/3000, Training Loss (MSE): 2.3914\n",
      "Epoch 17/3000, Training Loss (MSE): 2.6622\n",
      "Epoch 18/3000, Training Loss (MSE): 1.6066\n",
      "Epoch 19/3000, Training Loss (MSE): 1.9638\n",
      "Epoch 20/3000, Training Loss (MSE): 2.6218\n",
      "Epoch 21/3000, Training Loss (MSE): 1.9785\n",
      "Epoch 22/3000, Training Loss (MSE): 2.3848\n",
      "Epoch 23/3000, Training Loss (MSE): 2.3488\n",
      "Epoch 24/3000, Training Loss (MSE): 2.5670\n",
      "Epoch 25/3000, Training Loss (MSE): 2.4619\n",
      "Epoch 26/3000, Training Loss (MSE): 2.1950\n",
      "Epoch 27/3000, Training Loss (MSE): 1.9992\n",
      "Epoch 28/3000, Training Loss (MSE): 3.0962\n",
      "Epoch 29/3000, Training Loss (MSE): 2.1682\n",
      "Epoch 30/3000, Training Loss (MSE): 2.3572\n",
      "Epoch 31/3000, Training Loss (MSE): 2.7287\n",
      "Epoch 32/3000, Training Loss (MSE): 2.4023\n",
      "Epoch 33/3000, Training Loss (MSE): 2.4278\n",
      "Epoch 34/3000, Training Loss (MSE): 2.5142\n",
      "Epoch 35/3000, Training Loss (MSE): 2.6472\n",
      "Epoch 36/3000, Training Loss (MSE): 2.6315\n",
      "Epoch 37/3000, Training Loss (MSE): 3.0321\n",
      "Epoch 38/3000, Training Loss (MSE): 1.8582\n",
      "Epoch 39/3000, Training Loss (MSE): 2.2411\n",
      "Epoch 40/3000, Training Loss (MSE): 1.6430\n",
      "Epoch 41/3000, Training Loss (MSE): 2.5418\n",
      "Epoch 42/3000, Training Loss (MSE): 2.0309\n",
      "Epoch 43/3000, Training Loss (MSE): 1.4310\n",
      "Epoch 44/3000, Training Loss (MSE): 2.3757\n",
      "Epoch 45/3000, Training Loss (MSE): 2.8791\n",
      "Epoch 46/3000, Training Loss (MSE): 2.1327\n",
      "Epoch 47/3000, Training Loss (MSE): 2.1981\n",
      "Epoch 48/3000, Training Loss (MSE): 2.2047\n",
      "Epoch 49/3000, Training Loss (MSE): 1.8576\n",
      "Epoch 50/3000, Training Loss (MSE): 1.7143\n",
      "Epoch 51/3000, Training Loss (MSE): 2.5144\n",
      "Epoch 52/3000, Training Loss (MSE): 1.2926\n",
      "Epoch 53/3000, Training Loss (MSE): 2.3217\n",
      "Epoch 54/3000, Training Loss (MSE): 2.1862\n",
      "Epoch 55/3000, Training Loss (MSE): 2.0911\n",
      "Epoch 56/3000, Training Loss (MSE): 1.7392\n",
      "Epoch 57/3000, Training Loss (MSE): 1.6527\n",
      "Epoch 58/3000, Training Loss (MSE): 1.8875\n",
      "Epoch 59/3000, Training Loss (MSE): 1.6612\n",
      "Epoch 60/3000, Training Loss (MSE): 1.3094\n",
      "Epoch 61/3000, Training Loss (MSE): 1.6793\n",
      "Epoch 62/3000, Training Loss (MSE): 1.8788\n",
      "Epoch 63/3000, Training Loss (MSE): 1.5628\n",
      "Epoch 64/3000, Training Loss (MSE): 1.7055\n",
      "Epoch 65/3000, Training Loss (MSE): 2.2299\n",
      "Epoch 66/3000, Training Loss (MSE): 1.5391\n",
      "Epoch 67/3000, Training Loss (MSE): 1.5707\n",
      "Epoch 68/3000, Training Loss (MSE): 1.1172\n",
      "Epoch 69/3000, Training Loss (MSE): 2.0692\n",
      "Epoch 70/3000, Training Loss (MSE): 1.6429\n",
      "Epoch 71/3000, Training Loss (MSE): 1.0230\n",
      "Epoch 72/3000, Training Loss (MSE): 2.2487\n",
      "Epoch 73/3000, Training Loss (MSE): 1.7147\n",
      "Epoch 74/3000, Training Loss (MSE): 1.0998\n",
      "Epoch 75/3000, Training Loss (MSE): 1.0526\n",
      "Epoch 76/3000, Training Loss (MSE): 1.2456\n",
      "Epoch 77/3000, Training Loss (MSE): 1.1320\n",
      "Epoch 78/3000, Training Loss (MSE): 0.7270\n",
      "Epoch 79/3000, Training Loss (MSE): 1.5747\n",
      "Epoch 80/3000, Training Loss (MSE): 1.4759\n",
      "Epoch 81/3000, Training Loss (MSE): 1.2012\n",
      "Epoch 82/3000, Training Loss (MSE): 1.4632\n",
      "Epoch 83/3000, Training Loss (MSE): 0.9955\n",
      "Epoch 84/3000, Training Loss (MSE): 1.7977\n",
      "Epoch 85/3000, Training Loss (MSE): 1.0722\n",
      "Epoch 86/3000, Training Loss (MSE): 1.2760\n",
      "Epoch 87/3000, Training Loss (MSE): 1.3017\n",
      "Epoch 88/3000, Training Loss (MSE): 1.2090\n",
      "Epoch 89/3000, Training Loss (MSE): 1.7204\n",
      "Epoch 90/3000, Training Loss (MSE): 1.1960\n",
      "Epoch 91/3000, Training Loss (MSE): 1.1283\n",
      "Epoch 92/3000, Training Loss (MSE): 0.7553\n",
      "Epoch 93/3000, Training Loss (MSE): 1.1043\n",
      "Epoch 94/3000, Training Loss (MSE): 1.1271\n",
      "Epoch 95/3000, Training Loss (MSE): 0.9247\n",
      "Epoch 96/3000, Training Loss (MSE): 0.6408\n",
      "Epoch 97/3000, Training Loss (MSE): 1.7700\n",
      "Epoch 98/3000, Training Loss (MSE): 2.2398\n",
      "Epoch 99/3000, Training Loss (MSE): 1.0842\n",
      "Epoch 100/3000, Training Loss (MSE): 1.7817\n",
      "Epoch 101/3000, Training Loss (MSE): 1.4105\n",
      "Epoch 102/3000, Training Loss (MSE): 1.5055\n",
      "Epoch 103/3000, Training Loss (MSE): 1.3447\n",
      "Epoch 104/3000, Training Loss (MSE): 1.1263\n",
      "Epoch 105/3000, Training Loss (MSE): 1.4333\n",
      "Epoch 106/3000, Training Loss (MSE): 1.3724\n",
      "Epoch 107/3000, Training Loss (MSE): 1.2286\n",
      "Epoch 108/3000, Training Loss (MSE): 1.6350\n",
      "Epoch 109/3000, Training Loss (MSE): 1.1750\n",
      "Epoch 110/3000, Training Loss (MSE): 0.9641\n",
      "Epoch 111/3000, Training Loss (MSE): 1.6416\n",
      "Epoch 112/3000, Training Loss (MSE): 1.7900\n",
      "Epoch 113/3000, Training Loss (MSE): 1.0213\n",
      "Epoch 114/3000, Training Loss (MSE): 2.1163\n",
      "Epoch 115/3000, Training Loss (MSE): 1.4530\n",
      "Epoch 116/3000, Training Loss (MSE): 1.3982\n",
      "Epoch 117/3000, Training Loss (MSE): 1.3228\n",
      "Epoch 118/3000, Training Loss (MSE): 1.6649\n",
      "Epoch 119/3000, Training Loss (MSE): 1.0788\n",
      "Epoch 120/3000, Training Loss (MSE): 1.5150\n",
      "Epoch 121/3000, Training Loss (MSE): 1.0358\n",
      "Epoch 122/3000, Training Loss (MSE): 1.3557\n",
      "Epoch 123/3000, Training Loss (MSE): 1.4429\n",
      "Epoch 124/3000, Training Loss (MSE): 1.2869\n",
      "Epoch 125/3000, Training Loss (MSE): 1.8864\n",
      "Epoch 126/3000, Training Loss (MSE): 0.9739\n",
      "Epoch 127/3000, Training Loss (MSE): 1.3439\n",
      "Epoch 128/3000, Training Loss (MSE): 1.0731\n",
      "Epoch 129/3000, Training Loss (MSE): 1.0324\n",
      "Epoch 130/3000, Training Loss (MSE): 1.3512\n",
      "Epoch 131/3000, Training Loss (MSE): 1.5756\n",
      "Epoch 132/3000, Training Loss (MSE): 1.3536\n",
      "Epoch 133/3000, Training Loss (MSE): 1.1649\n",
      "Epoch 134/3000, Training Loss (MSE): 0.9576\n",
      "Epoch 135/3000, Training Loss (MSE): 2.1749\n",
      "Epoch 136/3000, Training Loss (MSE): 0.8561\n",
      "Epoch 137/3000, Training Loss (MSE): 2.0854\n",
      "Epoch 138/3000, Training Loss (MSE): 1.2775\n",
      "Epoch 139/3000, Training Loss (MSE): 1.8427\n",
      "Epoch 140/3000, Training Loss (MSE): 1.2182\n",
      "Epoch 141/3000, Training Loss (MSE): 1.8962\n",
      "Epoch 142/3000, Training Loss (MSE): 1.6080\n",
      "Epoch 143/3000, Training Loss (MSE): 1.1493\n",
      "Epoch 144/3000, Training Loss (MSE): 1.3526\n",
      "Epoch 145/3000, Training Loss (MSE): 2.0580\n",
      "Epoch 146/3000, Training Loss (MSE): 1.4464\n",
      "Epoch 147/3000, Training Loss (MSE): 1.9729\n",
      "Epoch 148/3000, Training Loss (MSE): 1.2639\n",
      "Epoch 149/3000, Training Loss (MSE): 0.8583\n",
      "Epoch 150/3000, Training Loss (MSE): 1.7805\n",
      "Epoch 151/3000, Training Loss (MSE): 1.6609\n",
      "Epoch 152/3000, Training Loss (MSE): 1.5398\n",
      "Epoch 153/3000, Training Loss (MSE): 0.7643\n",
      "Epoch 154/3000, Training Loss (MSE): 0.9052\n",
      "Epoch 155/3000, Training Loss (MSE): 1.4872\n",
      "Epoch 156/3000, Training Loss (MSE): 1.0447\n",
      "Epoch 157/3000, Training Loss (MSE): 1.3120\n",
      "Epoch 158/3000, Training Loss (MSE): 1.6409\n",
      "Epoch 159/3000, Training Loss (MSE): 1.6076\n",
      "Epoch 160/3000, Training Loss (MSE): 0.8938\n",
      "Epoch 161/3000, Training Loss (MSE): 1.6425\n",
      "Epoch 162/3000, Training Loss (MSE): 1.6528\n",
      "Epoch 163/3000, Training Loss (MSE): 1.2918\n",
      "Epoch 164/3000, Training Loss (MSE): 1.2811\n",
      "Epoch 165/3000, Training Loss (MSE): 1.0818\n",
      "Epoch 166/3000, Training Loss (MSE): 1.3327\n",
      "Epoch 167/3000, Training Loss (MSE): 1.4743\n",
      "Epoch 168/3000, Training Loss (MSE): 0.9499\n",
      "Epoch 169/3000, Training Loss (MSE): 0.7826\n",
      "Epoch 170/3000, Training Loss (MSE): 1.0294\n",
      "Epoch 171/3000, Training Loss (MSE): 1.1120\n",
      "Epoch 172/3000, Training Loss (MSE): 1.1666\n",
      "Epoch 173/3000, Training Loss (MSE): 1.6606\n",
      "Epoch 174/3000, Training Loss (MSE): 1.2872\n",
      "Epoch 175/3000, Training Loss (MSE): 1.2552\n",
      "Epoch 176/3000, Training Loss (MSE): 1.2456\n",
      "Epoch 177/3000, Training Loss (MSE): 1.0168\n",
      "Epoch 178/3000, Training Loss (MSE): 0.9195\n",
      "Epoch 179/3000, Training Loss (MSE): 1.1285\n",
      "Epoch 180/3000, Training Loss (MSE): 1.1663\n",
      "Epoch 181/3000, Training Loss (MSE): 1.5541\n",
      "Epoch 182/3000, Training Loss (MSE): 0.8434\n",
      "Epoch 183/3000, Training Loss (MSE): 1.9385\n",
      "Epoch 184/3000, Training Loss (MSE): 1.5268\n",
      "Epoch 185/3000, Training Loss (MSE): 2.2190\n",
      "Epoch 186/3000, Training Loss (MSE): 1.0788\n",
      "Epoch 187/3000, Training Loss (MSE): 1.9152\n",
      "Epoch 188/3000, Training Loss (MSE): 1.3007\n",
      "Epoch 189/3000, Training Loss (MSE): 1.1264\n",
      "Epoch 190/3000, Training Loss (MSE): 2.1086\n",
      "Epoch 191/3000, Training Loss (MSE): 2.2582\n",
      "Epoch 192/3000, Training Loss (MSE): 0.6327\n",
      "Epoch 193/3000, Training Loss (MSE): 1.9241\n",
      "Epoch 194/3000, Training Loss (MSE): 1.4939\n",
      "Epoch 195/3000, Training Loss (MSE): 2.0768\n",
      "Epoch 196/3000, Training Loss (MSE): 0.9506\n",
      "Epoch 197/3000, Training Loss (MSE): 1.2582\n",
      "Epoch 198/3000, Training Loss (MSE): 0.9129\n",
      "Epoch 199/3000, Training Loss (MSE): 1.3607\n",
      "Epoch 200/3000, Training Loss (MSE): 1.5992\n",
      "Epoch 201/3000, Training Loss (MSE): 1.7307\n",
      "Epoch 202/3000, Training Loss (MSE): 1.9422\n",
      "Epoch 203/3000, Training Loss (MSE): 1.6297\n",
      "Epoch 204/3000, Training Loss (MSE): 1.5047\n",
      "Epoch 205/3000, Training Loss (MSE): 1.5767\n",
      "Epoch 206/3000, Training Loss (MSE): 1.2472\n",
      "Epoch 207/3000, Training Loss (MSE): 1.7630\n",
      "Epoch 208/3000, Training Loss (MSE): 0.9789\n",
      "Epoch 209/3000, Training Loss (MSE): 1.6213\n",
      "Epoch 210/3000, Training Loss (MSE): 0.7414\n",
      "Epoch 211/3000, Training Loss (MSE): 1.0003\n",
      "Epoch 212/3000, Training Loss (MSE): 1.7145\n",
      "Epoch 213/3000, Training Loss (MSE): 0.8982\n",
      "Epoch 214/3000, Training Loss (MSE): 1.8889\n",
      "Epoch 215/3000, Training Loss (MSE): 2.1546\n",
      "Epoch 216/3000, Training Loss (MSE): 1.6242\n",
      "Epoch 217/3000, Training Loss (MSE): 2.0859\n",
      "Epoch 218/3000, Training Loss (MSE): 1.4087\n",
      "Epoch 219/3000, Training Loss (MSE): 1.3563\n",
      "Epoch 220/3000, Training Loss (MSE): 1.5538\n",
      "Epoch 221/3000, Training Loss (MSE): 0.8588\n",
      "Epoch 222/3000, Training Loss (MSE): 1.3471\n",
      "Epoch 223/3000, Training Loss (MSE): 1.7857\n",
      "Epoch 224/3000, Training Loss (MSE): 1.5698\n",
      "Epoch 225/3000, Training Loss (MSE): 1.9727\n",
      "Epoch 226/3000, Training Loss (MSE): 1.9327\n",
      "Epoch 227/3000, Training Loss (MSE): 1.6369\n",
      "Epoch 228/3000, Training Loss (MSE): 1.4759\n",
      "Epoch 229/3000, Training Loss (MSE): 1.2042\n",
      "Epoch 230/3000, Training Loss (MSE): 0.7701\n",
      "Epoch 231/3000, Training Loss (MSE): 2.4559\n",
      "Epoch 232/3000, Training Loss (MSE): 1.9648\n",
      "Epoch 233/3000, Training Loss (MSE): 1.7984\n",
      "Epoch 234/3000, Training Loss (MSE): 1.5970\n",
      "Epoch 235/3000, Training Loss (MSE): 2.0111\n",
      "Epoch 236/3000, Training Loss (MSE): 1.6419\n",
      "Epoch 237/3000, Training Loss (MSE): 2.9153\n",
      "Epoch 238/3000, Training Loss (MSE): 1.0465\n",
      "Epoch 239/3000, Training Loss (MSE): 0.8056\n",
      "Epoch 240/3000, Training Loss (MSE): 1.6626\n",
      "Epoch 241/3000, Training Loss (MSE): 1.8797\n",
      "Epoch 242/3000, Training Loss (MSE): 1.2739\n",
      "Epoch 243/3000, Training Loss (MSE): 0.9424\n",
      "Epoch 244/3000, Training Loss (MSE): 1.9864\n",
      "Epoch 245/3000, Training Loss (MSE): 1.8908\n",
      "Epoch 246/3000, Training Loss (MSE): 1.5378\n",
      "Epoch 247/3000, Training Loss (MSE): 1.7568\n",
      "Epoch 248/3000, Training Loss (MSE): 0.8679\n",
      "Epoch 249/3000, Training Loss (MSE): 1.5828\n",
      "Epoch 250/3000, Training Loss (MSE): 1.5921\n",
      "Epoch 251/3000, Training Loss (MSE): 1.7167\n",
      "Epoch 252/3000, Training Loss (MSE): 1.9057\n",
      "Epoch 253/3000, Training Loss (MSE): 1.7688\n",
      "Epoch 254/3000, Training Loss (MSE): 2.1778\n",
      "Epoch 255/3000, Training Loss (MSE): 2.0673\n",
      "Epoch 256/3000, Training Loss (MSE): 2.7576\n",
      "Epoch 257/3000, Training Loss (MSE): 2.1497\n",
      "Epoch 258/3000, Training Loss (MSE): 1.9513\n",
      "Epoch 259/3000, Training Loss (MSE): 1.1532\n",
      "Epoch 260/3000, Training Loss (MSE): 1.2730\n",
      "Epoch 261/3000, Training Loss (MSE): 1.9479\n",
      "Epoch 262/3000, Training Loss (MSE): 2.0401\n",
      "Epoch 263/3000, Training Loss (MSE): 2.1520\n",
      "Epoch 264/3000, Training Loss (MSE): 2.5205\n",
      "Epoch 265/3000, Training Loss (MSE): 1.0353\n",
      "Epoch 266/3000, Training Loss (MSE): 2.1176\n",
      "Epoch 267/3000, Training Loss (MSE): 1.4754\n",
      "Epoch 268/3000, Training Loss (MSE): 2.9521\n",
      "Epoch 269/3000, Training Loss (MSE): 1.9082\n",
      "Epoch 270/3000, Training Loss (MSE): 2.1735\n",
      "Epoch 271/3000, Training Loss (MSE): 2.0874\n",
      "Epoch 272/3000, Training Loss (MSE): 0.8204\n",
      "Epoch 273/3000, Training Loss (MSE): 1.4794\n",
      "Epoch 274/3000, Training Loss (MSE): 1.5178\n",
      "Epoch 275/3000, Training Loss (MSE): 2.3011\n",
      "Epoch 276/3000, Training Loss (MSE): 1.6360\n",
      "Epoch 277/3000, Training Loss (MSE): 1.9994\n",
      "Epoch 278/3000, Training Loss (MSE): 1.8552\n",
      "Epoch 279/3000, Training Loss (MSE): 1.7627\n",
      "Epoch 280/3000, Training Loss (MSE): 2.6997\n",
      "Epoch 281/3000, Training Loss (MSE): 1.6917\n",
      "Epoch 282/3000, Training Loss (MSE): 2.2888\n",
      "Epoch 283/3000, Training Loss (MSE): 1.2515\n",
      "Epoch 284/3000, Training Loss (MSE): 2.0463\n",
      "Epoch 285/3000, Training Loss (MSE): 1.9374\n",
      "Epoch 286/3000, Training Loss (MSE): 2.2696\n",
      "Epoch 287/3000, Training Loss (MSE): 2.7079\n",
      "Epoch 288/3000, Training Loss (MSE): 1.8070\n",
      "Epoch 289/3000, Training Loss (MSE): 1.4900\n",
      "Epoch 290/3000, Training Loss (MSE): 2.8496\n",
      "Epoch 291/3000, Training Loss (MSE): 2.1412\n",
      "Epoch 292/3000, Training Loss (MSE): 2.4512\n",
      "Epoch 293/3000, Training Loss (MSE): 1.6540\n",
      "Epoch 294/3000, Training Loss (MSE): 1.8036\n",
      "Epoch 295/3000, Training Loss (MSE): 2.1484\n",
      "Epoch 296/3000, Training Loss (MSE): 1.0702\n",
      "Epoch 297/3000, Training Loss (MSE): 2.5549\n",
      "Epoch 298/3000, Training Loss (MSE): 1.8260\n",
      "Epoch 299/3000, Training Loss (MSE): 1.8970\n",
      "Epoch 300/3000, Training Loss (MSE): 2.1968\n",
      "Epoch 301/3000, Training Loss (MSE): 2.2615\n",
      "Epoch 302/3000, Training Loss (MSE): 2.1045\n",
      "Epoch 303/3000, Training Loss (MSE): 2.0740\n",
      "Epoch 304/3000, Training Loss (MSE): 3.0225\n",
      "Epoch 305/3000, Training Loss (MSE): 1.5672\n",
      "Epoch 306/3000, Training Loss (MSE): 1.4123\n",
      "Epoch 307/3000, Training Loss (MSE): 1.4849\n",
      "Epoch 308/3000, Training Loss (MSE): 2.3499\n",
      "Epoch 309/3000, Training Loss (MSE): 2.9823\n",
      "Epoch 310/3000, Training Loss (MSE): 2.1280\n",
      "Epoch 311/3000, Training Loss (MSE): 1.9104\n",
      "Epoch 312/3000, Training Loss (MSE): 1.1159\n",
      "Epoch 313/3000, Training Loss (MSE): 1.5051\n",
      "Epoch 314/3000, Training Loss (MSE): 2.7835\n",
      "Epoch 315/3000, Training Loss (MSE): 2.5249\n",
      "Epoch 316/3000, Training Loss (MSE): 1.7268\n",
      "Epoch 317/3000, Training Loss (MSE): 2.2040\n",
      "Epoch 318/3000, Training Loss (MSE): 1.1425\n",
      "Epoch 319/3000, Training Loss (MSE): 1.2495\n",
      "Epoch 320/3000, Training Loss (MSE): 0.9284\n",
      "Epoch 321/3000, Training Loss (MSE): 2.0085\n",
      "Epoch 322/3000, Training Loss (MSE): 2.1711\n",
      "Epoch 323/3000, Training Loss (MSE): 1.8494\n",
      "Epoch 324/3000, Training Loss (MSE): 2.4328\n",
      "Epoch 325/3000, Training Loss (MSE): 1.9059\n",
      "Epoch 326/3000, Training Loss (MSE): 1.0311\n",
      "Epoch 327/3000, Training Loss (MSE): 1.5181\n",
      "Epoch 328/3000, Training Loss (MSE): 2.9225\n",
      "Epoch 329/3000, Training Loss (MSE): 1.9902\n",
      "Epoch 330/3000, Training Loss (MSE): 1.3774\n",
      "Epoch 331/3000, Training Loss (MSE): 2.3639\n",
      "Epoch 332/3000, Training Loss (MSE): 2.6603\n",
      "Epoch 333/3000, Training Loss (MSE): 1.2618\n",
      "Epoch 334/3000, Training Loss (MSE): 2.3985\n",
      "Epoch 335/3000, Training Loss (MSE): 2.7738\n",
      "Epoch 336/3000, Training Loss (MSE): 1.7216\n",
      "Epoch 337/3000, Training Loss (MSE): 2.6513\n",
      "Epoch 338/3000, Training Loss (MSE): 1.6989\n",
      "Epoch 339/3000, Training Loss (MSE): 2.6711\n",
      "Epoch 340/3000, Training Loss (MSE): 1.7018\n",
      "Epoch 341/3000, Training Loss (MSE): 1.9911\n",
      "Epoch 342/3000, Training Loss (MSE): 1.9925\n",
      "Epoch 343/3000, Training Loss (MSE): 2.1507\n",
      "Epoch 344/3000, Training Loss (MSE): 1.9449\n",
      "Epoch 345/3000, Training Loss (MSE): 1.9700\n",
      "Epoch 346/3000, Training Loss (MSE): 1.9358\n",
      "Epoch 347/3000, Training Loss (MSE): 2.4021\n",
      "Epoch 348/3000, Training Loss (MSE): 1.6140\n",
      "Epoch 349/3000, Training Loss (MSE): 2.9568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 49\u001b[0m\n\u001b[1;32m     35\u001b[0m x_batch\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m### VMAP JACREF/JACFWRD Workflow ###\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 1 min on CPU\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# torch.Size([N, 2, 2, 2, 2])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 7 minutes on CPU\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# torch.Size([N, 2, 2, N, 2])\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m jacobian_A_autograd \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# select pairs of n_i and n_i (the rest is empty)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m jacobian_A_autograd_lean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnabnc -> nabc\u001b[39m\u001b[38;5;124m'\u001b[39m, jacobian_A_autograd)\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/autograd/functional.py:786\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    784\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 786\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)\n\u001b[1;32m    795\u001b[0m     ):\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/autograd/functional.py:192\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/ice_thickness/.conda/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# float32 is default for\n",
    "# x_train = torch.load(\"data/sim_data/x_train_lines_discretised.pt\").float().requires_grad_()\n",
    "x_train = inputs_03\n",
    "y_train = simulate_convergence(x_train).float()\n",
    "\n",
    "print(f\"The shape of the training data is {y_train.shape}.\")\n",
    "print(f\"The dtype of the input data is {x_train.dtype}.\")\n",
    "\n",
    "# Convert to DataLoader for batching\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# Initialise model\n",
    "model_A = MLP_compute_A()\n",
    "model_A.train()\n",
    "\n",
    "# Define loss function (e.g., MSE for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (e.g., Adam)\n",
    "optimizer = optim.AdamW(model_A.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "num_epochs = 3000\n",
    "\n",
    "# Initialise tensor to store losses\n",
    "epoch_losses = torch.zeros(num_epochs)\n",
    "\n",
    "print()\n",
    "print(\"Start Training\")\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0  # Accumulate batch losses\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch.requires_grad_()\n",
    "        \n",
    "        ### VMAP JACREF/JACFWRD Workflow ###\n",
    "        # 1 min on CPU\n",
    "        # torch.Size([N, 2, 2, 2, 2])\n",
    "        # jacobian_A_vmap_jacrev = vmap(jacrev(model_A))(x_batch)\n",
    "        # assert that the second dim (size 2) is redundant (\"r)\")\n",
    "        # assert(jacobian_A_vmap_jacrev[:, 0, :, :, :] == jacobian_A_vmap_jacrev[:, 1, :, :, :]).all()\n",
    "        # jacobian_A_vmap_jacrev_lean = torch.einsum('n r a b c -> n a b c', jacobian_A_vmap_jacrev)\n",
    "        #y_pred = jacobian_A_vmap_jacrev_lean.diagonal(dim1 = -2, dim2 = -1).sum(dim = 1)\n",
    "\n",
    "        ### AUTOGRAD Workflow ###\n",
    "        # 7 minutes on CPU\n",
    "        # torch.Size([N, 2, 2, N, 2])\n",
    "        jacobian_A_autograd = torch.autograd.functional.jacobian(model_A, x_batch, create_graph = True)\n",
    "        # select pairs of n_i and n_i (the rest is empty)\n",
    "        jacobian_A_autograd_lean = torch.einsum('nabnc -> nabc', jacobian_A_autograd)\n",
    "        # The last two dims, and then we sum\n",
    "        y_pred = torch.diagonal(jacobian_A_autograd_lean, dim1 = -2, dim2 = -1).sum(dim = 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Store the average loss for the epoch\n",
    "    epoch_losses[epoch] = epoch_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss (MSE): {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to NumPy for plotting\n",
    "plt.figure(figsize = (6, 4))\n",
    "plt.plot(epoch_losses.numpy(), label = \"Training Loss\", color = \"b\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this with another Jacobian function\n",
    "\n",
    "torch.autograd.functional.jacobian()\n",
    "Need to \"turn on\" requires_grad for x because we are taking gradients with respect to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eval mode\n",
    "model_A.eval()\n",
    "\n",
    "x = inputs_03\n",
    "\n",
    "### AUTOGRAD Workflow ###\n",
    "# jacobian_A_autograd = torch.autograd.functional.jacobian(model_A, x)\n",
    "# jacobian_A_autograd_lean = torch.einsum('nabnc -> nabc', jacobian_A_autograd)\n",
    "# y_pred = torch.diagonal(jacobian_A_autograd_lean , dim1 = -2, dim2 = -1).sum(dim = 1).detach()\n",
    "\n",
    "### VMAP JACREF/JACFWRD Workflow ###\n",
    "jacobian_A_vmap_jacrev = vmap(jacrev(model_A))(x)\n",
    "# assert that the second dim (size 2) is redundant (\"r)\")\n",
    "assert(jacobian_A_vmap_jacrev[:, 0, :, :, :] == jacobian_A_vmap_jacrev[:, 1, :, :, :]).all()\n",
    "jacobian_A_vmap_jacrev_lean = torch.einsum('n r a b c -> n a b c', jacobian_A_vmap_jacrev)\n",
    "y_pred = jacobian_A_vmap_jacrev_lean.diagonal(dim1 = -2, dim2 = -1).sum(dim = 1)\n",
    "\n",
    "# div_jacrav = div_functional(x)\n",
    "div_jacrav = div_discrete(y_pred.detach())\n",
    "div_jacrav = torch.zeros_like(div_jacrav)\n",
    "\n",
    "visualise_v_quiver(y_pred.detach(), div_jacrav, x.detach(), title_string = \"Prediction over field\", color_abs_max = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_v_quiver(simulate_convergence(inputs_03), div_functional(inputs_03), inputs_03, title_string = \"Prediction over field\", color_abs_max = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.detach().mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_convergence(inputs_03).detach().mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_v_quiver(y_pred.detach(), div_functional(inputs_03), inputs_03, title_string = \"Prediction over field\", color_abs_max = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobian w.r.t. v throughs issues if x is a variable in compute_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian headache\n",
    "\n",
    "- Jacobian is probably among the most expensive functions\n",
    "- [torch.func.jacrev](https://pytorch.org/docs/stable/generated/torch.func.jacrev.html#torch.func.jacrev)\n",
    "    - The implementation goes forward\n",
    "    - torch.func.jacobian chooses based on efficiency\n",
    "- batched Jacobians via vmap\n",
    "- consider # _func_sum\n",
    "- torch.autograd.functional.jacobian(f, x)\n",
    "    - not as fast as func\n",
    "- Shape torch.Size([16, 2, 2, 2])\n",
    "    - for every i in N we have 2 (two) 2 x 2 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 2, 2)\n",
    "jacobian_vmap = vmap(jacrev(torch.sin))(x)\n",
    "print(jacobian_vmap.shape)\n",
    "\n",
    "jacobian = jacrev(torch.sin)(x)\n",
    "print(jacobian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue with how we construct U \n",
    "# Jacobian: torch.Size([16, 16, 2, 2, 2])\n",
    "# without vmap it was also torch.Size([16, 2, 2, 16, 2])\n",
    "jacobian = vmap(jacfwd(compute_A))(inputs)\n",
    "print(jacobian.shape)\n",
    "\n",
    "# Remove redundant dim\n",
    "# (jacobian[:, 0, : , :, :] == jacobian[:, 15, : , :, :]).any()\n",
    "assert(jacobian[:, 0, : , :, :] == jacobian[:, -1, : , :, :]).any()\n",
    "#jacobian_sq = jacobian[:, 0, : , :, :]\n",
    "#jacobian_sq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "\n",
    "Use apply function to pass arguments into function\n",
    "jacobian_A_vmap_jacrev = vmap(lambda x: jacrev(model_A)(x, param))(x_batch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
