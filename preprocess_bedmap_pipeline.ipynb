{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6835f1",
   "metadata": {},
   "source": [
    "# Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc9a56",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bedmap1 csv files: 1\n",
      "Number of bedmap2 csv files: 66\n",
      "Number of bedmap3 csv files: 84\n",
      "Processing Bedmap1...\n",
      "Number of bedmap1 csv files: 1\n",
      "Processing Bedmap2...\n",
      "Number of bedmap2 csv files: 66\n",
      "Processing Bedmap3...\n",
      "Number of bedmap3 csv files: 84\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyproj\n",
    "\n",
    "# CHANGE THIS TO YOUR PATH\n",
    "path_to_bedmap_data_folder = \"/home/kim/data/bedmap_raw_data_test\"\n",
    "\n",
    "# paths to subfolders\n",
    "path_to_bedmap1_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap1_raw_data\")\n",
    "path_to_bedmap2_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap2_raw_data\")\n",
    "path_to_bedmap3_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap3_raw_data\")\n",
    "\n",
    "# list all CSVs in the folder\n",
    "list_of_bedmap1_csv_files = [f for f in os.listdir(path_to_bedmap1_data_folder) if f.endswith(\".csv\")]\n",
    "list_of_bedmap2_csv_files = [f for f in os.listdir(path_to_bedmap2_data_folder) if f.endswith(\".csv\")]\n",
    "list_of_bedmap3_csv_files = [f for f in os.listdir(path_to_bedmap3_data_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# initialise DataFrame and column names\n",
    "column_list = [\"lon\", \"lat\", \"x\", \"y\", \"s\", \"t\", \"b\", \"b_inferred\", \"source\"]\n",
    "bedmap123_data = pd.DataFrame(columns = column_list)\n",
    "\n",
    "# set up coordinate transformer once\n",
    "lonlat_to_polarstereo = pyproj.Transformer.from_crs(\n",
    "    crs_from = pyproj.CRS(\"epsg:4326\"), # WGS84 (lon, lat)\n",
    "    crs_to = pyproj.CRS(\"epsg:3031\"), # Antarctic Polar Stereographic (x, y)\n",
    "    always_xy = True\n",
    ")\n",
    "\n",
    "# lists \n",
    "paths_to_data_folders_all_versions = [path_to_bedmap1_data_folder, path_to_bedmap2_data_folder, path_to_bedmap3_data_folder]\n",
    "list_of_all_versions = [list_of_bedmap1_csv_files, list_of_bedmap2_csv_files, list_of_bedmap3_csv_files]\n",
    "\n",
    "# loop over bedmap versions\n",
    "for v, (csv_list, folder_path) in enumerate(zip(list_of_all_versions, paths_to_data_folders_all_versions), start = 1):\n",
    "    print(f\"Processing Bedmap{v}...\")\n",
    "    print(f\"Number of bedmap{v} csv files:\", len(csv_list))\n",
    "\n",
    "    # loop over csv files\n",
    "    for i in csv_list:\n",
    "\n",
    "        print(\"Processing:\", i)\n",
    "        # construct full file path\n",
    "        file_path = os.path.join(folder_path, i)\n",
    "\n",
    "        # Load CSV, skipping metadata header lines\n",
    "        pd_data = pd.read_csv(file_path, skiprows = 18, low_memory = False)\n",
    "\n",
    "        # Extract and rename required columns\n",
    "        df = pd_data[[\n",
    "            \"longitude (degree_east)\",\n",
    "            \"latitude (degree_north)\",\n",
    "            \"surface_altitude (m)\",\n",
    "            \"land_ice_thickness (m)\",\n",
    "            \"bedrock_altitude (m)\"\n",
    "        ]].copy() # NOTE: Copy to avoid SettingWithCopyWarning\n",
    "\n",
    "        # Rename columns to short names\n",
    "        df.columns = [\"lon\", \"lat\", \"s\", \"t\", \"b\"]\n",
    "\n",
    "        # Mark where bedrock elevation is inferred (as this is approximately true)\n",
    "        df[\"b_inferred\"] = False\n",
    "        # Create a mask where bedrock elevation is missing (-9999) but surface and land ice thickness are provided\n",
    "        infer_b_mask = (df['s'] != -9999) & (df['t'] != -9999) & (df['b'] == -9999)\n",
    "        df.loc[infer_b_mask, 'b_inferred'] = True\n",
    "        df.loc[infer_b_mask, 'b'] = df['s'] - df['t']\n",
    "\n",
    "        # Drop rows still missing bed elevation\n",
    "        # TODO: Change this if we are focussing on ice thickness and not bed elevation\n",
    "        dropped_rows = (df['b'] == -9999).sum()\n",
    "        print(f\"#rows dropped: {dropped_rows}\")\n",
    "        df = df[df['b'] != -9999]\n",
    "\n",
    "        # Project coordinates\n",
    "        df[\"x\"], df[\"y\"] = lonlat_to_polarstereo.transform(df[\"lon\"].values, df[\"lat\"].values)\n",
    "\n",
    "        # Add filename source\n",
    "        df[\"source\"] = i\n",
    "\n",
    "        # Ensure column order and append\n",
    "        df = df[column_list]\n",
    "        bedmap123_data = pd.concat([bedmap123_data, df], ignore_index = True)\n",
    "\n",
    "    # Final check of shape\n",
    "    print(\"Combined dataset shape:\", bedmap123_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c0ba8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bedmap1 csvs: 1\n",
      "Processing: BEDMAP1_1966-2000_AIR_BM1.csv\n",
      "#rows dropped: 945249\n",
      "Combined dataset shape: (959801, 9)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyproj\n",
    "\n",
    "# CHANGE THIS TO YOUR PATH\n",
    "path_to_bedmap_data_folder = \"/home/kim/data/bedmap_raw_data_test\"\n",
    "\n",
    "# paths to subfolders\n",
    "path_to_bedmap1_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap1_raw_data\")\n",
    "path_to_bedmap2_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap2_raw_data\")\n",
    "path_to_bedmap3_data_folder = os.path.join(path_to_bedmap_data_folder, \"bedmap3_raw_data\")\n",
    "\n",
    "# list all CSVs in the folder\n",
    "list_of_bedmap1_csv_files = [f for f in os.listdir(path_to_bedmap1_data_folder) if f.endswith(\".csv\")]\n",
    "list_of_bedmap2_csv_files = [f for f in os.listdir(path_to_bedmap2_data_folder) if f.endswith(\".csv\")]\n",
    "list_of_bedmap3_csv_files = [f for f in os.listdir(path_to_bedmap3_data_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "print(\"Number of bedmap1 csv files:\", len(list_of_bedmap1_csv_files))\n",
    "print(\"Number of bedmap2 csv files:\", len(list_of_bedmap2_csv_files))\n",
    "print(\"Number of bedmap3 csv files:\", len(list_of_bedmap3_csv_files))\n",
    "\n",
    "# initialise DataFrame and column names\n",
    "column_list = [\"lon\", \"lat\", \"x\", \"y\", \"s\", \"t\", \"b\", \"b_inferred\", \"source\"]\n",
    "all_data = pd.DataFrame(columns = column_list)\n",
    "\n",
    "# set up coordinate transformer once\n",
    "lonlat_to_polarstereo = pyproj.Transformer.from_crs(\n",
    "    crs_from = pyproj.CRS(\"epsg:4326\"), # WGS84 (lon, lat)\n",
    "    crs_to = pyproj.CRS(\"epsg:3031\"), # Antarctic Polar Stereographic (x, y)\n",
    "    always_xy = True\n",
    ")\n",
    "\n",
    "paths_to_data_folders_all_versions = [path_to_bedmap1_data_folder, path_to_bedmap2_data_folder, path_to_bedmap3_data_folder]\n",
    "list_of_all_versions = [list_of_bedmap1_csv_files, list_of_bedmap2_csv_files, list_of_bedmap3_csv_files]\n",
    "\n",
    "for v, (csv_list, folder_path) in enumerate(zip(list_of_all_versions, paths_to_data_folders_all_versions), start = 1):\n",
    "    print(f\"Processing Bedmap{v}...\")\n",
    "    print(f\"Number of bedmap{v} csv files:\", len(csv_list))\n",
    "\n",
    "\n",
    "\n",
    "for i in list_of_csvs_bedmap1:\n",
    "    print(\"Processing:\", i)\n",
    "    file_path = os.path.join(path_to_bedmap1_data_folder, i)\n",
    "\n",
    "    # Load CSV, skipping metadata header lines\n",
    "    pd_data = pd.read_csv(file_path, skiprows = 18, low_memory = False)\n",
    "\n",
    "    # Extract and rename required columns\n",
    "    df = pd_data[[\n",
    "        \"longitude (degree_east)\",\n",
    "        \"latitude (degree_north)\",\n",
    "        \"surface_altitude (m)\",\n",
    "        \"land_ice_thickness (m)\",\n",
    "        \"bedrock_altitude (m)\"\n",
    "    ]].copy() # NOTE: Copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Rename columns to short names\n",
    "    df.columns = [\"lon\", \"lat\", \"s\", \"t\", \"b\"]\n",
    "\n",
    "    # Mark where bedrock elevation is inferred (as this is approximately true)\n",
    "    df[\"b_inferred\"] = False\n",
    "    # Create a mask where bedrock elevation is missing (-9999) but surface and land ice thickness are provided\n",
    "    infer_b_mask = (df['s'] != -9999) & (df['t'] != -9999) & (df['b'] == -9999)\n",
    "    df.loc[infer_b_mask, 'b_inferred'] = True\n",
    "    df.loc[infer_b_mask, 'b'] = df['s'] - df['t']\n",
    "\n",
    "    # Drop rows still missing bed elevation\n",
    "    # TODO: Change this if we are focussing on ice thickness and not bed elevation\n",
    "    dropped_rows = (df['b'] == -9999).sum()\n",
    "    print(f\"#rows dropped: {dropped_rows}\")\n",
    "    df = df[df['b'] != -9999]\n",
    "\n",
    "    # Project coordinates\n",
    "    df[\"x\"], df[\"y\"] = lonlat_to_polarstereo.transform(df[\"lon\"].values, df[\"lat\"].values)\n",
    "\n",
    "    # Add filename source\n",
    "    df[\"source\"] = i\n",
    "\n",
    "    # Ensure column order and append\n",
    "    df = df[column_list]\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Final check\n",
    "print(\"Combined dataset shape:\", all_data.shape)\n",
    "# print(all_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
